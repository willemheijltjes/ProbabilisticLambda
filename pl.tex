\documentclass{llncs}

\usepackage[hidelinks]{hyperref}
\usepackage{amsmath,amssymb,amsthm,mathtools,stmaryrd}

\usepackage{nicefrac}

%\usepackage{fullpage}

\usepackage{xcolor}
\usepackage{tikz}
  \usetikzlibrary{arrows.meta}
  \usetikzlibrary{matrix}
\usepackage{cleveref}
\usepackage{proof}

\makeatletter

% theorem environments
%
%\theoremstyle{definition}
%\newtheorem{definition}{Definition}
%\newtheorem{remark}[definition]{Remark}
%%%
%\theoremstyle{plain}
%\newtheorem{conjecture} [definition]{Conjecture}
%\newtheorem{corollary}  [definition]{Corollary}
%\newtheorem{lemma}      [definition]{Lemma}
%\newtheorem{proposition}[definition]{Proposition}
%\newtheorem{theorem}    [definition]{Theorem}
%%%

%text
\newcommand{\ie}{\textit{i.e.}}
\newcommand{\ih}{\textit{i.h.}}

% coloneqq
\newcommand*\coloneq{
 \mathrel{%
  \rlap{\raisebox{0.3ex}{$\m@th\cdot$}}%
        \raisebox{-0.3ex}{$\m@th\cdot$}%
 {=}}}
\newcommand*\coloneqq{
 \mathrel{%
  \rlap{\raisebox{0.3ex}{$\m@th\cdot$}}%
        \raisebox{-0.3ex}{$\m@th\cdot$}%
  \rlap{\raisebox{0.3ex}{$\m@th\cdot$}}%
        \raisebox{-0.3ex}{$\m@th\cdot$}%
 {=}}}

% vcenter
\newcommand\vc[1]{\vcenter{\hbox{$#1$}}}

% Small operators:

\newcommand\smallbin[1]{\mathchoice
      {\mathbin{\raise.2ex \hbox{$\scriptstyle      #1$}}}%
      {\mathbin{\raise.2ex \hbox{$\scriptstyle      #1$}}}%
      {\mathbin{\raise.12ex\hbox{$\scriptscriptstyle#1$}}}%
      {\mathbin{           \hbox{$\scriptscriptstyle#1$}}}}%

\newcommand\smallsquare{\mathchoice{{\scriptstyle\square}}{{\scriptstyle\square}}{{\scriptscriptstyle\square}}{{\scriptscriptstyle\square}}}

\newcommand\Con{\wedge}
\newcommand\Imp{\rightarrow}

\newcommand\con{\kern1pt{\smallbin\Con}\kern1pt}
\newcommand\imp{\kern1pt{\smallbin\Imp}}


% ===== TERMS AND TYPES

% Probabilistic lambda-calculus
\newcommand\PEL{\Lambda_{\textsf{PE}}}

% Free variables
\newcommand\fv[1]{\mathsf{fv}(\trm{#1})}
\newcommand\fl[1]{\mathsf{fl}(\trm{#1})}

% colours
\colorlet{mgray}{black!40}
\colorlet{lgray}{black!25}
\colorlet{llgray}{black!15}

\colorlet{dblue}{blue!80!black}
\colorlet{dred}{red!80!black}

\colorlet{typecolor}{dblue}
\colorlet{termcolor}{dred}

\newcommand\typecolor{\color{typecolor}}
\newcommand\termcolor{\color{termcolor}}

\newcommand\black{\color{black}}
\newcommand\dblue{\color{dblue}}
\newcommand\dred{\color{dred}}


% types
\newcommand\type[1]{{\let\type@sup@color\termcolor\typecolor\typ{#1}}}
\newcommand\typ[1]{%
  %\vphantom J%
  \let\type@loop=\type@next%
  \type@loop#1,%
}
\newcommand\type@next[1]{%
  \ifx#1,\let\type@loop\type@end\else%
  \ifx#1_\let\type@loop\type@sub\else%
  \ifx#1^\let\type@loop\type@sup\else%
  \ifx#1*\con\else%
  \ifx#1-\kern1pt{\imp}\else%
  #1%
  \fi\fi\fi\fi\fi%
  \type@loop%
}
\newcommand\type@sup@color{}
\newcommand\type@sub[1]{_{#1}\let\type@loop\type@next\type@loop}
\newcommand\type@sup[1]{^{{\type@sup@color #1}}\let\type@loop\type@next\type@loop}
\newcommand\type@vec[1]{\vec{\kern.5pt#1\kern.5pt}\let\type@loop\type@next\type@loop}
\newcommand\type@end{\let\type@sup@color\relax}

% terms
\newcommand\x{\lambda x}
\newcommand\y{\lambda y}
\newcommand\z{\lambda z}

\newcommand\lab{\bullet}
\newcommand{\labtwo}{\circ}

\newcommand\term[1]{{\let\term@typecolor\typecolor\termcolor\trm{#1}}}
\newcommand\trm[1]{%
  \vphantom(%
  \let\term@loop=\term@next%
  \term@loop#1,%
}
\newcommand\term@next[1]{%
  \ifx#1,\let\term@loop\term@end\else%
  \ifx#1:\black\colon\term@typecolor\let\term@loop\term@type\else%
  \ifx#1_\let\term@loop\term@sub\else%
  \ifx#1^\let\term@loop\term@sup\else%
  \ifx#1!\let\term@loop\term@box\else%
  \ifx#1+\let\term@loop\term@prob\else%
  \ifx#1*^\lab\else%
  \ifx#1<\lfloor\else%
  \ifx#1>\rfloor\else%
%  \ifx#1\x\lambda x\else%
%  \ifx#1\y\lambda y\else%
%  \ifx#1\z\lambda z\else%
  \ifx#1=\kern1pt{\smallbin=}\kern1pt\else
  #1%
  \fi\fi\fi\fi\fi\fi\fi\fi\fi\fi%\fi\fi\fi%
  \term@loop%
}
\newcommand\term@typecolor{}
\newcommand\term@end{\let\term@typecolor\relax}
\newcommand\term@sub[1]{_{#1}\let\term@loop\term@next\term@loop}
\newcommand\term@sup[1]{^{#1}\let\term@loop\term@next\term@loop}
\newcommand\term@vec[1]{\vec{\kern.5pt#1\kern.5pt}\let\term@loop\term@next\term@loop}
\newcommand\term@prob[1]{\kern1pt\overset{#1}{{\smallbin\oplus}}\kern1pt\let\term@loop\term@next\term@loop}
\newcommand\term@type{\let\type@loop=\type@next\type@loop}
\newcommand\term@box[1]{\probox{#1}\let\term@loop\term@next\term@loop}

\newcommand\probox[1]{\tikz[baseline=(a.base)]\node[draw,line width=.6pt,inner sep=2pt,minimum height=10pt,minimum width=10pt](a){\makebox[0pt][c]{$\scriptstyle #1\vphantom)$}};}

% rewriting
\newcommand\rw[1][{}]{\stackrel{#1}\rightsquigarrow}
\newcommand\dw{\rotatebox[origin=c]{270}{$\rw$}}
\newcommand\lw{\rotatebox[origin=c]{180}{$\rw$}}
\newcommand\lrw{\rotatebox[origin=c]{180}{$\lw\!\rw$}}
\newcommand\prob{\mathsf p}

\newcommand\confluence[4]{\begin{array}{ccc} \trm{#1} & \rw & \trm{#2} \\ \dw && \dw \\ \trm{#3} & \rw & \trm{#4} \end{array}}

\newcommand\rstrut{\rule{0pt}{13pt}}

% strategies
\newcommand\cbn{\mathsf{cbn}}
\newcommand\cbv{\mathsf{cbv}}

% new rewriting

\tikzstyle{implied}=[dashed]
\tikzstyle{rwhead}=[>/.tip={Triangle[open,length=2.5pt,width=4.5pt]},|/.tip={Rectangle[length=.5pt,width=4.5pt]}]
\tikzstyle{rwblack}=[>/.tip={Triangle[length=2.5pt,width=4.5pt]},|/.tip={Rectangle[length=.5pt,width=4.5pt]}]
\tikzstyle{rw} =[line width=.5pt,rwhead,->]
\tikzstyle{rwb}=[line width=.5pt,rwblack,->]
\tikzstyle{rwbs}=[line width=.5pt,rwblack,->.>]
\tikzstyle{rws}=[line width=.5pt,rwhead,->.>]
\tikzstyle{rwn}=[line width=.5pt,rwhead,->.>|]
\tikzstyle{rwbn}=[line width=.5pt,rwblack,->.>|]
\tikzstyle{rwp}=[line width=.5pt,rwhead,->,double]
\tikzstyle{rwx}=[line width=.5pt,rwhead,->.>,double]

\renewcommand\rw{\mathrel{\tikz\draw[rw](0,0)--(10pt,0pt);}}
\newcommand\rwb{\mathrel{\tikz\draw[rwb](0,0)--(10pt,0pt);}}
\newcommand\rwbs{\mathrel{\tikz\draw[rwbs](0,0)--(10pt,0pt);}}
\newcommand\rws{\mathrel{\tikz\draw[rws](0,0)--(10pt,0pt);}}
\newcommand\rwn{\mathrel{\tikz\draw[rwn](0,0)--(10pt,0pt);}}
\newcommand\rwbn{\mathrel{\tikz\draw[rwbn](0,0)--(10pt,0pt);}}
\newcommand\rwp{\mathrel{\tikz\draw[rwp](0,0)--(10pt,0pt);}}
\newcommand\rwx{\mathrel{\tikz\draw[rwx](0,0)--(10pt,0pt);}}

\newcommand\rwpleft{\mathrel{\tikz\draw[rwp](10pt,0pt)--(0,0);}}
\newcommand\rwxleft{\mathrel{\tikz\draw[rwx](10pt,0pt)--(0,0);}}


% rule names

\newcommand\idem{\ensuremath{\mathsf i}}
\newcommand\cancelL{\ensuremath{\mathsf c_1}}
\newcommand\cancelR{\ensuremath{\mathsf c_2}}
\newcommand\plusAbs{\ensuremath{{\smallbin\oplus}\lambda}}
\newcommand\plusArg{\ensuremath{{\smallbin\oplus}\mathsf a}}
\newcommand\plusFun{\ensuremath{{\smallbin\oplus}\mathsf f}}
\newcommand\plusBox{\ensuremath{{\smallbin{\oplus}\smallsquare}}}
%\newcommand\plusL{\ensuremath{\mathsf d_1}}
%\newcommand\plusR{\ensuremath{\mathsf d_2}}
\newcommand\plusL{\ensuremath{{\smallbin\oplus}{\smallbin\oplus}_1}}
\newcommand\plusR{\ensuremath{{\smallbin\oplus}{\smallbin\oplus}_2}}
\newcommand\plusX{\ensuremath{{\smallbin\oplus}{\star}}}
\newcommand\boxVoid{\ensuremath{\not{\kern-2pt\smallsquare}}}
\newcommand\boxAbs{\ensuremath{\smallsquare\lambda}}
\newcommand\boxFun{\ensuremath{\smallsquare\mathsf f}}


\makeatother


%============================================================ FRONTMATTER

\title{Decomposing probabilistic lambda-calculus}

%\author{Ugo Dal Lago, Giulio Guerrieri, and Willem Heijltjes}

\author{
	 Ugo Dal Lago\inst1
\and Giulio Guerrieri\inst2
\and Willem Heijltjes\inst2
}

\authorrunning{U.\ Dal Lago et al.}

\institute{%
Dipartimento di Informatica - Scienza e Ingegneria\\ Universit\`a di Bologna, Bologna, Italy\\
\email{ugo.dallago@unibo.it}\\[10pt]
\and%
Department of Computer Science\\ University of Bath, Bath, UK\\
\email{\{w.b.heijltjes,g.guerrieri\}@bath.ac.uk}
}


%============================================================ DOCUMENT

\begin{document}

\maketitle

\begin{abstract}
A notion of probabilistic lambda-calculus usually comes with a prescribed reduction strategy, typically call-by-name or call-by-value, as the calculus is non-confluent and these strategies yield different results. This is a break with one of the main advantages of lambda-calculus: confluence, which means results are independent from the choice of strategy.

We present a probabilistic lambda-calculus where the probabilistic operator is decomposed into two syntactic constructs: a generator, which represents a probabilistic event; and a consumer, which acts on the term depending on a given event. The resulting calculus, the Probabilistic Event Lambda-Calculus, is confluent, and interprets the call-by-name and call-by-value strategies through different interpretations of the probabilistic operator into our generator and consumer constructs.

We present two notions of reduction, one via fine-grained local rewrite steps, and one by generation and consumption of probabilistic events. Simple types for the calculus are essentially standard, and they convey strong normalization. We demonstrate how we can encode call-by-name and call-by-value probabilistic evaluation.
\end{abstract}

\section{Introduction}

\[
	\trm{(\x.x = x)(\top+{}\bot)} \qquad\begin{array}{ll}\rw_\cbn &\quad \trm{\top+{}\bot} \\[5pt] \rw_\cbv &\quad \top\end{array}
\]

\end{document}

\section{\texorpdfstring{The probabilistic $\lambda$-calculus $\PEL$}{The probabilistic lambda-claculus PEL}}


\begin{definition}
The \emph{probabilistic event $\lambda$-calculus} ($\PEL$) is given by the following grammar.
\[
	M,N \quad\coloneqq\quad x ~\mid~ \x.N ~\mid~ NM ~\mid~ \trm{N +a M} ~\mid~ \trm{!a.N}
\]
\end{definition}

In a term of the form $\trm{\x.M}$ (resp.~$\trm{!a.M}$), the abstraction $\trm{\x}$ (resp.~the box $\probox a$) is a binder for the free occurrences of the variable $x$ (resp.~the label $a$) in their scope $\trm{M}$.

The calculus features a decomposition of the usual probabilistic sum $\trm{+{}}$, as follows,
\[
	\trm{N +{} M} \quad\stackrel\Delta=\quad \trm{!a.\, N +a M}
\]
where the name $a$ represents an \emph{event}, a binary value $\{0,1\}$, probabilistically generated by the constructor $\probox a$ and used to create a choice by the constructor $\trm{+a}$. That is, $\probox a$ flips a coin setting $a$ to $0$ or $1$, and depending on this $\trm{N+aM}$ reduces to $N$ respectively $M$.

\begin{definition}
	The set $\fl{M}$ of \emph{free labels} of a term $\trm{M}$ is defined inductively as follows:
	\begin{align*}
		\fl{x} &= \emptyset & \fl{MN} &= \fl{M} \cup \fl{N}  & \fl{\x.M} &= \fl{M} \\
		\fl{!a.M} &= \fl{M} \smallsetminus \{a\} & \fl{M +a N} &= \fl{M}\cup \fl{N} \cup \{a\}
	\end{align*}

	A term $\trm{M}$ is \emph{label-closed} if $\fl{M} = \emptyset$.
\end{definition}


From now on, we consider only label-closed terms (and we implicitly assume this, unless otherwise stated).
All terms are identified up to renaming of their bound variables and labels.
Given some terms $\trm{M}$ and $\trm{N}$ and a variable $\trm{x}$, $\trm{M[N/x]}$ stands for the capture-avoiding (for both variables and labels) substitution of $\trm{N}$ for the free occurrences of $\trm{x}$ in $\trm{M}$.
We talk of a \emph{representative} $\trm{M}$ of a term when $\trm{M}$ is not considered up to such a renaming.
A representative $\trm{M}$ of a term is \emph{well-labeled} if
%for every sub-term $\trm{!a.N}$ of $\trm{M}$, the label $a$ may occur only in $\trm{N}$ (if at all).
for every occurrence of $\probox a$ in $\trm{M}$ there is no $\probox a$ occurring in its scope.

\begin{definition}[Order for labels]
\label{def:orderlabels}
	Let $\trm{M}$ be a well-labeled representative of a term.
	We define an \emph{order} $<_{{\trm{M}}}$ for the labels occurring in $\trm{M}$ as follows: $a <_{\trm{M}} b$ if and only if $\probox b$ occurs in the scope of $\probox a$.
\end{definition}


\begin{remark}
	If $\trm{M}$ is a well-labeled and label-closed representative of a term, then $<_{\trm{M}}$ is a finite tree order.
\end{remark}


\begin{definition}
\emph{Reduction} $\rw$ in $\PEL$ consists of \emph{$\beta$-reduction} $\rw_\beta$ and \emph{probabilistic} or \emph{$\prob$-reduction} $\rw_\prob$ (\ie $\rw \,=\, \rw_\beta \,\cup\, \rw_\prob$), both given in Figure~\ref{fig:reduction rules}.
%\[
%\begin{array}{rcl}
%	C[(\lambda x.N)M] &\rw_\beta& C[M[N/x]]
%\\	\trm{H[\,!a.N]} &\rw_p& H[N[0/a]] + H[N[1/a]]
%\end{array}
%\]
\end{definition}



\begin{figure}[!ht]
\begin{align}
	(\x.N)M 				&\rw_\beta N[M/x]													\notag
\\																								\notag
\\	\trm{N +a N}			&\rw_\prob N														\tag{\idem}
\\	\trm{(N +a M) +a P}		&\rw_\prob \trm{N +a P}					\rstrut						\tag{\cancelL}
\\	\trm{N +a (M +a P)}		&\rw_\prob \trm{N +a P}					\rstrut						\tag{\cancelR}
\\																								\notag
\\	\trm{\x.(N +a M)}		&\rw_\prob \trm{(\x.N) +a (\x.M)}									\tag{\plusAbs}
\\	\trm{(N +a M) P}		&\rw_\prob \trm{(NP) +a (MP)}			\rstrut						\tag{\plusFun}
\\	\trm{N (M +a P)}		&\rw_\prob \trm{(NM) +a (NP)}			\rstrut						\tag{\plusArg}
\\	\trm{(N +a M) +b P}		&\rw_\prob \trm{(N +b P) +a (M +b P)} 	\rstrut	&& (a\smallbin<b)	\tag{\plusL}
\\	\trm{N +b (M +a P)}		&\rw_\prob \trm{(N +b M) +a (N +b P)} 	\rstrut	&& (a\smallbin<b)	\tag{\plusR}
%\\	\trm{!b.(N +a M)}		&\rw_\prob \trm{(!b.N) +a (!c M[c/b])}	\rstrut	&& (a\neq b)		\tag{\plusBox}
\\	\trm{!b.(N +a M)}		&\rw_\prob \trm{(!b.N) +a (!b.M)}		\rstrut	&& (a\neq b)		\tag{\plusBox}
\\																								\notag
\\	\trm{!a.N}				&\rw_\prob N 									&& (a\notin N)		\tag{\boxVoid}
\\	\trm{\x.!a.N} 			&\rw_\prob \trm{!a.\x. N}				\rstrut						\tag{\boxAbs}
\\	\trm{(!a.N)M}			&\rw_\prob \trm{!a.(NM)}				\rstrut						\tag{\boxFun}
\end{align}

\caption{Reduction rules}
\label{fig:reduction rules}
\end{figure}

\begin{proposition}[Syntactic characterization of $\prob$-normal forms]
The normal forms $P_0$ of $\rw_\prob$ are given by the following grammars
\[
\begin{array}{ccc@{~}c@{~}c@{}l}
P_0 &\coloneqq& P_1 &\mid& \trm{P_0 +{} P_0}
\\	P_1	&\coloneqq& x   &\mid& \x.P_1 			 &~\mid~ P_1\,P_0
\end{array}
\]
\end{proposition}
\begin{proof}
	By inspection of the rules in Figure~\ref{fig:reduction rules}.
\end{proof}


\begin{proposition}[Syntactic characterization of normal forms]
	The normal forms $N_0$ of $\rw$ are given by the following grammars.
	\[
	\begin{array}{ccc@{~}c@{~}c}
	N_0 &\coloneqq& N_1 &\mid& \trm{N_0 +{} N_0}
	\\	N_1	&\coloneqq& N_2 &\mid& \x.N_1
	\\	N_2 &\coloneqq& x	&\mid& N_2\,N_0
	\end{array}
	\]
\end{proposition}

\subsection{Strong normalization of $\prob$-reduction}

\begin{remark}
	The set $\PEL$ endowed with $\rw_\prob$ is a (first-order) term rewriting system over a countably infinite set of variables (denoted by $x, y, z, \dots$) and the signature $\Sigma$ given by:
	\begin{itemize}
		\item the binary function symbol $\trm{+a}$, for any label $a$;
		\item the unary function symbol $\trm{!a}$, for any label $a$;
		\item the unary function symbol $\trm{\x}$, for any variable $x$;
		\item the binary function symbol $\trm{@}$ ($@(\trm{M},\trm{N})$ stands for $MN$).
	\end{itemize}
\end{remark}

\begin{definition}
	Let $\trm{M}$ be a well-labeled and label-closed representative a term, and let $\Sigma(M)$ be the set of signature symbols occurring in $\trm{M}$.
	We define $\prec_{\trm{M}}$ as the (strict) partial order on $\Sigma(M)$ generated by the following rules:
	\begin{itemize}
		\item $\trm{+a \prec_{\trm{M}} +b}$ if $a <_{\trm{M}} b$;
		\item $\trm{+a \prec_{\trm{M}} !b}$ for any labels $a, b$;
		\item $\trm{!b.\prec_{\trm{M}} @}$ and $\trm{!b.\prec_{\trm{M}} \x}$ for any label $b$.
	\end{itemize}
\end{definition}

\begin{lemma}
\label{lemma:strong-normalization}
	The reduction $\rw_\prob$ is strongly normalizing.
\end{lemma}

\begin{proof}
	For the first-order term rewriting system $(\PEL, \rw_\prob)$  it can be defined a well-founded recursive path ordering $>$ in the sense of \cite[p. 289]{Dershowitz82} such that $\trm{M \rw_\prob N}$ implies $\trm{M}>\trm{N}$.
\end{proof}

\subsection{Strong normalization for typed terms}
In this section, we prove that the relation $\rw$ enjoys strong
normalization in simply typed terms.

Since the proof of strong normalization is quite delicate, it make
sense to turn the definition of the order $<_{{\trm{M}}}$ from
Definition~\ref{def:orderlabels} more formal, at the same time
allowing to treat label-\emph{open} terms. This is based on
Figure~\ref{fig:order}.
\newcommand{\labjudg}[2]{#1\vdash_{L} #2}
\begin{figure}
  \fbox{
    \begin{minipage}{.97\textwidth}
      \begin{tabular}{ll}        
        \textsf{Label Sequences}: & $\theta\quad\coloneqq\quad \varepsilon ~\mid~ a\cdot\theta $\\
        \textsf{Label Judgments}: & $\xi\quad\coloneqq\quad \labjudg{\theta}{M}$\\
        \begin{minipage}{.25\textwidth}\textsf{Label Rules}:\end{minipage} &
        \begin{minipage}{.7\textwidth}
        $$
        \infer{\labjudg{\theta}{x}}{}\qquad
        \infer{\labjudg{\theta}{\x.M}}{\labjudg{\theta}{M}}\qquad
        \infer{\labjudg{\theta}{MN}}{\labjudg{\theta}{M} & \labjudg{\theta}{N}}
        $$
        $$
        \infer{\labjudg{\theta}{\trm{M +a N}}}{\labjudg{\theta}{M} & \labjudg{\theta}{N} & a\in\theta}\qquad\qquad
        \infer{\labjudg{\theta}{\trm{!a.M}}}{\labjudg{a\cdot\theta}{M}}
        $$
        \end{minipage}
        \\
      \end{tabular}
    \end{minipage}
  }
  \label{fig:order}
  \caption{Labelizing Terms}
\end{figure}
It is easy to realize that, of course modulo label $\alpha$-equivalence, for
every term $M$ there is at least one $\theta$ such that $\labjudg{\theta}{M}$.

Now, let us define types, environments, judgments, and typing rules in
Figure~\ref{fig:typing}.
\newcommand{\arrow}{\Rightarrow}
\newcommand{\judg}[3]{#1\vdash #2:#3}
\begin{figure}
  \fbox{
    \begin{minipage}{.97\textwidth}
      \begin{tabular}{ll}        
        \textsf{Types}: & $\tau\quad\coloneqq\quad \alpha ~\mid~ \tau\arrow\rho$\\
        \textsf{Environments}: & $\Gamma\quad\coloneqq\quad x_1:\tau_1,\ldots,x_n:\tau_n$\\
        \textsf{Judgments}: & $\pi\quad\coloneqq\quad \judg{\Gamma}{M}{\tau}$\\
        \begin{minipage}{.25\textwidth}\textsf{Typing Rules}:\end{minipage} &
        \begin{minipage}{.7\textwidth}
        $$
        \infer{\judg{\Gamma,x:\tau}{x}{\tau}}{}\qquad
        \infer{\judg{\Gamma}{\x.M}{\tau\arrow\rho}}{\judg{\Gamma,x:\tau}M\rho}\qquad
        \infer{\judg{\Gamma}{MN}{\rho}}{\judg{\Gamma}{M}{\tau\arrow\rho} & \judg{\Gamma}{N}{\tau}}
        $$
        $$
        \infer{\judg{\Gamma}{\trm{M +a N}}{\tau}}{\judg{\Gamma}{M}{\tau} & \judg{\Gamma}{N}{\tau}}\qquad\qquad
        \infer{\judg{\Gamma}{\trm{!a.M}}{\tau}}{\judg{\Gamma}{M}{\tau}}
        $$
        \end{minipage}
        \\
      \end{tabular}
    \end{minipage}
  }
  \caption{Types, Environments, Judgments, and Rules}
  \label{fig:typing}
\end{figure}
The type structure being precisely the usual one (although terms are of course
different), we can reuse most of the usual proof of strong normalization, for
example in the version given by Ralph Loader's notes, page 17. In the following, we only
report the elements which make our proof different.

\begin{lemma}
\label{lemma:cloredsum}
  The set SN is closed under the following rule:
  $$
  \infer{\trm{M +a N}L_1\ldots L_m}{ML_1\ldots L_m & NL_1\ldots L_m}
  $$
\end{lemma}
\begin{proof}
  Let $\theta$ be such that
  $$
  \labjudg{\theta}{\trm{M +a N}L_1\ldots L_m}
  $$
  and let $h(a,\theta)$ be the height of $a$ in the sequence $\theta$.
  The proof goes by lexicographic induction on the following quadruple:
  \begin{equation}\label{equ:redord}
  (m,h(a,\theta),\sum_{i=1}^m\mathit{sn}(L_i)+\mathit{sn}(M)+\mathit{sn}(N),|M|+|N|)
  \end{equation}
  We proceed by showing that all terms to which
  $\trm{M +a N}L_1\ldots L_m$ reduces are strongly normalizing:
  \begin{itemize}
  \item
    If reduction happens in one between $M,N,L_1,\ldots,L_m$, then we
    are done, because we get an instance of the rule where the first two
    components of \ref{equ:redord} stay constant, and the third
    strictly decreases.
  \item
    If reduction happens at the leftmost component $\trm{M +a N}$
    due to the rule $\trm{P +a P}\rw_\prob P$, then one of the two
    hypotheses apply trivially.
  \item
    If reduction happens at the leftmost component $\trm{M +a N}$
    due to the rule $\trm{(P +a Q) +a R}\rw_\prob \trm{P +a R}$,
    then the IH holds due to the fourth component being strictly
    smaller. Similarly when the rule is
    $\trm{P +a (Q +a R)}\rw_\prob \trm{P +a R}$.    
  \item
    If reduction happens in the leftmost application due to
    the rule $\trm{(P +a Q) R}\rw_\prob \trm{(PR) +a (QR)}$,
    then the IH can be applied, because the number of arguments $m$
    strictly decreases. Similarly when the rule is
    $\trm{N (M +a P)}\rw_\prob\trm{(NM) +a (NP)}$.
  \item
    If reduction happens at the leftmost component $\trm{M +a N}$
    due to the rule $\trm{(P +b Q) +a R}\rw_\prob \trm{(P +a R) +b (Q +a R)}$,
    then $M$ can be written as $\trm{P +b Q}$, and the
    following two terms are strongly normalizing (because
    $\trm{(P +b Q)L_1\ldots L_m}$ is by hypothesis strongly normalizing
      itself):
    $$
    PL_1\ldots L_m\qquad QL_1\ldots L_m
    $$
    Moreover, $\mathit{sn}(PL_1\ldots L_m),\mathit{sn}(QL_1\ldots
    L_m)\leq\mathit{sn}(\trm{(P +b Q)L_1\ldots L_m}$.  We can then
    conclude that $\trm{(P +a N)}L_1\ldots L_m$ and $\trm{(Q +a
        N)}L_1\ldots L_m$ are both strongly normalizing by IH, because
    the fourth component is strictly smaller. Finally, we can conclude
    again by induction hypothesis, since the number of arguments stays
    the same, while the level of $b$ must be smaller than that of
    $a$. Similarly if the rule applied is $\trm{P +a (Q +b
      R)}\rw_\prob \trm{(P +a Q) +b (P +a R)}$.
  \end{itemize}
\end{proof}

\begin{lemma}
  The set SN is closed under the following rule:
  $$
  \infer{\trm{(!a.M)}L_1\ldots L_m}{\trm{M}L_1\ldots L_m}
  $$
\end{lemma}
\begin{proof}
  The proof is structurally very similar to the one of
  Lemma~\ref{lemma:cloredsum}. The lexicographic order
  is however the following one:
  $$
  (m,\sum_{i=1}^m\mathit{sn}(L_i)+\mathit{sn}(M),|M|)
  $$
  There is one case in which we need to use
  Lemma \ref{lemma:cloredsum}, namely the one in which the
  considered reduction rule is the following:
  $$
  \trm{!b.(P +a Q)}\rw_\prob\trm{(!b.P) +a (!b.Q)}.
  $$
  Since $M=\trm{P +a Q}$ and $ML_1\ldots L_m$ by hypothesis,
  we conclusde that $PL_1\ldots L_m$ and $QL_1\ldots L_m$
  are both strongly normalizing. By induction hypothesis,
  since $\mathit{sn}(P),\mathit{sn}(Q)\leq\mathit{sn}(M)$,
  it holds that $\trm{(!b.P)}L_1\ldots L_m$ and $\trm{(!b.Q)}L_1\ldots L_m$
  are both strongly normalizing themselves. Lemma~\ref{lemma:cloredsum},
  yields the thesis.
\end{proof}

\begin{lemma}
  The set SN is closed under the following rule:
  $$
  \infer{\trm{(\x.M)}L_0\ldots L_m}{\trm{M[L_0/x]}L_1\ldots L_m & L_0}
  $$
\end{lemma}
\begin{proof}
  Again, the proof is structurally very similar to the one
  of Lemma~\ref{lemma:cloredsum}. The underlying order,
  needs to be slightly adapted, and is the lexicographic
  order on
  $$
  (\mathit{sn}(\trm{M[L_0/x]}L_1\ldots L_m)+\mathit{sn}(L_0),|M|)
  $$
  As usual, we proceed by showing that all terms to which
  $\trm{(\x.M)}L_0\ldots L_m$ reduces are strongly normalizing:
  \begin{itemize}
  \item
    If reduction happens in $L_0$, then we can mimick
    the same reduction in by zero or more reduction
    steps in $\trm{M[L_0/x]}L_1\ldots L_m$, and conclude
    by induction hypothesis.
  \item
    If reduction happens in $M$ or in $L_1,\ldots,L_m$,
    then we can mimick the same reduction in one or more
    reduction in $\trm{M[L_0/x]}L_1\ldots L_m$, and conclude
    by induction hypothesis.
  \item
    If the reduction step we perform is 
  \end{itemize}
\end{proof}

The definition of a reducible term stays the same:

Lemma 3.5 must be complemented with two new clauses, as follows:
\newcommand{\RedSet}[1]{\mathit{Red}_{#1}}
\begin{lemma}
  \begin{itemize}
  \item
    If $(\Gamma,ML_1\ldots L_m)\in\RedSet{\tau}$
    and $(\Gamma,NL_1\ldots L_m)\in\RedSet{\tau}$,
    then $(\Gamma,\trm{(M +a N)}L_1\ldots L_m)\in\RedSet{\tau}$.
  \item
    If $(\Gamma,ML_1\ldots L_m)\in\RedSet{\tau}$,
    then $(\Gamma,\trm{(!a.M)}L_1\ldots L_m)\in\RedSet{\tau}$.
  \end{itemize}
\end{lemma}
\begin{proof}
  The proofs are just very simple inductions on $\tau$.
\end{proof}

\subsection{Confluence of $\prob$-reduction}

\begin{definition}
We define a \emph{context} $C[\,]$ %and \emph{head context} $H[\,]$
as follows.
\[
\begin{array}{lll@{~}l@{~}l@{~}l@{~}l}
	C[\,] &\coloneqq& [\,] &\mid& \lambda x.C[\,] &\mid& C[\,]M ~\mid~ NC[\,] ~\mid~ \trm{C[\,]+aM} ~\mid~ \trm{N+aC[\,]} ~\mid~ \trm{!a.C[\,]}
%\\	H[\,] &\coloneqq& [\,] &\mid& \lambda x.H[\,] &\mid& H[\,]M
\end{array}
\]
The term $C[N]$ represents $C[\,]$ with the hole $[\,]$ replaced by $N$.
\end{definition}

Observe that the six reduction rules $\plusAbs$ through $\plusBox$ in Figure~\ref{fig:reduction rules} are all of the following form. We refer to these collectively as $\plusX$.
\begin{align}
	\trm{C[N+aM]} \rw_\prob \trm{C[N]+aC[M]}
	\tag\plusX
\end{align}


%
%\begin{definition}
%The $a$-\emph{projections} $N[i/a]$ for $i\in\{0,1\}$ of a term $N$ are as follows.
%\[
%\begin{array}{rcl}
%  \rstrut	\trm{x[i/a]}	 	&=& x
%\\\rstrut	\trm{(\x.N)[i/a]}	&=& \trm{\x.(N[i/a])}
%\\\rstrut	\trm{(NM)[i/a]}		&=& \trm{(N[i/a])(M[i/a])}
%\end{array}
%\begin{array}{rcl}
%  \rstrut	\trm{(N_0 +a N_1)[i/a]} &=& \trm{N_i[i/a]}
%\\\rstrut	\trm{(N +b M)[i/a]} 	&=& \trm{(N[i/a]) +b (M[i/a])}
%\\\rstrut	\trm{(!b.N)[i/a]}  		&=& \trm{!b.(N[i/a])}
%\end{array}
%\]
%\end{definition}

%
%\begin{proof}[Sketch]
%The following measure reduces for every step. Order constructors by
%\[
%			\trm{+a}
%\smallbin<	\trm{+b}
%\smallbin<	\probox c
%\qquad
%(a\smallbin<b\smallbin<c)
%\]
%(where $@$ stands for application). We consider sequences of these, ordered lexicographically.
%\end{proof}
%
%\begin{lemma}
%Reduction $\rw_\prob$ is confluent.
%\end{lemma}
%
%\begin{proof}
%	By Newman's lemma and strong normalization of $\rw_\prob$ (\Cref{lemma:strong-normalization}), we only have to prove that $\rw_\prob$ is locally confluent.
%We consider each reduction rule against those lower down in the table in Figure~\ref{fig:reduction rules}.
%\begin{itemize}
%	\item $(\idem)$ $\trm{N +a N}\rw N$.
%
%\[
%\begin{tikzpicture}
%	\matrix [matrix of math nodes] (m) {
%	  \trm{N +a (M +a M)} &[20pt] \trm{N +a M}
%	\\ };
%	\draw[rw,yshift=30pt]  (m-1-1) [] --node[above]{$\idem$}    (m-1-2);
%	\draw[rw,yshift=-3pt] (m-1-1) --node[below]{$\cancelR$} (m-1-2);
%\end{tikzpicture}
%\]
%
%\[
%	\trm{N +a (M +a M)} \begin{array}{c}\rw\\[-6pt]\rw\end{array} \trm{N +a M}
%\qquad
%\begin{array}{c@{~}c@{~}c}
%	\trm{(N +a M) +a (N +a M)} &\rw& \trm{N+a M}
%\\	\dw & \rotatebox[origin=c]{30}{$\rw$}
%\\	\trm{(N +a M) +a M}\rstrut
%\end{array}
%\qquad
%\begin{array}{c@{~}c@{~}c}
%	\trm{C[N +a N]}	&\rw& C[N]
%\\	\dw & \rotatebox[origin=c]{30}{$\rw$}
%\\	\trm{C[N] +a C[N]}\rstrut
%\end{array}
%\]
%
%	\item $\trm{N +a (M +a P)}\rw\trm{N +a P}$.
%
%\[
%\begin{array}{c@{~}c@{~}c}
%	\trm{(N+aM)+a(P+aQ)} & \rw & \trm{(N+aM)+a Q}
%\\	\dw && \dw
%\\	\trm{N +a (P+aQ)} & \rw & \trm{N+aQ} \rstrut
%\end{array}
%\qquad
%\begin{array}{c@{~}c@{~}c}
%	\trm{C[N +a (M +a P)]} &\rw& \trm{C[N+a M]}
%\\	\dw
%\\	\trm{C[N] +a C[M+a P]} && \dw
%\\	\dw
%\\	\trm{C[N] +a (C[M] +a C[P])} &\rw& \trm{C[N] +a C[M]}
%\end{array}
%\]
%
%\[
%a<b
%\begin{array}{c@{~}c@{~}c}
%	\trm{(N+aM)+b(P+bQ)} & \rw & \trm{(N+aM)+b Q}
%\\	\dw && \dw
%\\	\trm{(N+b(P+bQ))+a(M+b(P+bQ))} & \rws & \trm{(N+bQ)+a(M+bQ)} \rstrut
%\end{array}
%\]
%
%	\item $\trm{C[N+aM]}\rw\trm{C[N]+a C[M]}$.
%
%\[
%a < b \quad
%\begin{array}{c@{~}c@{~}c}
%	\trm{C[N +b (M +a P)]} &\rw& \trm{C[N]+b C[M+a P]}
%\\	\dw && \dw
%\\	\trm{C[(N +b M) +a (N+b P)]} && \trm{C[N]+b (C[M] +a C[P]} \rstrut
%\\	\dw && \dw
%\\	\trm{C[N +b M] +a [N +b P]}	&\rw& \trm{(C[N]+b C[M])+a(C[N]+bC[P]]} \rstrut
%\end{array}
%\]
%
%
%	\item $\trm{N +b (M +a P)}\rw\trm{(N +b M) +a (N +b P)}$.
%
%\[
%a<b
%\begin{array}{c@{~}c@{~}c}
%	\trm{(N+a Q)+b(M+a P)} &\rw& \trm{((N+a Q) +b M) +a ((N+a Q) +b P)}
%\\	\dw && \dw_*
%\\	\trm{(N+b(M+a P))+a(Q+b(M+a P))} && \trm{((N +b M)+a (Q +b M)) +a ((N +b P)+a(Q +b P))} \rstrut
%\\	\dw_* && \dw_*
%\\	\trm{((N+b M) +a (N+b P)) +a ((Q +b M) +a (Q +b P))} &\rw^*& \trm{(N+b M)+a(Q+b P)} \rstrut
%\end{array}
%\]
%
%{\footnotesize
%\[
%a<c<b
%\begin{array}{c@{~}c@{~}c}
%\trm{(N+a Q)+b(M+c P)} &\rw& \trm{((N+a Q) +b M) +c ((N+a Q) +b P)}
%\\	\dw && \dw_*
%\\	\trm{(N +b(M+c P))+a(Q+b(M+c P))} && \trm{((N +b M)+a (Q +b M)) +c ((N +b P)+a(Q +b P))} \rstrut
%\\	\dw_* && \dw_*
%\\\trm{((N +b M) +c (N +b P)) +a ((Q +b M) +c (Q +b P))} && \trm{((N +b M) +c ((N +b P)+a(Q +b P))) +a ((Q +b M) +c ((N +b P)+a(Q +b P)))} \rstrut
%\\	 & \rotatebox[origin=c]{155}{$\rw_*$}& \dw_*
%\\	 && \trm{(((N +b M) +c (N +b P)) +a ((N +b M) +c (Q +b P))) +a (((Q +b M) +c (N +b P)) +a ((Q +b M) +c (Q +b P)))} \rstrut
%\end{array}
%\]
%}
%
%
%	\item $\trm{N (M +a P)}\rw\trm{(NM) +a (NP)}$.
%
%\[
%\begin{array}{c@{~}c@{~}c}
%\trm{(N+a Q)(M+a P)} &\rw& \trm{((N+a Q) M) +a ((N+a Q) P)}
%\\	\dw && \dw_*
%\\	\trm{(N(M+a P))+a(Q(M+a P))} && \trm{((N M)+a (Q M)) +a ((N P)+a(Q P))} \rstrut
%\\	\dw_* && \dw_*
%\\	\trm{((NM) +a (N P)) +a ((Q M) +a (Q P))} &\rw^*& \trm{(NM)+a(QP)} \rstrut
%\end{array}
%\]
%
%{\footnotesize
%\[
%a<b
%\begin{array}{c@{~}c@{~}c}
%\trm{(N+a Q)(M+b P)} &\rw& \trm{((N+a Q) M) +b ((N+a Q) P)}
%\\	\dw && \dw_*
%\\	\trm{(N(M+b P))+a(Q(M+b P))} && \trm{((N M)+a (Q M)) +b ((N P)+a(Q P))} \rstrut
%\\	\dw_* && \dw_*
%\\	\trm{((NM) +b (N P)) +a ((Q M) +b (Q P))} && \trm{((N M) +b ((N P)+a(Q P))) +a ((Q M) +b ((N P)+a(Q P)))} \rstrut
%\\	 &\rotatebox[origin=c]{155}{$\rw_*$} & \dw_*
%\\	 && \trm{(((N M) +b (N P)) +a((N M) +b(Q P))) +a (((Q M) +b (N P)) +a ((Q M) +b(Q P)))} \rstrut
%\end{array}
%\]
%}
%
%	\item $\trm{!b.(N +a M)} \rw \trm{(!b.N) +a (!b.M)}$ %(!c M[c/b])}$
%
%\[
%a \neq b, \ b \notin\trm{N+a M} \
%\begin{array}{c@{~}c@{~}c}
%	\trm{!b.(N +a M)} &\rw& \trm{(!b.N) +a (!b.M)}
%\\	\dw & \rotatebox[origin=c]{210}{$\rw_*$}
%\\	\trm{N +a M} &&
%\end{array}
%\]
%
%\end{itemize}
%\end{proof}


\begin{lemma}
Reduction $\rw_\prob$ is confluent.
\end{lemma}

\begin{proof}
	By Newman's lemma and strong normalization of $\rw_\prob$ (\Cref{lemma:strong-normalization}), we only have to prove that $\rw_\prob$ is locally confluent.
We consider each reduction rule against those lower down in the table in Figure~\ref{fig:reduction rules}. For the symmetric rule pairs $\cancelL$/$\cancelR$, $\plusL$/$\plusR$, and $\plusFun/\plusArg$ we present only the first case.
\begin{itemize}
	\item $(\idem)$ $\trm{N +a N}\rw N$.

\[
\vc{\begin{tikzpicture}[x=20pt,y=1.5ex]
	\node[anchor=base east] (a) at (0,0) {$\trm{(N+aN)+aM}$};
	\node[anchor=base west] (b) at (1,0) {$\trm{N+aM}$};
	\draw[rw] (0,1) --node[above]{$\idem$}    (1,1);
	\draw[rw] (0,0) --node[below]{$\cancelL$} (1,0);
\end{tikzpicture}}
\quad
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+aM)+a(N+aM)} &[20pt] \trm{N+aM}
	\\[20pt]\trm{N+a(N+aM)}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\idem$}    (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\cancelL$} (m-2-1);
	\draw[rw,implied] (m-2-1) --node[below right=-2pt] {$\cancelR$} (m-1-2);
\end{tikzpicture}}}
\quad
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{C[N+aN]}    &[20pt] C[N]
	\\[20pt]\trm{C[N]+aC[N]}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\idem$}  (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusX$} (m-2-1);
	\draw[rw,implied] (m-2-1) --node[below right=-2pt] {$\idem$} (m-1-2);
\end{tikzpicture}}}
\]
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+aM)+b(N+aM)} &[30pt] \trm{N+aM}
	\\[20pt]\trm{(N+b(N+aM))+a(M+b(N+aM))} &&[10pt] (a<b)
	\\[20pt]\trm{((N+bN)+a(N+bM))+a((M+bN)+a(M+bM))} & \trm{(N+bN)+a(M+bM)}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\idem$}    (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusL$} (m-2-1);
	\draw[rws,implied] (m-2-1) --node[left] {$\plusR$}   (m-3-1);
	\draw[rws,implied] (m-3-2) --node[right]{$\idem$}    (m-1-2);
	\draw[rws,implied] (m-3-1) --node[below]{$\cancelL,\cancelR$} (m-3-2);
\end{tikzpicture}}}
\]

	\item $(\cancelL)$ $\trm{(N +a M) +a P}\rw\trm{N +a P}$.

\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+aM)+a(P+aQ)} &[20pt] \trm{N+a(P+aQ)}
	\\[20pt]\trm{(N+aM)+a Q} & \trm{N+aQ}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\cancelL$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\cancelR$} (m-2-1);
	\draw[rw,implied] (m-1-2) --node[right]{$\cancelR$} (m-2-2);
	\draw[rw,implied] (m-2-1) --node[below]{$\cancelL$} (m-2-2);
\end{tikzpicture}}}
\qquad
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{C[(N+aM)+aP]} &[20pt] \trm{C[N+aM]}
	\\[20pt]\trm{C[N+aM]+aC[P]}
	\\[20pt]\trm{(C[N]+aC[M])+aC[P]} & \trm{C[N]+aC[M]}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\cancelL$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusX$}   (m-2-1);
	\draw[rw,implied] (m-2-1) --node[left] {$\plusX$}   (m-3-1);
	\draw[rw,implied] (m-1-2) --node[right]{$\plusX$}   (m-3-2);
	\draw[rw,implied] (m-3-1) --node[below]{$\cancelL$} (m-3-2);
\end{tikzpicture}}}
\]
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
			\trm{(N+bM)+b(P+aQ)} &[20pt]  \trm{N+b(P+aQ)}
	\\[20pt]\trm{((N+bM)+bP)+a((N+bM)+bQ)} & \trm{(N+bP)+a(N+bQ)}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\cancelL$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusR$}   (m-2-1);
	\draw[rw, implied] (m-1-2) --node[right]{$\plusR$} (m-2-2);
	\draw[rws,implied] (m-2-1) --node[below]{$\cancelL$} (m-2-2);
\end{tikzpicture}}}
\qquad(a<b)
\]

	\item $(\plusX)$ $\trm{C[N+aM]}\rw\trm{C[N]+a C[M]}$.

\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{C[(N+aM)+bP]}      &[20pt] \trm{C[N+aM]+bC[P]}
	\\[20pt]\trm{C[(N+bP)+a(M+bP)]} &       \trm{(C[N]+aC[M])+bC[P]}		 &[10pt] (a<b)
	\\[20pt]\trm{C[N+bP]+aC[M+bP]}  &       \trm{(C[N]+bC[P])+a(C[M]+bC[P])}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\plusX$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusL$} (m-2-1);
	\draw[rw, implied] (m-1-2) --node[right]{$\plusX$} (m-2-2);
	\draw[rw, implied] (m-2-1) --node[left] {$\plusX$} (m-3-1);
	\draw[rw, implied] (m-2-2) --node[right]{$\plusL$} (m-3-2);
	\draw[rws,implied] (m-3-1) --node[below]{$\plusX$} (m-3-2);
\end{tikzpicture}}}
\]

	\item $(\plusL)$ $\trm{(N+aM)+bP}\rw\trm{(N+bP)+a(M+bP)}$.

\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+aM)+b(P+aQ)}                      &[10pt] \trm{(N+b(P+aQ))+a(M+b(P+aQ))}
	\\[20pt]\trm{((N+aM)+bP)+a((N+aM)+bQ)}            &       \trm{((N+bP)+a(N+bQ))+a((M+bP)+a(M+bQ))} &[10pt] (a<b)
	\\[20pt]\trm{((N+bP)+a(M+bP))+a((N+bQ)+a(M+bQ))}  &       \trm{(N+bP)+a(M+bQ)}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\plusL$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusR$} (m-2-1);
	\draw[rws,implied] (m-1-2) --node[right]{$\plusR$} (m-2-2);
	\draw[rws,implied] (m-2-1) --node[left] {$\plusL$} (m-3-1);
	\draw[rws,implied] (m-2-2) --node[right]{$\cancelL,\cancelR$} (m-3-2);
	\draw[rws,implied] (m-3-1) --node[below]{$\cancelL,\cancelR$} (m-3-2);
\end{tikzpicture}}}
\]
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+bM)+c(P+aQ)}            &[20pt] \trm{(N+c(P+aQ))+b(M+c(P+aQ))}
	\\[20pt]                                &       \trm{((N+cP)+a(N+cQ))+b((M+cP)+a(M+cQ))} &[10pt] (a<b<c)
	\\[20pt]\trm{((N+bM)+cP)+a((N+bM)+cQ)}  &       \trm{((N+cP)+b(M+cP))+a((N+cQ)+b(M+cQ))}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\plusL$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusR$} (m-3-1);
	\draw[rws,implied] (m-1-2) --node[right]{$\plusR$} (m-2-2);
	\draw[rws,implied] (m-2-2) --node[right]{$\plusL,\plusR,\cancelL,\cancelR$} (m-3-2);
	\draw[rws,implied] (m-3-1) --node[below]{$\plusL$} (m-3-2);
\end{tikzpicture}}}
\]

	\item $(\plusFun)$ $\trm{(N+aM)P}\rw\trm{(NP)+a(MP)}$.

\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+aM)(P+aQ)}                &[10pt] \trm{(N(P+aQ))+a(M(P+aQ))}
	\\[20pt]\trm{((N+aM)P)+a((N+aM)Q)}        &       \trm{((NP)+a(NQ))+a((MP)+a(MQ))}
	\\[20pt]\trm{((NP)+a(MP))+a((NQ)+a(MQ))}  &       \trm{(NP)+a(MQ)}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\plusFun$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusArg$} (m-2-1);
	\draw[rws,implied] (m-1-2) --node[right]{$\plusArg$} (m-2-2);
	\draw[rws,implied] (m-2-1) --node[left] {$\plusFun$} (m-3-1);
	\draw[rws,implied] (m-2-2) --node[right]{$\cancelL,\cancelR$} (m-3-2);
	\draw[rws,implied] (m-3-1) --node[below]{$\cancelL,\cancelR$} (m-3-2);
\end{tikzpicture}}}
\]
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+bM)(P+aQ)}         &[20pt] \trm{(N(P+aQ))+b(M(P+aQ))}
	\\[20pt]                           &       \trm{((NP)+a(NQ))+b((MP)+a(MQ))} &[10pt] (a<b)
	\\[20pt]\trm{((N+bM)P)+a((N+bM)Q)} &       \trm{((NP)+b(MP))+a((NQ)+b(MQ))}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\plusFun$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusArg$} (m-3-1);
	\draw[rws,implied] (m-1-2) --node[right]{$\plusArg$} (m-2-2);
	\draw[rws,implied] (m-2-2) --node[right]{$\plusL,\plusR,\cancelL,\cancelR$} (m-3-2);
	\draw[rws,implied] (m-3-1) --node[below]{$\plusFun$} (m-3-2);
\end{tikzpicture}}}
\]

	\item $(\plusBox)$ $\trm{!b.(N +a M)} \rw \trm{(!b.N) +a (!b.M)}$

\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{!b.(N+aM)}    &[20pt] \trm{(!b.N)+a(!b.M)}
	\\[20pt]\trm{N+aM}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\plusBox$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\boxVoid$} (m-2-1);
	\draw[rws,implied] (m-1-2) --node[below right=-2pt] {$\boxVoid$} (m-2-1);
\end{tikzpicture}}}
\quad (a \neq b, \ b \notin\trm{N+a M})
\]

\end{itemize}
\end{proof}



\begin{definition}
We denote the unique $\prob$-normal form of a term $N$ by $N^\prob$.
\end{definition}

\subsection{Confluence}

We aim to prove that $\rw \,=\, \rw_\beta \cup \rw_\prob$ is confluent.

\begin{lemma}[Substitution for $\rw_\prob$]
	\label{lemma:substitution}
	\hfill
	\begin{enumerate}
		\item If $\trm{N \rw_\prob N'}$ then $\trm{M[N/x] \rw_\prob^* M[N'/x]}$.
		\item If $\trm{M \rw_\prob M'}$ then $\trm{M[N/x] \rw_\prob M'[N/x]}$.
		\item If $\trm{x \in {\fv{M}}}$ and $a <_M b$ for any $\trm{b \in {\fl{M}}}$ then $\trm{M[N +a P/x]} \rw_\prob^* \trm{M[N/x] +a M[P/x]}$.
	\end{enumerate}
\end{lemma}

\begin{proof}\hfill
	\begin{enumerate}
		\item By induction on $\trm{M}$.
		\item By induction on the definition of $\trm{M \rw_\prob M'}$.
		\item By induction on $\trm{M}$.
		Cases:
		\begin{itemize}
			\item \emph{Variable}, \ie\ $\trm{M = x}$ (as $\trm{x} \in \fv{M}$), and then $\trm{M[N +a P/x]} = \trm{N +a P} = \trm{M[N/x] +a M[P/x]}$.

			\item \emph{Application}, \ie\ $\trm{M = M_1M_2}$.
			Since $\trm{x \in {\fv{M}}}$ there are three cases:
			\begin{itemize}
				\item $\trm{x \in {\fv{M_1}} \cup \fv{M_2}}$ and then, by \ih, $\trm{M_i[N +a P/x]} \rw_\prob^* \trm{M_i[N/x] +a M_i[P/x]}$ for all $i \in \{1,2\}$.
				So,
				$\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] M_2[N +a P/x]} \rw_\prob^* \trm{(M_1[N/x] +a M_1[P/x])(M_2[N/x] +a M_2[P/x])} \allowbreak\rw_\prob^* \trm{M_1[N/x]M_2[N/x] +a M_1[P/x]M_2[P/x]} = \trm{M[N/x] +a M[P/x]}$.

				\item $\trm{x \in {\fv{M_{1}}}}$ and $\trm{x \notin {\fv{M_2}}}$ and then, by \ih, $\trm{M_1[N +a P/x]} \rw_\prob^* \trm{M_1[N/x] +a M_1[P/x]}$.
				So,
				$\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] M_2} \rw_\prob^* \trm{(M_1[N/x] +a M_1[P/x])M_2} \allowbreak\rw_\prob^* \trm{M_1[N/x]M_2 +a M_1[P/x]M_2} = \trm{M[N/x] +a M[P/x]}$.

				\item $\trm{x \notin {\fv{M_{1}}}}$ and $\trm{x \in {\fv{M_2}}}$: analogous to the previous case.
			\end{itemize}

			\item \emph{Abstraction}, \ie\ $\trm{M = \y.M'}$.
			By \ih, as $\trm{x \in {\fv{M}} \subseteq \fv{M'}}$ $\trm{M'[N +a P/x]} \rw_\prob^* \trm{M'[N/x] +a M'[P/x]}$
			So, $\trm{M [N +a P/x] = \y.(M'[N +a P/x]) \rw_\prob^* \y.(M'[N/x] +a M'[P/x]) \rw_\prob \y.(M'[N/x]) +a \y.(M'[P/x])}$ $= \trm{M[N/x] +a M[P/x]}$.
			
			\item \emph{Superposition}, \ie\ $\trm{M = M_1 +b M_2}$. 
			By \ih, $\trm{M_i[N +a P/x]} \rw_\prob^* \trm{M_i[N/x] +a M_i[P/x]}$ for all $i \in \{1,2\}$.
			Since $a <_M b$ by hypothesis, $\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] +b M_2[N +a P/x]} \rw_\prob^* \trm{(M_1[N/x] +a M_1[P/x]) 
				\allowbreak+b (M_2[N/x] +a M_2[P/x])} \rw_\prob
			\trm{((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[N/x]) +a ((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[P/x])}
			\allowbreak\rw_\prob^* 
			\trm{((M_1[N/x]\allowbreak+b M_2[N/x]) +a (M_1[P/x] \allowbreak+b M_2[N/x]))  +a ((M_1[N/x] \allowbreak+b M_2[P/x]) +a (M_1[P/x] \allowbreak+b M_2[P/x])) }
			\allowbreak\rw_\prob^*
			\trm{(M_1[N/x] +b M_2[N/x]) +a (M_1[P/x] +b M_2[P/x])} = \trm{M[N/x] +a M[P/x]}$.

			\item \emph{Superposition}, \ie\ $\trm{M = M_1 +b M_2}$.
			Since $\trm{x \in {\fv{M}}}$ there are three cases:
			\begin{itemize}
				\item $\trm{x \in {\fv{M_1}} \cup \fv{M_2}}$ and then, by \ih, $\trm{M_i[N +a P/x]} \rw_\prob^* \trm{M_i[N/x] +a M_i[P/x]}$ for all $i \in \{1,2\}$.
				Since $a <_M b$ by hypothesis, $\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] +b M_2[N +a P/x]} \rw_\prob^* \trm{(M_1[N/x] +a M_1[P/x]) 
					\allowbreak+b (M_2[N/x] +a M_2[P/x])} \rw_\prob
				\trm{((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[N/x]) +a ((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[P/x])}
				\allowbreak\rw_\prob^* 
				\trm{((M_1[N/x]\allowbreak+b M_2[N/x]) +a (M_1[P/x] \allowbreak+b M_2[N/x]))  +a ((M_1[N/x] \allowbreak+b M_2[P/x]) +a (M_1[P/x] \allowbreak+b M_2[P/x])) }
				\allowbreak\rw_\prob^*
				\trm{(M_1[N/x] +b M_2[N/x]) +a (M_1[P/x] +b M_2[P/x])} = \trm{M[N/x] +a M[P/x]}$.
				
				\item $\trm{x \in {\fv{M_{1}}}}$ and $\trm{x \notin {\fv{M_2}}}$ and then, by \ih, $\trm{M_1[N +a P/x]} \rw_\prob^* \trm{M_1[N/x] +a M_1[P/x]}$.
				
				Since $a <_M b$ by hypothesis, $\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] +b M_2} \rw_\prob^* \trm{(M_1[N/x] +a M_1[P/x]) 
					\allowbreak+b M_2} \rw_\prob
				\trm{((M_1[N/x]\allowbreak+b M_2) +a (M_1[P/x] \allowbreak+b M_2) }
				= \trm{M[N/x] +a M[P/x]}$.

				\item $\trm{x \notin {\fv{M_{1}}}}$ and $\trm{x \in {\fv{M_2}}}$: analogous to the previous case.
			\end{itemize}

			\item \emph{Box}, \ie\ $\trm{M} = \trm{!b.M'}$. 
			We can suppose without loss of generality that $b \neq a$.
			By \ih, as $\trm{x \in {\fv{M}} = \fv{M'}}$ $\trm{M'[N +a P/x]} \rw_\prob^* \trm{M'[N/x] +a M'[P/x]}$
			So, $\trm{M [N +a P/x] = !b.(M'[N +a P/x]) \rw_\prob^* !b.(M'[N/x] +a M'[P/x]) \rw_\prob !b.(M'[N/x]) +a !b.(M'[P/x])}$ $= \trm{M[N/x] +a M[P/x]}$.
			\qedhere
		\end{itemize}
	\end{enumerate}
\end{proof}

\begin{remark}
	If $\trm{x \notin {\fv{M}}}$ then $\trm{M[N +a P/x] \not\rw_\prob^* M[N/x] +a M[P/x]}$.
	For instance, take $\trm{M} = \trm{y} \neq \trm{x}$: then, $\trm{M[N +a P/x]} \allowbreak= y \neq \trm{y +a y} = \trm{M[N/x] +a M[P/x]}$ where $\trm{y}$ is $\prob$-normal.
	In fact, if $\trm{x \notin {\fv{M}}}$ then $\trm{M[N/x] +a M[P/x] \allowbreak= M +a M \rw_\prob M = M[N +a P/x]}$.
\end{remark}

Two problematic cases to join critical pairs: the first two ones mean that we cannot use commutation and Hindley--Rosen lemma to prove that $\rw$ is confluent;
the second two ones suggest that the proof of confluence of $\rw$ is delicate (see the remark above).

$
\begin{array}{c@{~}c@{~}c}
\trm{(\x.!a.M)P} &\rw_\prob & \trm{(!a.(\x. M))P}
\\	\dw_\beta && \dw_\prob
\\ \trm{(!a.M)[P/x]} & & \trm{!a.(\x. M)P}
\\	= & \rotatebox[origin=c]{210}{$\rw_\beta$}
\\	\trm{!a.M[P/x]} &&
\end{array}
$
\qquad
$
\begin{array}{c@{~}c@{~}c}
\trm{(\x.(N +a M))P} &\rw_\prob & \trm{((\x.N) +a (\x. M))P}
\\	\dw_\beta && \dw_\prob
\\ \trm{(N +a M)[P/x]} & & \trm{(\x.N)P +a (\x. M)P}
\\	= & \rotatebox[origin=c]{210}{$\rw_\beta^+$}
\\	\trm{N[P/x] +a M[P/x]} &&
\end{array}
$


%Two problematic cases to join critical pairs: the first two ones mean that we cannot use commutation and Hindley--Rosen lemma to prove that $\rw$ is confluent;
%the second two ones suggest that the proof of confluence of $\rw$ is delicate (see the remark above);
%
%$
%\begin{array}{c@{~}c@{~}c}
%\trm{(\x.!a.M)P} &\rw_\prob & \trm{(!a.(\x. M))P}
%\\	\dw_\beta && \dw_\prob
%\\ \trm{(!a.M)[P/x]} & & \trm{!a.(\x. M)P}
%\\	= & \rotatebox[origin=c]{210}{$\rw_\beta$}
%\\	\trm{!a.M[P/x]} &&
%\end{array}
%$
%\qquad
%$
%\begin{array}{c@{~}c@{~}c}
%\trm{(\x.(N +a M))P} &\rw_\prob & \trm{((\x.N) +a (\x. M))P}
%\\	\dw_\beta && \dw_\prob
%\\ \trm{(N +a M)[P/x]} & & \trm{(\x.N)P +a (\x. M)P}
%\\	= & \rotatebox[origin=c]{210}{$\rw_\beta^+$}
%\\	\trm{N[P/x] +a M[P/x]} &&
%\end{array}
%$
%
%\begin{align*}
%\trm{x \in {\fv{M}}} \qquad & & & \qquad \trm{x \notin {\fv{M}}} \\
%\begin{array}{c@{~}c@{~}c}
%\trm{(\x.M)(N +a P)} &\rw_\prob & \trm{((\x.M)N) +a ((\x. M)P)}
%\\	\dw_\beta && \dw_{\beta^+}
%\\ \trm{M[(N +a P)/x]} & \rw_\prob^* & \trm{M[N/x] +a M[P/x]}
%\end{array}
%&&&
%\begin{array}{c@{~}c@{~}c}
%\trm{(\x.M)(N +a P)} &\rw_\prob & \trm{((\x.M)N) +a ((\x. M)P)}
%\\	\dw_\beta && \dw_{\beta^+}
%\\ \trm{M} & {}_\prob \lw & \trm{M +a M}
%\end{array}
%\end{align*}

\hrule

\begin{definition}
A \emph{labeled} term $\trm{N*}$ is a term $N$ with chosen $\beta$-redexes annotated as $\trm{(\x.M)*P}$. The \emph{labeled reduct} $\trm{<N*>}$ of a labeled term is defined by induction on $N$ as follows:
\begin{align*}
	\trm{<(\x.N)*M>} &= \trm{<N>[<M>/x]}
\\	\trm{<x>}		&= x
\\	\trm{<\x.N>}	&= \trm{\x.<N>}
\\	\trm{<NM>} 		&= \trm{<N><M>}
\\	\trm{<N+aM>}	&= \trm{<N>+a<M>}
\\	\trm{<!a.N>}	&= \trm{!a.<N>}
\end{align*}
A \emph{parallel $\beta$-step} is a reduction $N\rwp_\beta\trm{<N*>}$ for some labelling $\trm{N*}$ of $N$.
\end{definition}

We write $\trm{N*}\rwp_\beta\trm{<N*>}$ for the specific parallel step indicated by the labeling $\trm{N*}$. Observe that $\trm{<N*>}$ is a regular unlabeled term, since all labels are removed in the reduction.

\begin{remark}[Reflexivity of $\rwp_\beta$]
\label{rmk:reflexivity}
	For every term $\trm{N}$, one has $\trm{N} \rwp_\beta \trm{N}$. 
	Indeed, if $\trm{N*}$ is the empty labeling (which does not annotate any $\beta$-redex), then $\trm{N} = \trm{<N*>}$.
\end{remark}

\begin{lemma}
A parallel $\beta$-step $N\rwp_\beta M$ is a $\beta$-reduction $N\rws_\beta M$.
\end{lemma}

\begin{proof}
	Since $N\rwp_\beta M$ means that $\trm{M} = \trm{<N*>}$ for some labeling $\trm{N*}$ of $\trm{N}$, we prove that $\trm{N} \rws_\beta \trm{<N*>}$ for any labeling $\trm{N*}$ of $\trm{N}$, by induction on $\trm{N}$.
	Cases:
	\begin{itemize}
		\item \emph{Variable}, \ie\ $\trm{N} = x$. 
		Then $\trm{x*} = x$ and $\trm{<x*>} = x$.
		Therefore, $N = x = \trm{<N*>}$ and so $N \rws_\beta \trm{<N*>}$.
		
		\item \emph{Abstraction}, \ie\ $\trm{N} = \trm{\x.M}$.
		Then $\trm{N*} = \trm{\x.M*}$ and $\trm{<N*>} = \trm{\x.<M*>}$.
		By \ih, $\trm{M} \rws_\beta \trm{<M*>}$ and so $\trm{N} = \trm{\x.M} \rws_\beta \trm{\x.<M*>} = \trm{<N*>}$.
		
		\item \emph{Application}, \ie\ $\trm{N} = \trm{MP}$.
		There are two sub-cases:
		\begin{itemize}
			\item $\trm{M} \neq \trm{(\x.Q)*}$. 
			Then $\trm{N*} = \trm{M*P*}$ and $\trm{<N*>} = \trm{<M*><P*>}$.
			By \ih, $\trm{M} \rws_\beta \trm{<M*>}$ and $\trm{P} \rws_\beta \trm{<P*>}$, so $\trm{N} = \trm{MP} \rws_\beta \trm{<M*><P*>} = \trm{<N*>}$.
			
			\item $\trm{M} = \trm{(\x.Q)*}$.
			Then $\trm{N*} = \trm{(\x.Q*)*P*}$ and $\trm{<N*>} = \trm{<Q*>[<P*>/x]}$.
			By \ih, $\trm{Q} \rws_\beta \trm{<Q*>}$ and $\trm{P} \rws_\beta \trm{<P*>}$, so $\trm{N} = \trm{(\x.Q)P} \rw_\beta \trm{Q[P/x]} \rws_\beta \trm{<Q*>[<P*>/x]} = \trm{<N*>}$.
		\end{itemize}
	
		\item \emph{Superposition}, \ie\ $\trm{N} = \trm{M +a P}$.
		Then $\trm{N*} = \trm{M* +a P*}$ and $\trm{<N*>} = \trm{<M*>+a<P*>}$.
		By \ih, $\trm{M} \rws_\beta \trm{<M*>}$ and $\trm{P} \rws_\beta \trm{<P*>}$, so $\trm{N} = \trm{M +a P} \rws_\beta \trm{<M*> +a <P*>} = \trm{<N*>}$.
		
		\item \emph{Box}, \ie\ $\trm{N} = \trm{!a. M}$. 
		Analogous to the abstraction case.
		\qedhere
	\end{itemize}
\end{proof}

\begin{definition}
A \emph{labelled} $\prob$-reduction $\trm{N*}\rwb_\prob\trm{M*}$ is a $\prob$-reduction of one of the forms
\[
	\trm{(\x.N+aM)*P} \rws_\prob \trm{(\x.N)*P+a(\x.M)*P}
\qquad
	\trm{(\x.!a.N)*M} \rws_\prob \trm{!a.(\x.N)*M}
\]
or a single $\prob$-step $\rw_\prob$ on unlabeled constructors in $\trm{N*}$.
\end{definition}

\begin{lemma}
\label{lem:parallel p-reduction}
Reduction to normal form in $\rwb_\prob$ is equal to $\rwn_\prob$.
\end{lemma}

\begin{proof}
Observe that $\rw_\prob$ and $\rwb_\prob$ have the same normal forms. Then since $\rwb_\prob\,\subseteq\,\rws_\prob$ we have $\rwbn_\prob\,\subseteq\,\rwn_\prob$. Conversely, let $N\rwn_\prob M$. On this reduction, let $P\rw_\prob Q$ be the first step such that $P\not\rwb_\prob Q$. Then there is an $R$ such that $P\rwb_\prob R$ and $Q\rw_\prob R$. Note that we have $N\rwbs_\prob R$. By confluence, $R\rwn_\prob M$, and by induction on the sum length of paths in $\rw_\prob$ from $R$ (smaller than from $N$) we have $R\rwbn_\prob M$, and hence $N\rwbn_\prob M$.
	%On labeled terms, $\rwb_\prob \,\subseteq\, \rws_\prob$ and thus $\rwbn_\prob \,\subseteq\, \rwn_\prob$ {\color{red}(incomplete; how about:) if $N\rw_\prob M$ but $N\not\rwb_\prob M$ then for some $P$ we have $N\rwb_\prob$ and $M\rws_\prob P$;} hence $\rwbn_\prob \,=\, \rwn_\prob$.
%	In particular, $\trm{N*} \rwbn_\prob \trm{M*}$ if and only if $\trm{N*} \rwn_\prob \trm{M*}$.
\end{proof}

\begin{lemma}
\label{lem:parallel p - parallel beta}
If $\trm{N*}\rwb_\prob\trm{M*}$ then $\trm{<N*>}=_\prob\trm{<M*>}$.
\end{lemma}

\begin{lemma}
\label{lem:exhaustive p - parallel beta}
If $\trm{N*}\rwn_\prob\trm{M*}$ then $\trm{<N*>}=_\prob\trm{<M*>}$
\end{lemma}

\begin{proof}
Using \Cref{lem:parallel p-reduction} we decompose $\trm{N*}\rwn_\prob\trm{M*}$ as
\[
	\trm{N*}=\trm{N_1*}\rwb_\prob\trm{N_2*}\rwb_\prob \dots \rwb_\prob \trm{N_n*}=\trm{M*}
\]
for which \Cref{lem:parallel p - parallel beta} gives $\trm{<N_i*>}=_\prob\trm{<N_{i+1}*>}$.
\end{proof}

\begin{definition}
A \emph{complete} reduction step $\rwp$ is a parallel $\beta$-step followed by $\prob$-reduction to normal form:
\[
	N\rwp M^\prob \quad\coloneq\quad N\rwp_\beta M\rwn_\prob M^\prob~.
\]
\end{definition}

\begin{lemma}[Mapping on $\prob$-normal forms]
\label{lem:p to complete reduction}
Any reduction step $N\rw M$ maps onto a complete step $N^\prob\rwp M^\prob$ on $\prob$-normal forms.
\end{lemma}

\begin{proof}
The case of a $\prob$-step $N\rw_\prob M$ is immediate, since $N^\prob=M^\prob$ and $\rwp_\beta$ is reflexive (\Cref{rmk:reflexivity}). 
For a $\beta$-step $N\rw_\beta M$ we label the reduced redex in $N$ to get $\trm{N*}\rwp_\beta\trm{<N*>}=M$. 
Let $\trm{P*}=(\trm{N*})^\prob$ be the (labeled) $\prob$-normal form of $\trm{N*}$. 
Then \Cref{lem:exhaustive p - parallel beta} gives $M=\trm{<N*>}=_\prob\trm{<P*>}$, illustrated below.
\[
\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  \trm{N*} && \trm{P*} \\[20pt] \\ \trm{M=<N*>} & =_\prob & \trm{<P*>} \\
	};
	\draw[rwn] (m-1-1) --node[above]{$\scriptstyle\prob$} (m-1-3);
	\draw[rwp] (m-1-1) --node[left] {$\scriptstyle\beta$} (m-3-1);
	\draw[rwp] (m-1-3) --node[right]{$\scriptstyle\beta$} (m-3-3);
\end{tikzpicture}
\]
By confluence and strong normalization of $\rw_\prob$ then $\trm{<P*>}^\prob=M^\prob$. The complete reduction $N^\prob\rwp M^\prob$ is then given by $N^\prob\rwp_\beta\trm{<P*>}\rwn_\prob M^\prob$.
\end{proof}

\begin{lemma}
\label{lemma:application-parallel-beta}
	If $\trm{M} \rwp_\beta \trm{M'}$ and $\trm{N} \rwp_\beta \trm{N'}$, then $\trm{MN} \rwp_\beta \trm{M'N'}$.
\end{lemma}

\begin{proof}
	Since $\trm{M} \rwp_\beta \trm{<M*>} = M'$ and $\trm{N} \rwp_\beta \trm{<N*>} = N'$ for some labelings $\trm{M*}$ and $\trm{N*}$ of $M$ and $N$ respectively, let $\trm{(MN)*}$ be the labeling of $\trm{MN}$ obtained by putting together the labelings $\trm{M*}$ and $\trm{N*}$.
	Clearly, $\trm{MN} \rwp_\beta \trm{<(MN)*>} = \trm{<M*><N*>} = M'N'$.
\end{proof}

\begin{lemma}[Full labeling]
\label{lemma:full-development}
	Let $\trm{M}$ be a term, and $\trm{M*}$ be its \emph{full labeling}, which labels every $\beta$-redex in $\trm{M}$.
	\begin{enumerate}
		\item\label{lemma:full-development-beta} If $\trm{M} \rwp_\beta \trm{N}$ then $\trm{N} \rwp_\beta \trm{<M*>}$.
		\item\label{lemma:full-development-complete} If $\trm{M} \rwp \trm{N}$ then $\trm{N} \rwp \trm{<M*>}^\prob$.
	\end{enumerate}
\end{lemma}
\begin{proof}\hfill
	\begin{enumerate}
		\item	By induction on $\trm{M}$.
		Cases:
		\begin{itemize}
			\item \emph{Variable}, \ie\ $\trm{M} = x$.
			Then $\trm{N} = x$ since $x$ is normal. 
			Moreover, $\trm{M*} = x$ and hence $\trm{<M*>} = x$.
			Therefore, $\trm{N} \rwp \trm{<M*>}$ because $\rwp_\beta$ is reflexive (\Cref{rmk:reflexivity}).
			
			\item \emph{Abstraction}, \ie\ $\trm{M} = \trm{\x.P}$.
			Then $\trm{N} = \trm{\x.<P^\circ>}$ for some labeling $\trm{P^\circ}$ of $\trm{P}$.
			Since $\trm{P} \rwp_\beta \trm{<P^\circ>}$, one has $\trm{<P^\circ>} \rwp_\beta \trm{<P*>}$ and hence $\trm{N} = \trm{\x.<P^\circ>} \rwp_\beta \trm{\x.<P*>} = \trm{<M*>}$.
			
			\item \emph{Application}, \ie\ $\trm{M} = \trm{PQ}$.
			Let $\trm{M^\circ}$ be a labeling of $\trm{M}$ such that $N = \trm{<M^\circ>}$.
			There are three subcases:
			\begin{itemize}
				\item $\trm{M} \neq \trm{(\x.R)Q}$. 
				Then $\trm{N} = \trm{<P^\circ><Q^\circ>}$.
				By \ih\ (since $\trm{P} \rwp_\beta \trm{<P^\circ>}$ and $\trm{Q} \rwp_\beta \trm{<Q^\circ>}$), one has $\trm{<P^\circ>} \rwp_\beta \trm{<P*>}$ and $\trm{<Q^\circ>} \rwp_\beta \trm{<Q*>}$.
				Therefore, by \Cref{lemma:application-parallel-beta}, $\trm{N} \rwp_\beta \trm{<P*><Q*>} = \trm{<M*>}$, where the equality holds because $\trm{M} \neq \trm{(\x.R)Q}$.
				
				\item $\trm{M^\circ} = \trm{(\x.R)*Q}$.
				Then $\trm{N} = \trm{<R^\circ>[<Q^\circ>/x]}$
				
				\item $\trm{M^\circ} \neq \trm{(\x.R)*Q}$ but $\trm{M} = \trm{(\x.R)Q}$. 
				Then $\trm{N} = \trm{<P^\circ><Q^\circ>}$.
				By \ih\ (since $\trm{P} \rwp_\beta \trm{<P^\circ>}$ and $\trm{Q} \rwp_\beta \trm{<Q^\circ>}$), one has $\trm{<P^\circ>} \rwp_\beta \trm{<P*>}$ and $\trm{<Q^\circ>} \rwp_\beta \trm{<Q*>}$.
			\end{itemize}
		\end{itemize}
	
		\item Since $\trm{M} \rwp \trm{N}$, then $\trm{M} \rwp_\beta \trm{P} \rwn_\prob \trm{N}$ for some term $\trm{P}$ such that $\trm{N} = \trm{P}^\prob$.
		By \Cref{lemma:full-development}.\ref{lemma:full-development-beta}, $\trm{P} \rwp_\beta \trm{<M*>}$ and hence $\trm{P} \rwp \trm{<M*>^\prob}$.
		According to \Cref{lem:p to complete reduction}, $\trm{N} = \trm{P}^\prob \rwp \trm{(<M*>^\prob)^\prob} = \trm{<M*>^\prob}$.
		\qedhere
	\end{enumerate}
\end{proof}

\begin{corollary}[Complete reduction is diamond]
\label{cor:complete diamond}
%Complete reduction has the diamond property: if
	If $P\rwpleft N\rwp M$ then $P\rwp Q\rwpleft M$ for some $Q$.
\end{corollary}

\begin{proof}
	By \Cref{lemma:full-development}.\ref{lemma:full-development-complete}, $P\rwp \trm{<M*>} \rwpleft M$ where $\trm{M*}$ is the full labeling of $\trm{M}$.
\end{proof}

\begin{figure}
\[
\begin{array}{cccc}
\vcenter{\hbox{\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  \trm{N*} && \trm{M*} \\[20pt] \\ \trm{<N*>} & =_\prob & \trm{<M*>} \\
	};
	\draw[rwb] (m-1-1) --node[above]{$\scriptstyle\prob$} (m-1-3);
	\draw[rwp] (m-1-1) --node[left] {$\scriptstyle\beta$} (m-3-1);
	\draw[rwp] (m-1-3) --node[right]{$\scriptstyle\beta$} (m-3-3);
\end{tikzpicture}}}
&
\vcenter{\hbox{\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  \trm{N*} && \trm{M*} \\[20pt] \\ \trm{<N*>} & =_\prob & \trm{<M*>} \\
	};
	\draw[rwn] (m-1-1) --node[above]{$\scriptstyle\prob$} (m-1-3);
	\draw[rwp] (m-1-1) --node[left] {$\scriptstyle\beta$} (m-3-1);
	\draw[rwp] (m-1-3) --node[right]{$\scriptstyle\beta$} (m-3-3);
\end{tikzpicture}}}
&
\vcenter{\hbox{\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  \trm{N} &[20pt] & \trm{M} \\[20pt] \\ N^\prob && M^\prob \\
	};
	\draw[rw]  (m-1-1) -- (m-1-3);
	\draw[rwn] (m-1-1) --node[left] {$\scriptstyle\prob$} (m-3-1);
	\draw[rwn] (m-1-3) --node[right]{$\scriptstyle\prob$} (m-3-3);
	\draw[rwx] (m-3-1) -- (m-3-3);
\end{tikzpicture}}}
&
\vcenter{\hbox{\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  \trm{N} &[20pt] & \trm{M} \\[20pt] \\ \trm{P} && \trm{Q} \\
	};
	\draw[rwp] (m-1-1) -- (m-1-3);
	\draw[rwp] (m-1-1) -- (m-3-1);
	\draw[rwp] (m-1-3) -- (m-3-3);
	\draw[rwp] (m-3-1) -- (m-3-3);
\end{tikzpicture}}}
\\ \\
  \text{\Cref{lem:parallel p - parallel beta}}
& \text{\Cref{lem:exhaustive p - parallel beta}}
& \text{\Cref{lem:p to complete reduction}}
& \text{\Cref{cor:complete diamond}}
\end{array}
\]
\caption{Diagrams for the lemmata leading up to confluence}
\label{fig:confluence diagrams}
\end{figure}


\begin{theorem}
\label{thm:confluence}
Reduction $\rw$ is confluent.
\end{theorem}

\begin{proof}
By the following diagram. For the top and left areas, by Lemma~\ref{lem:p to complete reduction} any reduction path $N\rws M$ maps onto one $N^\prob \rwx M^\prob$. The main square follows by the diamond property of complete reduction, \Cref{cor:complete diamond}.
\[
\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  N &[10pt] &[18pt] M &[10pt] \\[10pt] & N^\prob && M^\prob \\[18pt] P \\[10pt] & P^\prob && Q \\
	};
	\draw[rws] (m-1-1) -- (m-1-3);
	\draw[rws] (m-1-1) -- (m-3-1);
	\draw[rwn] (m-1-1) --node[below left =-2pt] {$\scriptstyle\prob$} (m-2-2);
	\draw[rwn] (m-1-3) --node[above right=-2pt]{$\scriptstyle\prob$} (m-2-4);
	\draw[rwn] (m-3-1) --node[below left =-2pt] {$\scriptstyle\prob$} (m-4-2);
	\draw[rwx] (m-2-2) -- (m-2-4);
	\draw[rwx] (m-2-2) -- (m-4-2);
	\draw[rwx] (m-2-4) -- (m-4-4);
	\draw[rwx] (m-4-2) -- (m-4-4);
\end{tikzpicture}
\]
\end{proof}


\hrule

\newcommand\proj[3]{\pi^{#1}_{#2}(\trm{#3})}

\section{Projective reduction}

The reduction $\rw_\prob$ evaluates probabilistic sums purely by rewriting. Here we look at an alternative \emph{projective} notion of reduction, which conforms more closely to the intuition that $\trm{!a}$ generates a probabilistic event that is consumed by $\trm{+a}$.

For projective reduction we distinguish a global, meta-level probabilistic sum $+$ from the internal, object-level probabilistic sum $\trm{N+{}M=!a.N+aM}$. Let $N^+$ denote the term $N$ with every top-level internal sum $\trm{+{}}$ evaluated as an external sum; formally:
\[
	\trm{(N+{}M)}^+=N^+\!+M^+ \qquad\qquad N^+=N \quad(N\neq \trm{M+{}P})~.
\]
{\color{red}(NOTE: The evaluation $N^+$ should be discussed earlier, to complete our reduction $\rw_\prob$ by linking our syntactic $\trm{+{}}$ to semantic probabilistic sums.)}

\begin{definition}
The \emph{$a$-projections} $\proj a0N$ and $\proj a1N$ are defined as follows, where $a\neq b$.
\begin{align*}
	\proj a0{N+aM} &= \proj a0N
\\	\proj a1{N+aM} &= \proj a1M
\\	\proj ai{!a.N} &= \trm{!a.N}
\\	\proj aix      &= x
\\	\proj ai{\x.N} &= \x.\proj aiN
\\	\proj ai{NM}   &= (\proj aiN)(\proj aiM)
\\	\proj ai{N+bM} &= (\proj aiN)\trm{+b}(\proj aiM)
\\	\proj ai{!b.N} &= \trm{!b.}\proj aiN
\end{align*}
\end{definition}

\begin{definition}
A \emph{head context} $H[\,]$ is given by the following grammar.
\[
	H[\,] \coloneqq [\,] ~\mid~ \lambda x.H[\,] ~\mid~ H[\,]N
\]
\end{definition}


\begin{definition}
\emph{Projective} reduction $\rw_\pi$ is the reduction step
\[
	\trm{!a.N} ~\rw_\pi~ \proj a0N + \proj a1N
\]
closed under head context:
\[
	N\rw_\pi M \quad\implies\quad H[N]\rw_\pi H[M]~.
\]
\end{definition}


Observe that projective reduction is not a rewrite relation, as it applies only in head contexts---that is, we do not evaluate inside arguments or under other probabilistic events $\trm{!a}$ or sums $\trm{+a}$.

\begin{proposition}
If $N\rw_\pi M$ then there is a $P$ such that $N\rws_\prob P$ with $P^+=M$.
\end{proposition}


\bibliographystyle{plain}
\bibliography{biblio}
\addcontentsline{toc}{section}{References}

\end{document}

%============================================================

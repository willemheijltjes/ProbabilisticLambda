\documentclass{llncs}

\let\proof\relax %To avoid incompatibility between llncs and amsthm
\let\endproof\relax %To avoid incompatibility between llncs and amsthm

\usepackage[hidelinks]{hyperref}
\usepackage{amsmath,amssymb,amsthm,mathtools,stmaryrd}

\usepackage{nicefrac}

%\usepackage{fullpage}

\usepackage{xcolor}
\usepackage{tikz}
  \usetikzlibrary{arrows.meta}
  \usetikzlibrary{calc}
  \usetikzlibrary{matrix}
\usepackage{cleveref}
\usepackage{proof}

\makeatletter

%% theorem environments

\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{rmrk}[defn]{Remark}
%%
\theoremstyle{plain}
\newtheorem{conj} [defn]{Conjecture}
\newtheorem{cor}  [defn]{Corollary}
\newtheorem{lem}  [defn]{Lemma}
\newtheorem{prop} [defn]{Proposition}
\newtheorem{thm}  [defn]{Theorem}
%%

%text
\newcommand{\ie}{\textit{i.e.}}
\newcommand{\ih}{\textit{i.h.}}

% coloneqq
\newcommand*\coloneq{
 \mathrel{%
  \rlap{\raisebox{0.3ex}{$\m@th\cdot$}}%
        \raisebox{-0.3ex}{$\m@th\cdot$}%
 {=}}}
\newcommand*\coloneqq{
 \mathrel{%
  \rlap{\raisebox{0.3ex}{$\m@th\cdot$}}%
        \raisebox{-0.3ex}{$\m@th\cdot$}%
  \rlap{\raisebox{0.3ex}{$\m@th\cdot$}}%
        \raisebox{-0.3ex}{$\m@th\cdot$}%
 {=}}}

% vcenter
\newcommand\vc[1]{\vcenter{\hbox{$#1$}}}

% Small operators:

\newcommand\smallbin[1]{\mathchoice
      {\mathbin{\raise.2ex \hbox{$\scriptstyle      #1$}}}%
      {\mathbin{\raise.2ex \hbox{$\scriptstyle      #1$}}}%
      {\mathbin{\raise.12ex\hbox{$\scriptscriptstyle#1$}}}%
      {\mathbin{           \hbox{$\scriptscriptstyle#1$}}}}%

\newcommand\smallsquare{\mathchoice{{\scriptstyle\square}}{{\scriptstyle\square}}{{\scriptscriptstyle\square}}{{\scriptscriptstyle\square}}}

\newcommand\Con{\wedge}
\newcommand\Imp{\rightarrow}

\newcommand\con{\kern1pt{\smallbin\Con}\kern1pt}
\newcommand\imp{\kern1pt{\smallbin\Imp}}


% ===== TERMS AND TYPES

% Probabilistic lambda-calculus
\newcommand\PEL{\Lambda_{\textsf{PE}}}

% Free variables
\newcommand\fv[1]{\mathsf{fv}(\trm{#1})}
\newcommand\fl[1]{\mathsf{fl}(\trm{#1})}

% colours
\colorlet{mgray}{black!40}
\colorlet{lgray}{black!25}
\colorlet{llgray}{black!15}

\colorlet{dblue}{blue!80!black}
\colorlet{dred}{red!80!black}

\colorlet{typecolor}{dblue}
\colorlet{termcolor}{dred}

\newcommand\typecolor{\color{typecolor}}
\newcommand\termcolor{\color{termcolor}}

\newcommand\black{\color{black}}
\newcommand\dblue{\color{dblue}}
\newcommand\dred{\color{dred}}


% types
\newcommand\type[1]{{\let\type@sup@color\termcolor\typecolor\typ{#1}}}
\newcommand\typ[1]{%
  %\vphantom J%
  \let\type@loop=\type@next%
  \type@loop#1,%
}
\newcommand\type@next[1]{%
  \ifx#1,\let\type@loop\type@end\else%
  \ifx#1_\let\type@loop\type@sub\else%
  \ifx#1^\let\type@loop\type@sup\else%
  \ifx#1*\con\else%
  \ifx#1-\kern1pt{\imp}\else%
  #1%
  \fi\fi\fi\fi\fi%
  \type@loop%
}
\newcommand\type@sup@color{}
\newcommand\type@sub[1]{_{#1}\let\type@loop\type@next\type@loop}
\newcommand\type@sup[1]{^{{\type@sup@color #1}}\let\type@loop\type@next\type@loop}
\newcommand\type@vec[1]{\vec{\kern.5pt#1\kern.5pt}\let\type@loop\type@next\type@loop}
\newcommand\type@end{\let\type@sup@color\relax}

% terms
\newcommand\x{\lambda x}
\newcommand\y{\lambda y}
\newcommand\z{\lambda z}

\newcommand\+[1][{}]{\kern1pt{\smallbin\oplus}_{#1}\kern1pt}

\newcommand\lab{\bullet}
\newcommand{\labtwo}{\circ}

\newcommand\ttrm[1]{\smash{\trm{#1}}}

\newcommand\term[1]{{\let\term@typecolor\typecolor\termcolor\trm{#1}}}
\newcommand\trm[1]{%
  \vphantom(%
  \let\term@loop=\term@next%
  \term@loop#1,%
}
\newcommand\term@next[1]{%
  \ifx#1,\let\term@loop\term@end\else%
  \ifx#1:\black\colon\term@typecolor\let\term@loop\term@type\else%
  \ifx#1_\let\term@loop\term@sub\else%
  \ifx#1^\let\term@loop\term@sup\else%
  \ifx#1!\let\term@loop\term@box\else%
  \ifx#1+\let\term@loop\term@prob\else%
  \ifx#1*^\lab\else%
  \ifx#1<\lfloor\else%
  \ifx#1>\rfloor\else%
  \ifx#1..\,\else%
%  \ifx#1\x\lambda x\else%
%  \ifx#1\y\lambda y\else%
%  \ifx#1\z\lambda z\else%
  \ifx#1=\kern1pt{\smallbin=}\kern1pt\else
  #1%
  \fi\fi\fi\fi\fi\fi\fi\fi\fi\fi\fi%\fi\fi\fi%
  \term@loop%
}
\newcommand\term@typecolor{}
\newcommand\term@end{\let\term@typecolor\relax}
\newcommand\term@sub[1]{_{#1}\let\term@loop\term@next\term@loop}
\newcommand\term@sup[1]{^{#1}\let\term@loop\term@next\term@loop}
\newcommand\term@vec[1]{\vec{\kern.5pt#1\kern.5pt}\let\term@loop\term@next\term@loop}
\newcommand\term@prob[1]{\kern1pt\raisebox{-.5pt}{$\overset{\raisebox{-1pt}{$\scriptstyle#1$}}{{\smallbin\oplus}}$}\kern1pt\let\term@loop\term@next\term@loop}
\newcommand\term@type{\let\type@loop=\type@next\type@loop}
\newcommand\term@box[1]{\probox{#1}\let\term@loop\term@next\term@loop}

%\newcommand\probox[1]{\tikz[baseline=(a.base)]\node[draw,line width=.6pt,inner sep=2pt,minimum height=10pt,minimum width=10pt](a){\makebox[0pt][c]{$\scriptstyle #1\vphantom)$}};}

\newcommand\probox[1]{\begin{tikzpicture}[baseline=0]\node[anchor=base](a){$\scriptstyle #1\vphantom)$};\draw[line width=.6pt] (-5pt,-2.5pt) rectangle (5pt,7.5pt);\end{tikzpicture}}


% label judgments
\newcommand{\labjudg}[2]{#1\vdash_{L} #2}


% rewriting
\newcommand\rw[1][{}]{\stackrel{#1}\rightsquigarrow}
\newcommand\dw{\rotatebox[origin=c]{270}{$\rw$}}
\newcommand\lw{\rotatebox[origin=c]{180}{$\rw$}}
\newcommand\lrw{\rotatebox[origin=c]{180}{$\lw\!\rw$}}
\newcommand\perm{\mathsf p}

\newcommand\confluence[4]{\begin{array}{ccc} \trm{#1} & \rw & \trm{#2} \\ \dw && \dw \\ \trm{#3} & \rw & \trm{#4} \end{array}}

\newcommand\rstrut{\rule{0pt}{13pt}}

\newcommand\SN{\textsf{SN}}

% strategies
\newcommand\cbn{\mathsf{cbn}}
\newcommand\cbv{\mathsf{cbv}}

% translations
\newcommand\uncbv[1]{\llbracket#1\rrbracket_\cbv}
\newcommand\unopen[1]{\llbracket#1\rrbracket_{\mathsf{open}}}
\newcommand\labclose[2]{\lfloor\labjudg{#1}{#2}\rfloor}

% new rewriting

\tikzstyle{implied}=[dashed]
\tikzstyle{rwhead}=[>/.tip={Triangle[open,length=2.5pt,width=4.5pt]},|/.tip={Rectangle[length=.5pt,width=4.5pt]}]
\tikzstyle{rwblack}=[>/.tip={Triangle[length=2.5pt,width=4.5pt]},|/.tip={Rectangle[length=.5pt,width=4.5pt]}]
\tikzstyle{rw} =[line width=.5pt,rwhead,->]
\tikzstyle{rwb}=[line width=.5pt,rwblack,->]
\tikzstyle{rwbs}=[line width=.5pt,rwblack,->.>]
\tikzstyle{rws}=[line width=.5pt,rwhead,->.>]
\tikzstyle{rwn}=[line width=.5pt,rwhead,->.>|]
\tikzstyle{rwbn}=[line width=.5pt,rwblack,->.>|]
\tikzstyle{rwp}=[line width=.5pt,rwhead,->,double]
\tikzstyle{rwx}=[line width=.5pt,rwhead,->.>,double]

\renewcommand\rw{\mathrel{\tikz\draw[rw](0,0)--(10pt,0pt);}}
\newcommand\rwb{\mathrel{\tikz\draw[rwb](0,0)--(10pt,0pt);}}
\newcommand\rwbs{\mathrel{\tikz\draw[rwbs](0,0)--(10pt,0pt);}}
\newcommand\rws{\mathrel{\tikz\draw[rws](0,0)--(10pt,0pt);}}
\newcommand\rwn{\mathrel{\tikz\draw[rwn](0,0)--(10pt,0pt);}}
\newcommand\rwbn{\mathrel{\tikz\draw[rwbn](0,0)--(10pt,0pt);}}
\newcommand\rwp{\mathrel{\tikz\draw[rwp](0,0)--(10pt,0pt);}}
\newcommand\rwx{\mathrel{\tikz\draw[rwx](0,0)--(10pt,0pt);}}

\newcommand\rwpleft{\mathrel{\tikz\draw[rwp](10pt,0pt)--(0,0);}}
\newcommand\rwxleft{\mathrel{\tikz\draw[rwx](10pt,0pt)--(0,0);}}


% rule names

\newcommand\idem{\ensuremath{\mathsf i}}
\newcommand\cancelL{\ensuremath{\mathsf c_1}}
\newcommand\cancelR{\ensuremath{\mathsf c_2}}
\newcommand\plusAbs{\ensuremath{{\smallbin\oplus}\lambda}}
\newcommand\plusArg{\ensuremath{{\smallbin\oplus}\mathsf a}}
\newcommand\plusFun{\ensuremath{{\smallbin\oplus}\mathsf f}}
\newcommand\plusBox{\ensuremath{{\smallbin{\oplus}\smallsquare}}}
%\newcommand\plusL{\ensuremath{\mathsf d_1}}
%\newcommand\plusR{\ensuremath{\mathsf d_2}}
\newcommand\plusL{\ensuremath{{\smallbin\oplus}{\smallbin\oplus}_1}}
\newcommand\plusR{\ensuremath{{\smallbin\oplus}{\smallbin\oplus}_2}}
\newcommand\plusX{\ensuremath{{\smallbin\oplus}{\star}}}
\newcommand\boxVoid{\ensuremath{\not{\kern-2pt\smallsquare}}}
\newcommand\boxAbs{\ensuremath{\smallsquare\lambda}}
\newcommand\boxFun{\ensuremath{\smallsquare\mathsf f}}


\makeatother


%============================================================ FRONTMATTER

\title{Decomposing probabilistic lambda-calculus}

%\author{Ugo Dal Lago, Giulio Guerrieri, and Willem Heijltjes}

\author{
	 Ugo Dal Lago\inst1
\and Giulio Guerrieri\inst2
\and Willem Heijltjes\inst2
}

\authorrunning{U.\ Dal Lago et al.}

\institute{%
Dipartimento di Informatica - Scienza e Ingegneria\\ Universit\`a di Bologna, Bologna, Italy\\
\email{ugo.dallago@unibo.it}\\[10pt]
\and%
Department of Computer Science\\ University of Bath, Bath, UK\\
\email{\{w.b.heijltjes,g.guerrieri\}@bath.ac.uk}
}


%============================================================ DOCUMENT

\begin{document}


\maketitle

\begin{abstract}
A notion of probabilistic lambda-calculus usually comes with a prescribed reduction strategy, typically call-by-name or call-by-value, as the calculus is non-confluent and these strategies yield different results. This is a break with one of the main advantages of lambda-calculus: confluence, which means results are independent from the choice of strategy.

We present a probabilistic lambda-calculus where the probabilistic operator is decomposed into two syntactic constructs: a generator, which represents a probabilistic event; and a consumer, which acts on the term depending on a given event. The resulting calculus, the Probabilistic Event Lambda-Calculus, is confluent, and interprets the call-by-name and call-by-value strategies through different interpretations of the probabilistic operator into our generator and consumer constructs.

We present two notions of reduction, one via fine-grained local rewrite steps, and one by generation and consumption of probabilistic events. Simple types for the calculus are essentially standard, and they convey strong normalization. We demonstrate how we can encode call-by-name and call-by-value probabilistic evaluation.
\end{abstract}

\section{Introduction}

Probabilistic lambda-calculi \cite{...} extend the lambda-calculus with a probabilistic choice operator $N\+[p]M$, which chooses $N$ with probability $p$ and $M$ with probability $1-p$ (throughout this paper, we let $p=0.5$ and will omit it). Duplication of $N\+M$, as is wont to happen in lambda-calculus, raises a fundamental question about its semantics: do the duplicate occurrences represent \emph{the same} probabilistic event, or \emph{different} ones with the same probability? For example, take the formula $\top\+\bot$ that represents a coin flip between boolean values \emph{true} $\top$ and \emph{false} $\bot$. If we duplicate this formula, do the copies represent two distinct coin flips with possibly distinct outcomes, or do these represent a single coin flip that determines the outcome for both copies? Put differently again, when we duplicate $\top\+\bot$, do we duplicate the \emph{event}, or only its \emph{outcome}?

In probabilistic lambda-calculus, these two interpretations are captured by the evaluation strategies of call-by-name ($\rw_\cbn$), which duplicates events, and call-by-value ($\rw_\cbv$), which evaluates any probabilistic choice before it is duplicated, and thus only duplicates outcomes. Consider the following example, where $=$ tests equality of boolean values.
\[
	(\x.\,x = x)(\top\+\bot) \qquad\begin{array}{ll}\rws_\cbn &\quad \trm{\top\+\bot} \\[5pt] \rws_\cbv &\quad \top\end{array}
\]
This situation is not ideal, for several, related reasons. First, it demonstrates how probabilistic lambda-calculus is non-confluent, negating one of the central properties of the lambda-calculus, and one of the main reasons why it is the prominent model of computation that it is. Second, a probabilistic lambda-calculus must derive its semantics from a prescribed reduction strategy, and its terms only have meaning in the context of that strategy. Third, it becomes difficult to have a mix of different kinds of probabilities, as it would require specialized reduction strategies.

We address these issues by a decomposition of the probabilistic operator into a \emph{generator} $\ttrm{!a}$ and a \emph{choice} $\ttrm{+a}$, as follows.
\[
	\trm{N \+ M} \quad\stackrel\Delta=\quad \trm{!a. N +a M}
\]
Semantically, $\ttrm{!a}$ represents a probabilistic event, that generates a boolean value recorded as $a$. The choice $\ttrm{N+aM}$ is simply a conditional on $a$, choosing $N$ if $a$ is false and $M$ if $a$ is true. Syntactically, $a$ is a boolean variable with an occurrence in $\ttrm{+a}$, and $\ttrm{!a}$ acts as a quantifier, binding all occurrences in its scope. (To capture a non-equal chance, one would attach a probability $p$ to a generator, as $\ttrm{!a}{\kern1pt}_p$, though we will not do so in this paper.) 

The resulting \emph{probabilistic event lambda-calculus} $\PEL$, which we present in this paper, is confluent. Our decomposition allows us to separate duplicating an \emph{event}, represented by the generator $\ttrm{!a}$, from duplicating only its \emph{outcome} $a$, through having multiple choice operators $\trm{+a}$. In this way our calculus may interpret both original strategies, call-by-name and call-by-value, by different translations of standard probabilistic terms into $\PEL$. For the above example, we get the following translations and reductions.
\[
\begin{array}{l@{\quad}l@{\quad}l@{\quad}l@{\quad}l@{\quad}l}
	\cbn: & \trm{(\x.x = x)(!a.\top+a\bot)} & \rw_\beta & \trm{(!a.\top+a\bot)=(!b.\top+b\bot)} & \rws & \top\+\bot
\\[10pt]
	\cbv: & \trm{!a.(\x.x = x)(\top+a\bot)} & \rw_\beta & \trm{!a.(\top+a\bot)=(\top+a\bot)}    & \rws & \top
\end{array}
\]

In this paper, we introduce $\PEL$ and its reduction mechanisms (Section~\ref{...}); we prove confluence (Section~\ref{...}); we give a system of simple types and prove strong normalization for typed terms (Section~\ref{...}); and we demonstrate the two translations to interpret call-by-name and call-by-value evaluation (Section~\ref{...}).


\subsection{Related work}

Probabilistic $\lambda$-calculi are a topic of study since the pioneering works by Saheb-Djaromi~\cite{SahebDjahromi78}, who was the first one to give the syntax and operational semantics of a $\lambda$-calculus with binary probabilistic choice. Giving denotational models enjoying nice properties to probabilistic $\lambda$-calculi has proved to be challenging, as witnessed by the many contributions spanning thirty years: from Jones and Plotkin early study of the probabilistic powerdomain~\cite{JonesPlotkin89}, to Jung and Tix's remarkable observations~\cite{JungTix98}, to the very recent encouraging results by Goubault-Larrecq~\cite{GoubaultLarrecq19}. A particularly well-behaved model for probabilistic $\lambda$-calculus can be obtained by taking a probabilistic variation of Girard's coherent spaces~\cite{DanosEhrhard11}, this way getting fully abstraction~\cite{EPT18}.

On the operational side, one could mention a study about the various ways the operational semantics of a calculus with binary probability choice can be specified, namely by small-step or big step semantics, or by inductively or coinductively defined set of rules~\cite{DalLagoZorzi12}. Termination and complexity analsysis of higher-order probabilistic programs seen as $\lambda$-terms have been studied by way of type systems in a series of recent results about size~\cite{DalLagoGrellois19}, intersection~\cite{BreuvartDalLago18}, and refinement type disciplines \cite{AvanziniDalLagoGhyselen19}. Contextual equivalence on probabilistic $\lambda$-calculi has been studied, and compared with equational theories induced by B\"ohm Trees~\cite{Leventis18}, applicative bisimilarity~\cite{DalLagoSangiorgiAlberti14}, or environmental bisimilarity~\cite{SangiorgiVignudelli16}.

In all the aforementioned works, probabilistic $\lambda$-calculi have been taken as implicitly endowed with a either call-by-name or call-by-value strategies, for the reasons outlined above. There are only a few exceptions, namely some works on Geometry of Interaction~\cite{DLFVY17}, Probabilistic Coherent Spaces~\cite{EhrhardTasson19}, and Standardization~\cite{FaggianRonchi19}, which achieve, in different contexts, a certain degree of independence from the underlying strategy, thus accomodating both the call-by-name and call-by-value strategy. The way this is achieved, however, invariably relies on Linear Logic. This is deeply different from what we do here.

%Our use of the conditional $\ttrm{+a}$ was inspired by recent developments in deep-inference proof theory.


\section{\texorpdfstring{The probabilistic event $\lambda$-calculus $\PEL$}{The probabilistic event lambda-claculus PEL}}


\begin{defn}
The \emph{probabilistic event $\lambda$-calculus} ($\PEL$) is given by the following grammar, with from left to right: a \emph{variable}, an \emph{abstraction}, an \emph{application}, a \emph{(labelled) choice}, and a \emph{(probabilistic) generator}.
\[
	M,N \quad\coloneqq\quad x ~\mid~ \x.N ~\mid~ NM ~\mid~ \trm{N +a M} ~\mid~ \trm{!a.N}
\]
\end{defn}
%
In a term $\trm{\x.M}$ the abstraction $\x$ binds the free occurrences of the variable $x$ in its scope $\trm{M}$, and in $\ttrm{!a.N}$ the generator $\ttrm{!a}$ binds the \emph{label} $a$ in $\trm{M}$. The calculus features a decomposition of the usual probabilistic sum $\trm{\+}$, as follows.
\[
	N\+M \quad\stackrel\Delta=\quad \trm{!a. N +a M}
\]
The generator $\ttrm{!a}$ represents a probabilistic \emph{event}, whose outcome, a binary value $\{0,1\}$ represented by the label $a$, is used by the choice operator $\ttrm{+a}$. That is, $\ttrm{!a}$ flips a coin setting $a$ to $0$ or $1$, and depending on this $\ttrm{N+aM}$ reduces to $N$ respectively $M$. We will use the unlabelled choice $\+$ as the above abbreviation.



\begin{figure}[!ht]
\begin{align}
	(\x.N)M 				&\rw_\beta N[M/x]													\tag{$\beta$}
\\																								\notag
\\	\trm{N +a N}			&\rw_\perm N														\tag{\idem}
\\	\trm{(N +a M) +a P}		&\rw_\perm \trm{N +a P}					\rstrut						\tag{\cancelL}
\\	\trm{N +a (M +a P)}		&\rw_\perm \trm{N +a P}					\rstrut						\tag{\cancelR}
\\																								\notag
\\	\trm{\x.(N +a M)}		&\rw_\perm \trm{(\x.N) +a (\x.M)}									\tag{\plusAbs}
\\	\trm{(N +a M) P}		&\rw_\perm \trm{(NP) +a (MP)}			\rstrut						\tag{\plusFun}
\\	\trm{N (M +a P)}		&\rw_\perm \trm{(NM) +a (NP)}			\rstrut						\tag{\plusArg}
\\	\trm{(N +a M) +b P}		&\rw_\perm \trm{(N +b P) +a (M +b P)} 	\rstrut	&& (a\smallbin<b)	\tag{\plusL}
\\	\trm{N +b (M +a P)}		&\rw_\perm \trm{(N +b M) +a (N +b P)} 	\rstrut	&& (a\smallbin<b)	\tag{\plusR}
%\\	\trm{!b.(N +a M)}		&\rw_\perm \trm{(!b.N) +a (!c M[c/b])}	\rstrut	&& (a\neq b)		\tag{\plusBox}
\\	\trm{!b.(N +a M)}		&\rw_\perm \trm{(!b.N) +a (!b.M)}		\rstrut	&& (a\neq b)		\tag{\plusBox}
\\																								\notag
\\	\trm{!a.N}				&\rw_\perm N 									&& (a\notin N)		\tag{\boxVoid}
\\	\trm{\x.!a.N} 			&\rw_\perm \trm{!a.\x. N}				\rstrut						\tag{\boxAbs}
\\	\trm{(!a.N)M}			&\rw_\perm \trm{!a.(NM)}				\rstrut						\tag{\boxFun}
\end{align}

\caption{Reduction rules}
\label{fig:reduction rules}
\end{figure}


\subsection{Reduction}

Reduction in $\PEL$ will consist of standard $\beta$-reduction $\rw_\beta$ plus an evaluation mechanism for generators and choice operators, which implements probabilistic choice. We will present two such mechanisms: \emph{projective} reduction~$\rw_\pi$ and \emph{permutative} reduction~$\rw_\perm$. While projective reduction implements the given intuition for the generator and choice operator, we relegate it to Section~\ref{sec:projective reduction} and make permutative reduction our main evaluation mechanism, for the reason that it is more fine-grained, and thus more general. 

Permutative reduction is based on the idea that any operator distributes over the labelled choice operator (see the reduction steps in Figure~\ref{fig:reduction rules}), even other choice operators, as below.
\[
	\trm{(N +a M) +b P}	~\sim~ \trm{(N +b P) +a (M +b P)}
\]
To orient this as a rewrite rule, we need to give priority to one label over another. Fortunately, the relative position of the associated generators $\ttrm{!a}$ and $\ttrm{!b}$ provides just that. Then to define $\rw_\perm$, we will want every choice to belong to some generator, and make the order of generators explicit.

\begin{defn}
	The set $\fl{M}$ of \emph{free labels} of a term $\trm{M}$ is defined inductively as follows:
	\begin{align*}
		\fl{x} &= \emptyset & \fl{MN} &= \fl{M} \cup \fl{N}  & \fl{\x.M} &= \fl{M} \\
		\fl{!a.M} &= \fl{M} \smallsetminus \{a\} & \fl{M +a N} &= \fl{M}\cup \fl{N} \cup \{a\}
	\end{align*}
	A term $\trm{M}$ is \emph{label-closed} if $\fl{M} = \emptyset$.
\end{defn}

From now on, we consider only label-closed terms (and we implicitly assume this, unless otherwise stated).
All terms are identified up to renaming of their bound variables and labels.
Given some terms $\trm{M}$ and $\trm{N}$ and a variable $\trm{x}$, $\trm{M[N/x]}$ stands for the capture-avoiding (for both variables and labels) substitution of $\trm{N}$ for the free occurrences of $\trm{x}$ in $\trm{M}$.
We talk of a \emph{representative} $\trm{M}$ of a term when $\trm{M}$ is not considered up to such a renaming.
A representative $\trm{M}$ of a term is \emph{well-labeled} if
%for every sub-term $\trm{!a.N}$ of $\trm{M}$, the label $a$ may occur only in $\trm{N}$ (if at all).
for every occurrence of $\probox a$ in $\trm{M}$ there is no $\probox a$ occurring in its scope.

\begin{defn}[Order for labels]
\label{def:orderlabels}
	Let $\trm{M}$ be a well-labeled representative of a term.
	We define an \emph{order} $<_{{\trm{M}}}$ for the labels occurring in $\trm{M}$ as follows: $a <_{\trm{M}} b$ if and only if $\probox b$ occurs in the scope of $\probox a$.
\end{defn}

\noindent
For a well-labeled and label-closed representative $\trm{M}$, $<_{\trm{M}}$ is a finite tree order.


\begin{defn}
\emph{Reduction} $\rw \,=\, \rw_\beta \cup \rw_\perm$ in $\PEL$ consists of \emph{$\beta$-reduction}~$\rw_\beta$ and \emph{permutative} or \emph{$\perm$-reduction}~$\rw_\perm$, both given in Figure~\ref{fig:reduction rules}. We write $\rws$ for the reflexive-transitive closure of reduction and $\rwn$ for reduction to normal form, and similarly for $\rw_\beta$ and $\rw_\perm$.
%\[
%\begin{array}{rcl}
%	C[(\lambda x.N)M] &\rw_\beta& C[M[N/x]]
%\\	\trm{H[\,!a.N]} &\rw_p& H[N[0/a]] + H[N[1/a]]
%\end{array}
%\]
\end{defn}

\noindent
The introduction briefly sketches two example reductions; a third, complete reduction is given in Figure~\ref{fig:example reduction}.
The crucial feature of $\perm$-reduction is that a choice $\ttrm{+a}$ \emph{does} permute out of the argument position of an application, but a generator $\ttrm{!a}$ does \emph{not}, as below. Since the argument of a redex may be duplicated, this is how we characterize the difference between the \emph{outcome} of a probabilistic event, whose duplicates may be identified, and the event itself, whose duplicates may yield different outcomes.
\[
	\trm{N\,(M +a P)}~\rw_\perm~ \trm{(NM) +a (NP)} 
	\qquad
	\qquad
	\trm{N\,(!a.M)}~\not\rw_\perm~\trm{!a.N\,M}
\]
By inspection of the rewrite rules in Figure~\ref{fig:reduction rules}, we can then characterize the normal forms of $\rw_\perm$ and $\rw$ as follows.

\begin{prop}[Syntactic characterization of normal forms]
The normal forms $P_0$ of $\rw_\perm$, respectively $N_0$ of $\rw$, are given by the following grammars.
\[
	\begin{array}{ccc@{~}c@{~}c@{}l}
		P_0 &\coloneqq& P_1 &\mid& \trm{P_0 \+ P_0}
	\\	P_1	&\coloneqq& x   &\mid& \x.P_1 			 &~\mid~ P_1\,P_0
	\end{array}
	\qquad\qquad
	\begin{array}{ccc@{~}c@{~}c}
		N_0 &\coloneqq& N_1 &\mid& \trm{N_0 \+ N_0}
	\\	N_1	&\coloneqq& N_2 &\mid& \x.N_1
	\\	N_2 &\coloneqq& x	&\mid& N_2\,N_0
	\end{array}
\]
\end{prop}


\begin{figure}[!t]
\newcommand\fit[1]{\makebox[36pt][c]{$#1$}}%
\begin{align*}
	\trm{!a.(\x.x = x)(\top+a\bot)} 
			& \fit{\rw_\perm}	\trm{!a.(\x.x=x)\top~+a~(\x.x=x)\bot}	\tag\plusArg
\\[5pt]		& \fit{\rws_\beta}	\trm{!a.(\top=\top)\,+a\,(\bot=\bot)}
\\[5pt]		& \fit{=}			\trm{!a. \top +a \top}
			  \fit{\rw_\perm} 	\trm{!a. \top} 
			  \fit{\rw_\perm}	\top           						 	\tag{\idem,\boxVoid}
\end{align*}
\caption{Example reduction of the $\cbv$-translation of the term in the introduction.}
\label{fig:example reduction}
\end{figure}

%=====================================================================================

\section{Properties of permutative reduction}

We will prove strong normalization (\SN) and confluence of $\rw_\perm$. For strong normalization, the obstacle is the interaction between different choice operators, which may duplicate each other, and even themselves, creating super-exponential growth.\footnote{This was inferred from only a simple simulation; we would be interested to know a rigorous complexity result.} Fortunately, Dershowitz's \emph{recursive path orders}~\cite{Dershowitz82} seem tailor-made for our situation.

%\subsection{Strong normalization of permutative reduction}

We observe that the set $\PEL$ endowed with $\rw_\perm$ is a (first-order) term rewriting system over a countably infinite set of variables (denoted by $x, y, z, \dots$) and the signature $\Sigma$ given by:
\begin{itemize}
	\item the binary function symbol $\trm{+a}$, for any label $a$;
	\item the unary function symbol $\trm{!a}$, for any label $a$;
	\item the unary function symbol $\trm{\x}$, for any variable $x$;
	\item the binary function symbol $\trm{@}$, letting $@(\trm{M},\trm{N})$ stand for $MN$.
\end{itemize}

\begin{defn}
	Let $\trm{M}$ be a well-labeled representative of a label-closed term, and let $\Sigma_M$ be the set of signature symbols occurring in $\trm{M}$.
	We define $\prec_M$ as the (strict) partial order on $\Sigma_M$ generated by the following rules.
\[
\begin{array}{rcl@{\qquad\quad}l}
		\trm{+a} &\prec_M& \trm{+b} & \text{ if } a <_M b
\\[5pt]	\trm{+a} &\prec_M& \trm{!b} & \text{ for any labels } a,b
\\[5pt]	\trm{!b} &\prec_M& @,\x		& \text{ for any label } b
\end{array}
\]
\end{defn}

\begin{lem}
\label{lemma:strong-normalization}
	The reduction $\rw_\perm$ is strongly normalizing.
\end{lem}

\begin{proof}
For the first-order term rewriting system $(\PEL, \rw_\perm)$ we derive a well-founded recursive path ordering $<$ from $\prec_M$ following \cite[p. 289]{Dershowitz82}. Let $f$ and $g$ range over function symbols, let $[N_1,\dots,N_n]$ denote a multiset and extend $<$ to multisets by the standard multiset ordering, and let $N = f(N_1,\dots,N_n)$ and $M = g(M_1,\dots,M_m)$; then
\[
N < M \iff
\left\{
\begin{array}{ll}
	[N_1,\dots,N_n] < [M_1,\dots,M_m] & \text{ if } f = g
\\[5pt]
	[N_1,\dots,N_n] < [M]			  & \text{ if } f \prec_M g 
\\[5pt]
	[N] \leq [M_1,\dots,M_m]		  & \text{ if } f \npreceq_M g~.
\end{array}
\right.
\]
While $\prec_M$ is defined only relative to $\Sigma_M$, reduction may only reduce the signature. Inspection of Figure~\ref{fig:reduction rules} then shows that $M \rw_\perm N$ implies $N<M$.
\end{proof}

\subsection{Confluence of permutative reduction}

With strong normalization, confluence of $\rw_\perm$ requires only local confluence. We begin by reducing the number of cases to consider, by casting the permutations of $\ttrm{+a}$ as instances of a common shape.

\begin{defn}
We define a \emph{context} $C[\,]$ as follows.
\[
\begin{array}{lll@{~}l@{~}l@{~}l@{~}l}
	C[\,] &\coloneqq& [\,] &\mid& \lambda x.C[\,] &\mid& C[\,]M ~\mid~ NC[\,] ~\mid~ \trm{C[\,]+aM} ~\mid~ \trm{N+aC[\,]} ~\mid~ \trm{!a.C[\,]}
\end{array}
\]
The term $C[N]$ represents $C[\,]$ with the hole $[\,]$ replaced by $N$.
\end{defn}

Observe that the six reduction rules $\plusAbs$ through $\plusBox$ in Figure~\ref{fig:reduction rules} are all of the following form. We refer to these collectively as $\plusX$.
\begin{align}
	\trm{C[N+aM]} \rw_\perm \trm{C[N]+aC[M]}
	\tag\plusX
\end{align}


%
%\begin{defn}
%The $a$-\emph{projections} $N[i/a]$ for $i\in\{0,1\}$ of a term $N$ are as follows.
%\[
%\begin{array}{rcl}
%  \rstrut	\trm{x[i/a]}	 	&=& x
%\\\rstrut	\trm{(\x.N)[i/a]}	&=& \trm{\x.(N[i/a])}
%\\\rstrut	\trm{(NM)[i/a]}		&=& \trm{(N[i/a])(M[i/a])}
%\end{array}
%\begin{array}{rcl}
%  \rstrut	\trm{(N_0 +a N_1)[i/a]} &=& \trm{N_i[i/a]}
%\\\rstrut	\trm{(N +b M)[i/a]} 	&=& \trm{(N[i/a]) +b (M[i/a])}
%\\\rstrut	\trm{(!b.N)[i/a]}  		&=& \trm{!b.(N[i/a])}
%\end{array}
%\]
%\end{defn}

%
%\begin{proof}[Sketch]
%The following measure reduces for every step. Order constructors by
%\[
%			\trm{+a}
%\smallbin<	\trm{+b}
%\smallbin<	\probox c
%\qquad
%(a\smallbin<b\smallbin<c)
%\]
%(where $@$ stands for application). We consider sequences of these, ordered lexicographically.
%\end{proof}
%
%\begin{lem}
%Reduction $\rw_\perm$ is confluent.
%\end{lem}
%
%\begin{proof}
%	By Newman's lemma and strong normalization of $\rw_\perm$ (\Cref{lemma:strong-normalization}), we only have to prove that $\rw_\perm$ is locally confluent.
%We consider each reduction rule against those lower down in the table in Figure~\ref{fig:reduction rules}.
%\begin{itemize}
%	\item $(\idem)$ $\trm{N +a N}\rw N$.
%
%\[
%\begin{tikzpicture}
%	\matrix [matrix of math nodes] (m) {
%	  \trm{N +a (M +a M)} &[20pt] \trm{N +a M}
%	\\ };
%	\draw[rw,yshift=30pt]  (m-1-1) [] --node[above]{$\idem$}    (m-1-2);
%	\draw[rw,yshift=-3pt] (m-1-1) --node[below]{$\cancelR$} (m-1-2);
%\end{tikzpicture}
%\]
%
%\[
%	\trm{N +a (M +a M)} \begin{array}{c}\rw\\[-6pt]\rw\end{array} \trm{N +a M}
%\qquad
%\begin{array}{c@{~}c@{~}c}
%	\trm{(N +a M) +a (N +a M)} &\rw& \trm{N+a M}
%\\	\dw & \rotatebox[origin=c]{30}{$\rw$}
%\\	\trm{(N +a M) +a M}\rstrut
%\end{array}
%\qquad
%\begin{array}{c@{~}c@{~}c}
%	\trm{C[N +a N]}	&\rw& C[N]
%\\	\dw & \rotatebox[origin=c]{30}{$\rw$}
%\\	\trm{C[N] +a C[N]}\rstrut
%\end{array}
%\]
%
%	\item $\trm{N +a (M +a P)}\rw\trm{N +a P}$.
%
%\[
%\begin{array}{c@{~}c@{~}c}
%	\trm{(N+aM)+a(P+aQ)} & \rw & \trm{(N+aM)+a Q}
%\\	\dw && \dw
%\\	\trm{N +a (P+aQ)} & \rw & \trm{N+aQ} \rstrut
%\end{array}
%\qquad
%\begin{array}{c@{~}c@{~}c}
%	\trm{C[N +a (M +a P)]} &\rw& \trm{C[N+a M]}
%\\	\dw
%\\	\trm{C[N] +a C[M+a P]} && \dw
%\\	\dw
%\\	\trm{C[N] +a (C[M] +a C[P])} &\rw& \trm{C[N] +a C[M]}
%\end{array}
%\]
%
%\[
%a<b
%\begin{array}{c@{~}c@{~}c}
%	\trm{(N+aM)+b(P+bQ)} & \rw & \trm{(N+aM)+b Q}
%\\	\dw && \dw
%\\	\trm{(N+b(P+bQ))+a(M+b(P+bQ))} & \rws & \trm{(N+bQ)+a(M+bQ)} \rstrut
%\end{array}
%\]
%
%	\item $\trm{C[N+aM]}\rw\trm{C[N]+a C[M]}$.
%
%\[
%a < b \quad
%\begin{array}{c@{~}c@{~}c}
%	\trm{C[N +b (M +a P)]} &\rw& \trm{C[N]+b C[M+a P]}
%\\	\dw && \dw
%\\	\trm{C[(N +b M) +a (N+b P)]} && \trm{C[N]+b (C[M] +a C[P]} \rstrut
%\\	\dw && \dw
%\\	\trm{C[N +b M] +a [N +b P]}	&\rw& \trm{(C[N]+b C[M])+a(C[N]+bC[P]]} \rstrut
%\end{array}
%\]
%
%
%	\item $\trm{N +b (M +a P)}\rw\trm{(N +b M) +a (N +b P)}$.
%
%\[
%a<b
%\begin{array}{c@{~}c@{~}c}
%	\trm{(N+a Q)+b(M+a P)} &\rw& \trm{((N+a Q) +b M) +a ((N+a Q) +b P)}
%\\	\dw && \dw_*
%\\	\trm{(N+b(M+a P))+a(Q+b(M+a P))} && \trm{((N +b M)+a (Q +b M)) +a ((N +b P)+a(Q +b P))} \rstrut
%\\	\dw_* && \dw_*
%\\	\trm{((N+b M) +a (N+b P)) +a ((Q +b M) +a (Q +b P))} &\rw^*& \trm{(N+b M)+a(Q+b P)} \rstrut
%\end{array}
%\]
%
%{\footnotesize
%\[
%a<c<b
%\begin{array}{c@{~}c@{~}c}
%\trm{(N+a Q)+b(M+c P)} &\rw& \trm{((N+a Q) +b M) +c ((N+a Q) +b P)}
%\\	\dw && \dw_*
%\\	\trm{(N +b(M+c P))+a(Q+b(M+c P))} && \trm{((N +b M)+a (Q +b M)) +c ((N +b P)+a(Q +b P))} \rstrut
%\\	\dw_* && \dw_*
%\\\trm{((N +b M) +c (N +b P)) +a ((Q +b M) +c (Q +b P))} && \trm{((N +b M) +c ((N +b P)+a(Q +b P))) +a ((Q +b M) +c ((N +b P)+a(Q +b P)))} \rstrut
%\\	 & \rotatebox[origin=c]{155}{$\rw_*$}& \dw_*
%\\	 && \trm{(((N +b M) +c (N +b P)) +a ((N +b M) +c (Q +b P))) +a (((Q +b M) +c (N +b P)) +a ((Q +b M) +c (Q +b P)))} \rstrut
%\end{array}
%\]
%}
%
%
%	\item $\trm{N (M +a P)}\rw\trm{(NM) +a (NP)}$.
%
%\[
%\begin{array}{c@{~}c@{~}c}
%\trm{(N+a Q)(M+a P)} &\rw& \trm{((N+a Q) M) +a ((N+a Q) P)}
%\\	\dw && \dw_*
%\\	\trm{(N(M+a P))+a(Q(M+a P))} && \trm{((N M)+a (Q M)) +a ((N P)+a(Q P))} \rstrut
%\\	\dw_* && \dw_*
%\\	\trm{((NM) +a (N P)) +a ((Q M) +a (Q P))} &\rw^*& \trm{(NM)+a(QP)} \rstrut
%\end{array}
%\]
%
%{\footnotesize
%\[
%a<b
%\begin{array}{c@{~}c@{~}c}
%\trm{(N+a Q)(M+b P)} &\rw& \trm{((N+a Q) M) +b ((N+a Q) P)}
%\\	\dw && \dw_*
%\\	\trm{(N(M+b P))+a(Q(M+b P))} && \trm{((N M)+a (Q M)) +b ((N P)+a(Q P))} \rstrut
%\\	\dw_* && \dw_*
%\\	\trm{((NM) +b (N P)) +a ((Q M) +b (Q P))} && \trm{((N M) +b ((N P)+a(Q P))) +a ((Q M) +b ((N P)+a(Q P)))} \rstrut
%\\	 &\rotatebox[origin=c]{155}{$\rw_*$} & \dw_*
%\\	 && \trm{(((N M) +b (N P)) +a((N M) +b(Q P))) +a (((Q M) +b (N P)) +a ((Q M) +b(Q P)))} \rstrut
%\end{array}
%\]
%}
%
%	\item $\trm{!b.(N +a M)} \rw \trm{(!b.N) +a (!b.M)}$ %(!c M[c/b])}$
%
%\[
%a \neq b, \ b \notin\trm{N+a M} \
%\begin{array}{c@{~}c@{~}c}
%	\trm{!b.(N +a M)} &\rw& \trm{(!b.N) +a (!b.M)}
%\\	\dw & \rotatebox[origin=c]{210}{$\rw_*$}
%\\	\trm{N +a M} &&
%\end{array}
%\]
%
%\end{itemize}
%\end{proof}


\begin{lem}
Reduction $\rw_\perm$ is confluent.
\end{lem}

\begin{proof}
We prove local confluence; by Newman's lemma and strong normalization of $\rw_\perm$ (\Cref{lemma:strong-normalization}), confluence follows. We consider each reduction rule against those lower down in Figure~\ref{fig:reduction rules}. For the symmetric rule pairs $\cancelL$/$\cancelR$, $\plusL$/$\plusR$, and $\plusFun/\plusArg$ we present only the first case. Unless otherwise specified, we let $a<b<c$.

\newcommand\itm[2]{\medskip\noindent(#1)}% \qquad$#2$}

%=====
\itm\idem{\trm{N +a N}\rw N}
\[
\vc{\begin{tikzpicture}[x=20pt,y=1.5ex]
	\node[anchor=base east] (a) at (0,0) {$\trm{(N+aN)+aM}$};
	\node[anchor=base west] (b) at (1,0) {$\trm{N+aM}$};
	\draw[rw] (0,1) --node[above]{$\idem$}    (1,1);
	\draw[rw] (0,0) --node[below]{$\cancelL$} (1,0);
\end{tikzpicture}}
\]
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+aM)+a(N+aM)} &[20pt] \trm{N+aM}
	\\[20pt]\trm{N+a(N+aM)}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\idem$}    (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\cancelL$} (m-2-1);
	\draw[rw,implied] (m-2-1) --node[below right=-2pt] {$\cancelR$} (m-1-2);
\end{tikzpicture}}}
\qquad
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{C[N+aN]}    &[20pt] C[N]
	\\[20pt]\trm{C[N]+aC[N]}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\idem$}  (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusX$} (m-2-1);
	\draw[rw,implied] (m-2-1) --node[below right=-2pt] {$\idem$} (m-1-2);
\end{tikzpicture}}}
\]
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+aM)+b(N+aM)} &[30pt] \trm{N+aM}
	\\[20pt]\trm{(N+b(N+aM))+a(M+b(N+aM))} %&&[10pt] (a<b)
	\\[20pt]\trm{((N+bN)+a(N+bM))+a((M+bN)+a(M+bM))} & \trm{(N+bN)+a(M+bM)}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\idem$}    (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusL$} (m-2-1);
	\draw[rws,implied] (m-2-1) --node[left] {$\plusR$}   (m-3-1);
	\draw[rws,implied] (m-3-2) --node[right]{$\idem$}    (m-1-2);
	\draw[rws,implied] (m-3-1) --node[below]{$\cancelL,\cancelR$} (m-3-2);
\end{tikzpicture}}}
\]

%=====
\itm\cancelL{\trm{(N +a M) +a P}\rw\trm{N +a P}}
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+aM)+a(P+aQ)} &[15pt] \trm{N+a(P+aQ)}
	\\[20pt]\trm{(N+aM)+a Q} & \trm{N+aQ}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\cancelL$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\cancelR$} (m-2-1);
	\draw[rw,implied] (m-1-2) --node[right]{$\cancelR$} (m-2-2);
	\draw[rw,implied] (m-2-1) --node[below]{$\cancelL$} (m-2-2);
\end{tikzpicture}}}
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{C[(N+aM)+aP]} &[15pt] \trm{C[N+aM]}
	\\[20pt]\trm{C[N+aM]+aC[P]}
	\\[20pt]\trm{(C[N]+aC[M])+aC[P]} & \trm{C[N]+aC[M]}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\cancelL$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusX$}   (m-2-1);
	\draw[rw,implied] (m-2-1) --node[left] {$\plusX$}   (m-3-1);
	\draw[rw,implied] (m-1-2) --node[right]{$\plusX$}   (m-3-2);
	\draw[rw,implied] (m-3-1) --node[below]{$\cancelL$} (m-3-2);
\end{tikzpicture}}}
\]
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
			\trm{(N+bM)+b(P+aQ)} &[20pt]  \trm{N+b(P+aQ)}
	\\[20pt]\trm{((N+bM)+bP)+a((N+bM)+bQ)} & \trm{(N+bP)+a(N+bQ)}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\cancelL$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusR$}   (m-2-1);
	\draw[rw, implied] (m-1-2) --node[right]{$\plusR$} (m-2-2);
	\draw[rws,implied] (m-2-1) --node[below]{$\cancelL$} (m-2-2);
\end{tikzpicture}}}
%\qquad(a<b)
\]

%=====
\itm\plusX{\trm{C[N+aM]}\rw\trm{C[N]+a C[M]}}
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{C[(N+aM)+bP]}      &[20pt] \trm{C[N+aM]+bC[P]}
	\\[20pt]\trm{C[(N+bP)+a(M+bP)]} &       \trm{(C[N]+aC[M])+bC[P]}		 %&[10pt] (a<b)
	\\[20pt]\trm{C[N+bP]+aC[M+bP]}  &       \trm{(C[N]+bC[P])+a(C[M]+bC[P])}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\plusX$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusL$} (m-2-1);
	\draw[rw, implied] (m-1-2) --node[right]{$\plusX$} (m-2-2);
	\draw[rw, implied] (m-2-1) --node[left] {$\plusX$} (m-3-1);
	\draw[rw, implied] (m-2-2) --node[right]{$\plusL$} (m-3-2);
	\draw[rws,implied] (m-3-1) --node[below]{$\plusX$} (m-3-2);
\end{tikzpicture}}}
\]

%=====
\itm\plusL{\trm{(N+aM)+bP}\rw\trm{(N+bP)+a(M+bP)}}
\[
\vcenter{\hbox{\begin{tikzpicture}[x=340pt,y=40pt]
	\node[anchor=west] (a) at (0,2) {$\trm{(N+aM)+b(P+aQ)}$};
	\node[anchor=west] (b) at (0,1) {$\trm{((N+aM)+bP)+a((N+aM)+bQ)}$};
	\node[anchor=west] (c) at (0,0) {$\trm{((N+bP)+a(M+bP))+a((N+bQ)+a(M+bQ))}$};
	%
	\node[anchor=east] (d) at (1,2) {$\trm{(N+b(P+aQ))+a(M+b(P+aQ))}$};
	\node[anchor=east] (e) at (1,1) {$\trm{((N+bP)+a(N+bQ))+a((M+bP)+a(M+bQ))}$};
	\node[anchor=east] (f) at (1,0) {$\trm{(N+bP)+a(M+bQ)}$};
%
	\draw[rw] (a) --node[above]{$\plusL$} (d);
	\draw[rw] 			($(a.south west)+( 43.5pt,0pt)$) --node[left] {$\plusR$} ($(b.north west)+( 43.5pt,0pt)$);
	\draw[rws,implied]	($(d.south east)+(-43.5pt,0pt)$) --node[right]{$\plusR$} ($(e.north east)+(-43.5pt,0pt)$);
	\draw[rws,implied]	($(b.south west)+( 43.5pt,0pt)$) --node[left] {$\plusL$} ($(c.north west)+( 43.5pt,0pt)$);
	\draw[rws,implied]	($(e.south east)+(-43.5pt,0pt)$) --node[right]{$\cancelL,\cancelR$} ($(f.north east)+(-43.5pt,0pt)$);
	\draw[rws,implied] (c) --node[below]{$\cancelL,\cancelR$} (f);
\end{tikzpicture}}}
%\vcenter{\hbox{\begin{tikzpicture}
%	\matrix [matrix of math nodes] (m) {
%	  		\trm{(N+aM)+b(P+aQ)}                      &[10pt] \trm{(N+b(P+aQ))+a(M+b(P+aQ))}
%	\\[20pt]\trm{((N+aM)+bP)+a((N+aM)+bQ)}            &       \trm{((N+bP)+a(N+bQ))+a((M+bP)+a(M+bQ))} %&[10pt] (a<b)
%	\\[20pt]\trm{((N+bP)+a(M+bP))+a((N+bQ)+a(M+bQ))}  &       \trm{(N+bP)+a(M+bQ)}
%	\\ };
%	\draw[rw] (m-1-1) --node[above]{$\plusL$} (m-1-2);
%	\draw[rw] (m-1-1) --node[left] {$\plusR$} (m-2-1);
%	\draw[rws,implied] (m-1-2) --node[right]{$\plusR$} (m-2-2);
%	\draw[rws,implied] (m-2-1) --node[left] {$\plusL$} (m-3-1);
%	\draw[rws,implied] (m-2-2) --node[right]{$\cancelL,\cancelR$} (m-3-2);
%	\draw[rws,implied] (m-3-1) --node[below]{$\cancelL,\cancelR$} (m-3-2);
%\end{tikzpicture}}}
\]
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+bM)+c(P+aQ)}            &[20pt] \trm{(N+c(P+aQ))+b(M+c(P+aQ))}
	\\[20pt]                                &       \trm{((N+cP)+a(N+cQ))+b((M+cP)+a(M+cQ))} %&[10pt] (a<b<c)
	\\[20pt]\trm{((N+bM)+cP)+a((N+bM)+cQ)}  &       \trm{((N+cP)+b(M+cP))+a((N+cQ)+b(M+cQ))}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\plusL$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusR$} (m-3-1);
	\draw[rws,implied] (m-1-2) --node[right]{$\plusR$} (m-2-2);
	\draw[rws,implied] (m-2-2) --node[right]{$\plusL,\plusR,\cancelL,\cancelR$} (m-3-2);
	\draw[rws,implied] (m-3-1) --node[below]{$\plusL$} (m-3-2);
\end{tikzpicture}}}
\]

%=====
\itm\plusFun{\trm{(N+aM)P}\rw\trm{(NP)+a(MP)}}
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+aM)(P+aQ)}                &[10pt] \trm{(N(P+aQ))+a(M(P+aQ))}
	\\[20pt]\trm{((N+aM)P)+a((N+aM)Q)}        &       \trm{((NP)+a(NQ))+a((MP)+a(MQ))}
	\\[20pt]\trm{((NP)+a(MP))+a((NQ)+a(MQ))}  &       \trm{(NP)+a(MQ)}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\plusFun$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusArg$} (m-2-1);
	\draw[rws,implied] (m-1-2) --node[right]{$\plusArg$} (m-2-2);
	\draw[rws,implied] (m-2-1) --node[left] {$\plusFun$} (m-3-1);
	\draw[rws,implied] (m-2-2) --node[right]{$\cancelL,\cancelR$} (m-3-2);
	\draw[rws,implied] (m-3-1) --node[below]{$\cancelL,\cancelR$} (m-3-2);
\end{tikzpicture}}}
\]
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{(N+bM)(P+aQ)}         &[20pt] \trm{(N(P+aQ))+b(M(P+aQ))}
	\\[20pt]                           &       \trm{((NP)+a(NQ))+b((MP)+a(MQ))} %&[10pt] (a<b)
	\\[20pt]\trm{((N+bM)P)+a((N+bM)Q)} &       \trm{((NP)+b(MP))+a((NQ)+b(MQ))}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\plusFun$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\plusArg$} (m-3-1);
	\draw[rws,implied] (m-1-2) --node[right]{$\plusArg$} (m-2-2);
	\draw[rws,implied] (m-2-2) --node[right]{$\plusL,\plusR,\cancelL,\cancelR$} (m-3-2);
	\draw[rws,implied] (m-3-1) --node[below]{$\plusFun$} (m-3-2);
\end{tikzpicture}}}
\]

%=====
\itm\plusBox{\trm{!b.(N +a M)} \rw \trm{(!b.N) +a (!b.M)}}
\[
\vcenter{\hbox{\begin{tikzpicture}
	\matrix [matrix of math nodes] (m) {
	  		\trm{!b.(N+aM)}    &[20pt] \trm{(!b.N)+a(!b.M)}
	\\[20pt]\trm{N+aM}
	\\ };
	\draw[rw] (m-1-1) --node[above]{$\plusBox$} (m-1-2);
	\draw[rw] (m-1-1) --node[left] {$\boxVoid$} (m-2-1);
	\draw[rws,implied] (m-1-2) --node[below right=-2pt] {$\boxVoid$} (m-2-1);
\end{tikzpicture}}}
\quad (a \neq b, \ b \notin\trm{N+a M})
\]
\end{proof}

\begin{defn}
We denote the unique $\perm$-normal form of a term $N$ by $N^\perm$.
\end{defn}

%=====================================================================================

\section{Confluence}

We aim to prove that $\rw \,=\, \rw_\beta \cup \rw_\perm$ is confluent. We will use the standard technique of \emph{parallel} $\beta$-reduction, a simultaneous reduction step on an arbitrary number of $\beta$-redexes in the source term, which we define via a labelling of the redexes to be reduced. The central point is to find a notion of reduction that is \emph{diamond}, \ie\ every critical pair can be closed in one (or zero) steps. This will be our \emph{complete} reduction, which consists of parallel $\beta$-reduction followed by $\perm$-reduction to normal form.
%
%\begin{lem}[Substitution for $\rw_\perm$]
%	\label{lemma:substitution}
%	\hfill
%	\begin{enumerate}
%		\item If $\trm{N \rw_\perm N'}$ then $\trm{M[N/x] \rw_\perm^* M[N'/x]}$.
%		\item If $\trm{M \rw_\perm M'}$ then $\trm{M[N/x] \rw_\perm M'[N/x]}$.
%		%\item If $\trm{x \in {\fv{M}}}$ and $a <_M b$ for any $\trm{b \in {\fl{M}}}$ then $\trm{M[N +a P/x]} \rw_\perm^* \trm{M[N/x] +a M[P/x]}$.
%	\end{enumerate}
%\end{lem}

%\begin{proof}\hfill
%	\begin{enumerate}
%		\item By induction on $\trm{M}$.
%		\item By induction on the definition of $\trm{M \rw_\perm M'}$. \qedhere
%	\end{enumerate}
%\end{proof}




%		\item By induction on $\trm{M}$.
%		Cases:
%		\begin{itemize}
%			\item \emph{Variable}, \ie\ $\trm{M = x}$ (as $\trm{x} \in \fv{M}$), and then $\trm{M[N +a P/x]} = \trm{N +a P} = \trm{M[N/x] +a M[P/x]}$.
%
%			\item \emph{Application}, \ie\ $\trm{M = M_1M_2}$.
%			Since $\trm{x \in {\fv{M}}}$ there are three cases:
%			\begin{itemize}
%				\item $\trm{x \in {\fv{M_1}} \cup \fv{M_2}}$ and then, by \ih, $\trm{M_i[N +a P/x]} \rw_\perm^* \trm{M_i[N/x] +a M_i[P/x]}$ for all $i \in \{1,2\}$.
%				So,
%				$\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] M_2[N +a P/x]} \rw_\perm^* \trm{(M_1[N/x] +a M_1[P/x])(M_2[N/x] +a M_2[P/x])} \allowbreak\rw_\perm^* \trm{M_1[N/x]M_2[N/x] +a M_1[P/x]M_2[P/x]} = \trm{M[N/x] +a M[P/x]}$.
%
%				\item $\trm{x \in {\fv{M_{1}}}}$ and $\trm{x \notin {\fv{M_2}}}$ and then, by \ih, $\trm{M_1[N +a P/x]} \rw_\perm^* \trm{M_1[N/x] +a M_1[P/x]}$.
%				So,
%				$\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] M_2} \rw_\perm^* \trm{(M_1[N/x] +a M_1[P/x])M_2} \allowbreak\rw_\perm^* \trm{M_1[N/x]M_2 +a M_1[P/x]M_2} = \trm{M[N/x] +a M[P/x]}$.
%
%				\item $\trm{x \notin {\fv{M_{1}}}}$ and $\trm{x \in {\fv{M_2}}}$: analogous to the previous case.
%			\end{itemize}
%
%			\item \emph{Abstraction}, \ie\ $\trm{M = \y.M'}$.
%			By \ih, as $\trm{x \in {\fv{M}} \subseteq \fv{M'}}$ $\trm{M'[N +a P/x]} \rw_\perm^* \trm{M'[N/x] +a M'[P/x]}$
%			So, $\trm{M [N +a P/x] = \y.(M'[N +a P/x]) \rw_\perm^* \y.(M'[N/x] +a M'[P/x]) \rw_\perm \y.(M'[N/x]) +a \y.(M'[P/x])}$ $= \trm{M[N/x] +a M[P/x]}$.
%			
%			\item \emph{Superposition}, \ie\ $\trm{M = M_1 +b M_2}$. 
%			By \ih, $\trm{M_i[N +a P/x]} \rw_\perm^* \trm{M_i[N/x] +a M_i[P/x]}$ for all $i \in \{1,2\}$.
%			Since $a <_M b$ by hypothesis, $\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] +b M_2[N +a P/x]} \rw_\perm^* \trm{(M_1[N/x] +a M_1[P/x]) 
%				\allowbreak+b (M_2[N/x] +a M_2[P/x])} \rw_\perm
%			\trm{((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[N/x]) +a ((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[P/x])}
%			\allowbreak\rw_\perm^* 
%			\trm{((M_1[N/x]\allowbreak+b M_2[N/x]) +a (M_1[P/x] \allowbreak+b M_2[N/x]))  +a ((M_1[N/x] \allowbreak+b M_2[P/x]) +a (M_1[P/x] \allowbreak+b M_2[P/x])) }
%			\allowbreak\rw_\perm^*
%			\trm{(M_1[N/x] +b M_2[N/x]) +a (M_1[P/x] +b M_2[P/x])} = \trm{M[N/x] +a M[P/x]}$.
%
%			\item \emph{Superposition}, \ie\ $\trm{M = M_1 +b M_2}$.
%			Since $\trm{x \in {\fv{M}}}$ there are three cases:
%			\begin{itemize}
%				\item $\trm{x \in {\fv{M_1}} \cup \fv{M_2}}$ and then, by \ih, $\trm{M_i[N +a P/x]} \rw_\perm^* \trm{M_i[N/x] +a M_i[P/x]}$ for all $i \in \{1,2\}$.
%				Since $a <_M b$ by hypothesis, $\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] +b M_2[N +a P/x]} \rw_\perm^* \trm{(M_1[N/x] +a M_1[P/x]) 
%					\allowbreak+b (M_2[N/x] +a M_2[P/x])} \rw_\perm
%				\trm{((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[N/x]) +a ((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[P/x])}
%				\allowbreak\rw_\perm^* 
%				\trm{((M_1[N/x]\allowbreak+b M_2[N/x]) +a (M_1[P/x] \allowbreak+b M_2[N/x]))  +a ((M_1[N/x] \allowbreak+b M_2[P/x]) +a (M_1[P/x] \allowbreak+b M_2[P/x])) }
%				\allowbreak\rw_\perm^*
%				\trm{(M_1[N/x] +b M_2[N/x]) +a (M_1[P/x] +b M_2[P/x])} = \trm{M[N/x] +a M[P/x]}$.
%				
%				\item $\trm{x \in {\fv{M_{1}}}}$ and $\trm{x \notin {\fv{M_2}}}$ and then, by \ih, $\trm{M_1[N +a P/x]} \rw_\perm^* \trm{M_1[N/x] +a M_1[P/x]}$.
%				
%				Since $a <_M b$ by hypothesis, $\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] +b M_2} \rw_\perm^* \trm{(M_1[N/x] +a M_1[P/x]) 
%					\allowbreak+b M_2} \rw_\perm
%				\trm{((M_1[N/x]\allowbreak+b M_2) +a (M_1[P/x] \allowbreak+b M_2) }
%				= \trm{M[N/x] +a M[P/x]}$.
%
%				\item $\trm{x \notin {\fv{M_{1}}}}$ and $\trm{x \in {\fv{M_2}}}$: analogous to the previous case.
%			\end{itemize}
%
%			\item \emph{Box}, \ie\ $\trm{M} = \trm{!b.M'}$. 
%			We can suppose without loss of generality that $b \neq a$.
%			By \ih, as $\trm{x \in {\fv{M}} = \fv{M'}}$ $\trm{M'[N +a P/x]} \rw_\perm^* \trm{M'[N/x] +a M'[P/x]}$
%			So, $\trm{M [N +a P/x] = !b.(M'[N +a P/x]) \rw_\perm^* !b.(M'[N/x] +a M'[P/x]) \rw_\perm !b.(M'[N/x]) +a !b.(M'[P/x])}$ $= \trm{M[N/x] +a M[P/x]}$.
%			\qedhere
%		\end{itemize}
%
%\begin{remark}
%	If $\trm{x \notin {\fv{M}}}$ then $\trm{M[N +a P/x] \not\rw_\perm^* M[N/x] +a M[P/x]}$.
%	For instance, take $\trm{M} = \trm{y} \neq \trm{x}$: then, $\trm{M[N +a P/x]} \allowbreak= y \neq \trm{y +a y} = \trm{M[N/x] +a M[P/x]}$ where $\trm{y}$ is $\perm$-normal.
%	In fact, if $\trm{x \notin {\fv{M}}}$ then $\trm{M[N/x] +a M[P/x] \allowbreak= M +a M \rw_\perm M = M[N +a P/x]}$.
%\end{remark}
%
%Two problematic cases to join critical pairs: the first two ones mean that we cannot use commutation and Hindley--Rosen lemma to prove that $\rw$ is confluent;
%the second two ones suggest that the proof of confluence of $\rw$ is delicate (see the remark above).
%
%$
%\begin{array}{c@{~}c@{~}c}
%\trm{(\x.!a.M)P} &\rw_\perm & \trm{(!a.(\x. M))P}
%\\	\dw_\beta && \dw_\perm
%\\ \trm{(!a.M)[P/x]} & & \trm{!a.(\x. M)P}
%\\	= & \rotatebox[origin=c]{210}{$\rw_\beta$}
%\\	\trm{!a.M[P/x]} &&
%\end{array}
%$
%\qquad
%$
%\begin{array}{c@{~}c@{~}c}
%\trm{(\x.(N +a M))P} &\rw_\perm & \trm{((\x.N) +a (\x. M))P}
%\\	\dw_\beta && \dw_\perm
%\\ \trm{(N +a M)[P/x]} & & \trm{(\x.N)P +a (\x. M)P}
%\\	= & \rotatebox[origin=c]{210}{$\rw_\beta^+$}
%\\	\trm{N[P/x] +a M[P/x]} &&
%\end{array}
%$

%Two problematic cases to join critical pairs: the first two ones mean that we cannot use commutation and Hindley--Rosen lemma to prove that $\rw$ is confluent;
%the second two ones suggest that the proof of confluence of $\rw$ is delicate (see the remark above);
%
%$
%\begin{array}{c@{~}c@{~}c}
%\trm{(\x.!a.M)P} &\rw_\perm & \trm{(!a.(\x. M))P}
%\\	\dw_\beta && \dw_\perm
%\\ \trm{(!a.M)[P/x]} & & \trm{!a.(\x. M)P}
%\\	= & \rotatebox[origin=c]{210}{$\rw_\beta$}
%\\	\trm{!a.M[P/x]} &&
%\end{array}
%$
%\qquad
%$
%\begin{array}{c@{~}c@{~}c}
%\trm{(\x.(N +a M))P} &\rw_\perm & \trm{((\x.N) +a (\x. M))P}
%\\	\dw_\beta && \dw_\perm
%\\ \trm{(N +a M)[P/x]} & & \trm{(\x.N)P +a (\x. M)P}
%\\	= & \rotatebox[origin=c]{210}{$\rw_\beta^+$}
%\\	\trm{N[P/x] +a M[P/x]} &&
%\end{array}
%$
%
%\begin{align*}
%\trm{x \in {\fv{M}}} \qquad & & & \qquad \trm{x \notin {\fv{M}}} \\
%\begin{array}{c@{~}c@{~}c}
%\trm{(\x.M)(N +a P)} &\rw_\perm & \trm{((\x.M)N) +a ((\x. M)P)}
%\\	\dw_\beta && \dw_{\beta^+}
%\\ \trm{M[(N +a P)/x]} & \rw_\perm^* & \trm{M[N/x] +a M[P/x]}
%\end{array}
%&&&
%\begin{array}{c@{~}c@{~}c}
%\trm{(\x.M)(N +a P)} &\rw_\perm & \trm{((\x.M)N) +a ((\x. M)P)}
%\\	\dw_\beta && \dw_{\beta^+}
%\\ \trm{M} & {}_\perm \lw & \trm{M +a M}
%\end{array}
%\end{align*}

%\hrule

\begin{defn}
A \emph{labeled} term $\trm{N*}$ is a term $N$ with chosen $\beta$-redexes annotated as $\trm{(\x.M)*P}$. The \emph{labeled reduct} $\trm{<N*>}$ of a labeled term is defined by induction on $N$ as follows:
\begin{align*}
	\trm{<(\x.N*)*M*>} &= \trm{<N*>[<M*>/x]}	&	\trm{<N*M*>} 	&= \trm{<N*><M*>}
\\	\trm{<x>}		&= x						&	\trm{<N*+aM*>}	&= \trm{<N*>+a<M*>}
\\	\trm{<\x.N*>}	&= \trm{\x.<N*>}			&	\trm{<\,!a.N*>}	&= \trm{!a.<N*>}
\end{align*}
A \emph{parallel $\beta$-step} is a reduction $N\rwp_\beta\trm{<N*>}$ for some labelling $\trm{N*}$ of $N$.
\end{defn}

\noindent
We write $\trm{N*}\rwp_\beta\trm{<N*>}$ for the specific parallel step indicated by the labeling $\trm{N*}$. Observe that $\trm{<N*>}$ is a regular unlabeled term, since all labels are removed in the reduction. For the empty labelling, $\trm{N} = \trm{<N*>}$, so that parallel reduction is reflexive: $\trm{N} \rwp_\beta \trm{N}$.

\begin{lem}
A parallel $\beta$-step $N\rwp_\beta M$ is a $\beta$-reduction $N\rws_\beta M$.
\end{lem}

\begin{proof}
By induction on the labelled term $\trm{N*}$ generating $N\rwp_\beta\trm{<N*>}=M$.
\end{proof}

%\begin{proof}
%	Since $N\rwp_\beta M$ means that $\trm{M} = \trm{<N*>}$ for some labeling $\trm{N*}$ of $\trm{N}$, we prove that $\trm{N} \rws_\beta \trm{<N*>}$ for any labeling $\trm{N*}$ of $\trm{N}$, by induction on $\trm{N}$.
%	Cases:
%	\begin{itemize}
%		\item \emph{Variable}: $\trm{N} = x$. 
%		Then $\trm{x*} = x$ and $\trm{<x*>} = x$.
%		Therefore, $N = x = \trm{<N*>}$ and so $N \rws_\beta \trm{<N*>}$.
%		
%		\item \emph{Abstraction}: $\trm{N} = \trm{\x.M}$.
%		Then $\trm{N*} = \trm{\x.M*}$ and $\trm{<N*>} = \trm{\x.<M*>}$.
%		By \ih, $\trm{M} \rws_\beta \trm{<M*>}$ and so $\trm{N} = \trm{\x.M} \rws_\beta \trm{\x.<M*>} = \trm{<N*>}$.
%		
%		\item \emph{Application}: $\trm{N} = \trm{MP}$.
%		There are two sub-cases:
%		\begin{enumerate}
%			\item $\trm{M} \neq \trm{(\x.Q)*}$. 
%			Then $\trm{N*} = \trm{M*P*}$ and $\trm{<N*>} = \trm{<M*><P*>}$.
%			By \ih, $\trm{M} \rws_\beta \trm{<M*>}$ and $\trm{P} \rws_\beta \trm{<P*>}$, so $\trm{N} = \trm{MP} \rws_\beta \trm{<M*><P*>} = \trm{<N*>}$.
%			
%			\item $\trm{M} = \trm{(\x.Q)*}$.
%			Then $\trm{N*} = \trm{(\x.Q*)*P*}$ and $\trm{<N*>} = \trm{<Q*>[<P*>/x]}$.
%			By \ih, $\trm{Q} \rws_\beta \trm{<Q*>}$ and $\trm{P} \rws_\beta \trm{<P*>}$, so $\trm{N} = \trm{(\x.Q)P} \rw_\beta \trm{Q[P/x]} \rws_\beta \trm{<Q*>[<P*>/x]} = \trm{<N*>}$.
%		\end{enumerate}
%	
%		\item \emph{Choice}: $\trm{N} = \trm{M +a P}$.
%		Then $\trm{N*} = \trm{M* +a P*}$ and $\trm{<N*>} = \trm{<M*>+a<P*>}$.
%		By \ih, $\trm{M} \rws_\beta \trm{<M*>}$ and $\trm{P} \rws_\beta \trm{<P*>}$, so $\trm{N} = \trm{M +a P} \rws_\beta \trm{<M*> +a <P*>} = \trm{<N*>}$.
%		
%		\item \emph{Generator}: $\trm{N} = \trm{!a. M}$. 
%		Analogous to the abstraction case.
%		\qedhere
%	\end{itemize}
%\end{proof}

For the commutation of (parallel) $\beta$-reduction with $\perm$-reduction, we run into the minor issue that a permuting generator or choice operator may block a redex: in both cases below, on the left the term has a redex, but on the right it is blocked. We address by an adaptation of $\perm$-reduction $\rwb_\perm$ on labelled terms, which is a strategy in $\rws_\perm$ that permutes past a labelled redex in one step.
\[
\begin{array}{rcl}
	\trm{(\x.N+aM)\,P} & \rw_\perm & \trm{((\x.N)+a(\x.M))\,P}
\\[5pt]
	\trm{(\x.!a.N)\,M} & \rw_\perm & \trm{(!a.\x.N)\,M}
\end{array}
\]

\begin{defn}
A \emph{labelled} $\perm$-reduction $\trm{N*}\rwb_\perm\trm{M*}$ is a $\perm$-reduction of one of the forms
\[
\begin{array}{rcl}
	\trm{(\x.N*+aM*)*P*} &\rws_\perm& \trm{(\x.N*)*P*+a(\x.M*)*P*}
\\[5pt]
	\trm{(\x.!a.N*)*M*} &\rws_\perm& \trm{!a.(\x.N*)*M*}
\end{array}
\]
or a single $\perm$-step $\rw_\perm$ on unlabeled constructors in $\trm{N*}$.
\end{defn}

\begin{lem}
\label{lem:parallel p-reduction}
Reduction to normal form in $\rwb_\perm$ is equal to $\rwn_\perm$.
\end{lem}

\begin{proof}
Observe that $\rw_\perm$ and $\rwb_\perm$ have the same normal forms. Then since $\rwb_\perm\,\subseteq\,\rws_\perm$ we have $\rwbn_\perm\,\subseteq\,\rwn_\perm$. Conversely, let $N\rwn_\perm M$. On this reduction, let $P\rw_\perm Q$ be the first step such that $P\not\rwb_\perm Q$. Then there is an $R$ such that $P\rwb_\perm R$ and $Q\rw_\perm R$. Note that we have $N\rwbs_\perm R$. By confluence, $R\rwn_\perm M$, and by induction on the sum length of paths in $\rw_\perm$ from $R$ (smaller than from $N$) we have $R\rwbn_\perm M$, and hence $N\rwbn_\perm M$.
\end{proof}

The following lemmata then give the required commutation properties of the relations $\rwb_\perm$, $\rwn_\perm$, and $\rwp_\beta$. Figure~\ref{fig:confluence diagrams} illustrates these by commuting diagrams.

\begin{lem}
\label{lem:parallel p - parallel beta}
If $\trm{N*}\rwb_\perm\trm{M*}$ then $\trm{<N*>}=_\perm\trm{<M*>}$.
\end{lem}

\begin{proof}
By induction on the rewrite step $\rwb_\perm$. The two interesting cases are the following.
\[
\begin{array}{cl}
\vcenter{\hbox{\begin{tikzpicture}
	\matrix[matrix of math nodes] (m) {
	  		\trm{(\x.M*)*(N* +a P*)} &[20pt] \trm{((\x.M*)*N*) +a ((\x. M*)*P*)}
	\\[20pt]\trm{<M*>[(<N*> +a <P*>)/x]} & \trm{<M*>[<N*>/x] +a <M*>[<P*>/x]}
	\\ };
	\draw[rwb] (m-1-1) --node[above]{$\perm$} (m-1-2);
	\draw[rwp] (m-1-1) --node[left] {$\beta$} (m-2-1);
	\draw[rwp,implied] (m-1-2) --node[right]{$\beta$} (m-2-2);
	\draw[rws,implied] (m-2-1) --node[below]{$\perm$} (m-2-2);
\end{tikzpicture}}}
&	(x\in\fv M)
\\ \\
\vcenter{\hbox{\begin{tikzpicture}
	\matrix[matrix of math nodes] (m) {
	  		\trm{(\x.M*)*(N* +a P*)} &[20pt] \trm{((\x.M*)*N*) +a ((\x. M*)*P*)}
	\\[20pt]\trm{<M*>}\vphantom{\trm{+a}} & \trm{<M*> +a <M*>}
	\\ };
	\draw[rwb] (m-1-1) --node[above]{$\perm$} (m-1-2);
	\draw[rwp] (m-1-1) --node[left] {$\beta$} (m-2-1);
	\draw[rwp,implied] (m-1-2) --node[right]{$\beta$} (m-2-2);
	\draw[rw, implied] (m-2-2) --node[below]{$\perm$} (m-2-1);
\end{tikzpicture}}}
&	(x\notin\fv M)
\end{array}
\qedhere
\]
\end{proof}


\begin{lem}
\label{lem:exhaustive p - parallel beta}
If $\trm{N*}\rwn_\perm\trm{M*}$ then $\trm{<N*>}=_\perm\trm{<M*>}$
\end{lem}

\begin{proof}
Using \Cref{lem:parallel p-reduction} we decompose $\trm{N*}\rwn_\perm\trm{M*}$ as
\[
	\trm{N*}=\trm{N_1*}\rwb_\perm\trm{N_2*}\rwb_\perm \dots \rwb_\perm \trm{N_n*}=\trm{M*}
\]
for which \Cref{lem:parallel p - parallel beta} gives $\trm{<N_i*>}=_\perm\trm{<N_{i+1}*>}$.
\end{proof}



\begin{defn}
A \emph{complete} reduction step $\rwp$ is a parallel $\beta$-step followed by $\perm$-reduction to normal form:
\[
	N\rwp M^\perm \quad\coloneq\quad N\rwp_\beta M\rwn_\perm M^\perm~.
\]
\end{defn}

\begin{lem}[Mapping on $\perm$-normal forms]
\label{lem:p to complete reduction}
Any reduction step $N\rw M$ maps onto a complete step $N^\perm\rwp M^\perm$ on $\perm$-normal forms.
\end{lem}

\begin{proof}
The case of a $\perm$-step $N\rw_\perm M$ is immediate, since $N^\perm=M^\perm$ and $\rwp_\beta$ is reflexive. 
For a $\beta$-step $N\rw_\beta M$ we label the reduced redex in $N$ to get $\trm{N*}\rwp_\beta\trm{<N*>}=M$. 
Let $\trm{P*}=(\trm{N*})^\perm$ be the (labeled) $\perm$-normal form of $\trm{N*}$. 
Then \Cref{lem:exhaustive p - parallel beta} gives $M=\trm{<N*>}=_\perm\trm{<P*>}$, illustrated below.
\[
\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  \trm{N*} && \trm{P*} \\[20pt] \\ \trm{M=<N*>} & =_\perm & \trm{<P*>} \\
	};
	\draw[rwn] (m-1-1) --node[above]{$\scriptstyle\perm$} (m-1-3);
	\draw[rwp] (m-1-1) --node[left] {$\scriptstyle\beta$} (m-3-1);
	\draw[rwp] (m-1-3) --node[right]{$\scriptstyle\beta$} (m-3-3);
\end{tikzpicture}
\]
By confluence and strong normalization of $\rw_\perm$ then $\trm{<P*>}^\perm=M^\perm$. The complete reduction $N^\perm\rwp M^\perm$ is then given by $N^\perm\rwp_\beta\trm{<P*>}\rwn_\perm M^\perm$.
\end{proof}

\begin{lem}
\label{lemma:application-parallel-beta}
	If $\trm{M} \rwp_\beta \trm{M'}$ and $\trm{N} \rwp_\beta \trm{N'}$, then $\trm{MN} \rwp_\beta \trm{M'N'}$.
\end{lem}

\begin{proof}
	Since $\trm{M} \rwp_\beta \trm{<M*>} = M'$ and $\trm{N} \rwp_\beta \trm{<N*>} = N'$ for some labelings $\trm{M*}$ and $\trm{N*}$ of $M$ and $N$ respectively, let $\trm{(MN)*}$ be the labeling of $\trm{MN}$ obtained by putting together the labelings $\trm{M*}$ and $\trm{N*}$.
	Clearly, $\trm{MN} \rwp_\beta \trm{<(MN)*>} = \trm{<M*><N*>} = M'N'$.
\end{proof}

\begin{lem}[Full labeling]
\label{lemma:full-development}
	Let $\trm{M}$ be a term, and $\trm{M*}$ be its \emph{full labeling}, which labels every $\beta$-redex in $\trm{M}$.
	\begin{enumerate}
		\item\label{lemma:full-development-beta} If $\trm{M} \rwp_\beta \trm{N}$ then $\trm{N} \rwp_\beta \trm{<M*>}$.
		\item\label{lemma:full-development-complete} If $\trm{M} \rwp \trm{N}$ then $\trm{N} \rwp \trm{<M*>}^\perm$.
	\end{enumerate}
\end{lem}
\begin{proof}\hfill
	\begin{enumerate}
		\item	By induction on $\trm{M}$.
		Cases:
		\begin{itemize}
			\item \emph{Variable}: $\trm{M} = x$.
			Then $\trm{N} = x$ since $x$ is normal. 
			Moreover, $\trm{M*} = x$ and hence $\trm{<M*>} = x$.
			Therefore, $\trm{N} \rwp \trm{<M*>}$ because $\rwp_\beta$ is reflexive.
			
			\item \emph{Abstraction}: $\trm{M} = \trm{\x.P}$.
			Then $\trm{N} = \trm{\x.<P^\circ>}$ for some labeling $\trm{P^\circ}$ of $\trm{P}$.
			Since $\trm{P} \rwp_\beta \trm{<P^\circ>}$, one has $\trm{<P^\circ>} \rwp_\beta \trm{<P*>}$ and hence $\trm{N} = \trm{\x.<P^\circ>} \rwp_\beta \trm{\x.<P*>} = \trm{<M*>}$.
			
			\item \emph{Application}: $\trm{M} = \trm{PQ}$.
			Let $\trm{M^\circ}$ be a labeling of $\trm{M}$ such that $N = \trm{<M^\circ>}$.
			There are three subcases:
			\begin{enumerate}
				\item $\trm{M} \neq \trm{(\x.R)Q}$. 
				Then $\trm{N} = \trm{<P^\circ><Q^\circ>}$.
				By \ih\ (since $\trm{P} \rwp_\beta \trm{<P^\circ>}$ and $\trm{Q} \rwp_\beta \trm{<Q^\circ>}$), one has $\trm{<P^\circ>} \rwp_\beta \trm{<P*>}$ and $\trm{<Q^\circ>} \rwp_\beta \trm{<Q*>}$.
				Therefore, by \Cref{lemma:application-parallel-beta}, $\trm{N} \rwp_\beta \trm{<P*><Q*>} = \trm{<M*>}$, where the equality holds because $\trm{M} \neq \trm{(\x.R)Q}$.
				
				\item $\trm{M^\circ} = \trm{(\x.R)*Q}$.
				Then $\trm{N} = \trm{<R^\circ>[<Q^\circ>/x]}$
				
				\item $\trm{M^\circ} \neq \trm{(\x.R)*Q}$ but $\trm{M} = \trm{(\x.R)Q}$. 
				Then $\trm{N} = \trm{<P^\circ><Q^\circ>}$.
				By \ih\ (since $\trm{P} \rwp_\beta \trm{<P^\circ>}$ and $\trm{Q} \rwp_\beta \trm{<Q^\circ>}$), one has $\trm{<P^\circ>} \rwp_\beta \trm{<P*>}$ and $\trm{<Q^\circ>} \rwp_\beta \trm{<Q*>}$.
			\end{enumerate}
		\end{itemize}
	
		\item Since $\trm{M} \rwp \trm{N}$, then $\trm{M} \rwp_\beta \trm{P} \rwn_\perm \trm{N}$ for some term $\trm{P}$ such that $\trm{N} = \trm{P}^\perm$.
		By \Cref{lemma:full-development}.\ref{lemma:full-development-beta}, $\trm{P} \rwp_\beta \trm{<M*>}$ and hence $\trm{P} \rwp \trm{<M*>^\perm}$.
		According to \Cref{lem:p to complete reduction}, $\trm{N} = \trm{P}^\perm \rwp \trm{(<M*>^\perm)^\perm} = \trm{<M*>^\perm}$.
		\qedhere
	\end{enumerate}
\end{proof}

\begin{cor}[Complete reduction is diamond]
\label{cor:complete diamond}
%Complete reduction has the diamond property: if
	If $P\rwpleft N\rwp M$ then $P\rwp Q\rwpleft M$ for some $Q$.
\end{cor}

\begin{proof}
	By \Cref{lemma:full-development}.\ref{lemma:full-development-complete}, $P\rwp \trm{<M*>} \rwpleft M$ where $\trm{M*}$ is the full labeling of $\trm{M}$.
\end{proof}

\begin{figure}
\[
\begin{array}{cccc}
\vcenter{\hbox{\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  \trm{N*} && \trm{M*} \\[20pt] \\ \trm{<N*>} & =_\perm & \trm{<M*>} \\
	};
	\draw[rwb] (m-1-1) --node[above]{$\scriptstyle\perm$} (m-1-3);
	\draw[rwp] (m-1-1) --node[left] {$\scriptstyle\beta$} (m-3-1);
	\draw[rwp] (m-1-3) --node[right]{$\scriptstyle\beta$} (m-3-3);
\end{tikzpicture}}}
&
\vcenter{\hbox{\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  \trm{N*} && \trm{M*} \\[20pt] \\ \trm{<N*>} & =_\perm & \trm{<M*>} \\
	};
	\draw[rwn] (m-1-1) --node[above]{$\scriptstyle\perm$} (m-1-3);
	\draw[rwp] (m-1-1) --node[left] {$\scriptstyle\beta$} (m-3-1);
	\draw[rwp] (m-1-3) --node[right]{$\scriptstyle\beta$} (m-3-3);
\end{tikzpicture}}}
&
\vcenter{\hbox{\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  \trm{N} &[20pt] & \trm{M} \\[20pt] \\ N^\perm && M^\perm \\
	};
	\draw[rw]  (m-1-1) -- (m-1-3);
	\draw[rwn] (m-1-1) --node[left] {$\scriptstyle\perm$} (m-3-1);
	\draw[rwn] (m-1-3) --node[right]{$\scriptstyle\perm$} (m-3-3);
	\draw[rwx] (m-3-1) -- (m-3-3);
\end{tikzpicture}}}
&
\vcenter{\hbox{\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  \trm{N} &[20pt] & \trm{M} \\[20pt] \\ \trm{P} && \trm{Q} \\
	};
	\draw[rwp] (m-1-1) -- (m-1-3);
	\draw[rwp] (m-1-1) -- (m-3-1);
	\draw[rwp] (m-1-3) -- (m-3-3);
	\draw[rwp] (m-3-1) -- (m-3-3);
\end{tikzpicture}}}
\\ \\
  \text{\Cref{lem:parallel p - parallel beta}}
& \text{\Cref{lem:exhaustive p - parallel beta}}
& \text{\Cref{lem:p to complete reduction}}
& \text{\Cref{cor:complete diamond}}
\end{array}
\]
\caption{Diagrams for the lemmata leading up to confluence}
\label{fig:confluence diagrams}
\end{figure}


\begin{thm}
\label{thm:confluence}
Reduction $\rw$ is confluent.
\end{thm}

\begin{proof}
By the following diagram. For the top and left areas, by Lemma~\ref{lem:p to complete reduction} any reduction path $N\rws M$ maps onto one $N^\perm \rwx M^\perm$. The main square follows by the diamond property of complete reduction, \Cref{cor:complete diamond}.
\[
\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  N &[10pt] &[18pt] M &[10pt] \\[10pt] & N^\perm && M^\perm \\[18pt] P \\[10pt] & P^\perm && Q \\
	};
	\draw[rws] (m-1-1) -- (m-1-3);
	\draw[rws] (m-1-1) -- (m-3-1);
	\draw[rwn] (m-1-1) --node[below left =-2pt] {$\scriptstyle\perm$} (m-2-2);
	\draw[rwn] (m-1-3) --node[above right=-2pt]{$\scriptstyle\perm$} (m-2-4);
	\draw[rwn] (m-3-1) --node[below left =-2pt] {$\scriptstyle\perm$} (m-4-2);
	\draw[rwx] (m-2-2) -- (m-2-4);
	\draw[rwx] (m-2-2) -- (m-4-2);
	\draw[rwx] (m-2-4) -- (m-4-4);
	\draw[rwx] (m-4-2) -- (m-4-4);
\end{tikzpicture}
\qedhere
\]
\end{proof}


%=====================================================================================

\section{Strong normalization for typed terms}

In this section, we prove that the relation $\rw$ enjoys strong
normalization in simply typed terms. Since the proof of strong
normalization is quite delicate, it make sense to turn the definition
of the order $<_{{\trm{M}}}$ from Definition~\ref{def:orderlabels}
more formal, at the same time allowing to treat label-\emph{open}
terms. This is based on Figure~\ref{fig:order}. 
%
\begin{figure}
  \fbox{
    \begin{minipage}{.97\textwidth}
      \begin{tabular}{ll}        
        \textsf{Label Sequences}: & $\theta\quad\coloneqq\quad \varepsilon ~\mid~ a\cdot\theta$\\[5pt]
        \textsf{Label Judgments}: & $\xi\quad\coloneqq\quad \labjudg{\theta}{M}$\\
        \begin{minipage}{.25\textwidth}\textsf{Label Rules}:\end{minipage} &
        \begin{minipage}{.7\textwidth}
        \[
        \begin{array}{c}        
        \infer{\labjudg{\theta}{x}}{}\qquad\quad
        \infer{\labjudg{\theta}{\x.M}}{\labjudg{\theta}{M}}\qquad\quad
        \infer{\labjudg{\theta}{\ttrm{!a.M}}}{\labjudg{a\cdot\theta}{M}}
        \\\\
        \infer{\labjudg{\theta}{MN}}{\labjudg{\theta}{M} & \labjudg{\theta}{N}}\qquad\quad
        \infer{\labjudg{\theta}{\ttrm{M +a N}}}{\labjudg{\theta}{M} & \labjudg{\theta}{N} & a\in\theta}
        \end{array}
        \]
        \end{minipage}
        \\
      \end{tabular}
    \end{minipage}
  }
  \label{fig:order}
  \caption{Labelling Terms}
\end{figure}
%\begin{figure}
%  \fbox{
%    \begin{minipage}{.97\textwidth}
%      \begin{tabular}{ll}        
%        \textsf{Label Sequences}: & $\theta\quad\coloneqq\quad \varepsilon ~\mid~ a\cdot\theta $\\
%        \textsf{Label Judgments}: & $\xi\quad\coloneqq\quad \labjudg{\theta}{M}$\\
%        \begin{minipage}{.25\textwidth}\textsf{Label Rules}:\end{minipage} &
%        \begin{minipage}{.7\textwidth}
%        $$
%        \infer{\labjudg{\theta}{x}}{}\qquad
%        \infer{\labjudg{\theta}{\x.M}}{\labjudg{\theta}{M}}\qquad
%        \infer{\labjudg{\theta}{\ttrm{!a.M}}}{\labjudg{a\cdot\theta}{M}}
%        $$
%        $$
%        \infer{\labjudg{\theta}{MN}}{\labjudg{\theta}{M} & \labjudg{\theta}{N}}\qquad
%        \infer{\labjudg{\theta}{\ttrm{M +a N}}}{\labjudg{\theta}{M} & \labjudg{\theta}{N} & a\in\theta}
%        $$
%        \end{minipage}
%        \\
%      \end{tabular}
%    \end{minipage}
%  }
%  \label{fig:order}
%  \caption{Labelling Terms}
%\end{figure}
%
It is easy to realize that, of course modulo label $\alpha$-equivalence, for
every term $M$ there is at least one $\theta$ such that $\labjudg{\theta}{M}$.
Similarly, reduction as defined by $\rw$ can be made parametric on a sequence
of labels $\theta$, i.e., one can define a family of reduction
relations $\rw^\theta$. An easy fact to check is that if
$\labjudg{\theta}{M}$ and $M\rw^\theta N$, then $\labjudg{\theta}{N}$.
It thus makes sense to define $\mathit{SN}^\theta$ and $\mathit{sn}^\theta(M)$
simply as the set of strongly normalizing $\theta$-terms modulo $\rw^\theta$,
and the maximum number of $\theta$-steps to normal form of a given
$\theta$-term $M$.

Now, let us define types, environments, judgments, and typing rules in
Figure~\ref{fig:typing}.
\newcommand{\arrow}{\Rightarrow}
\newcommand{\judg}[3]{#1\vdash #2:#3}
\begin{figure}
  \fbox{
    \begin{minipage}{.97\textwidth}
      \begin{tabular}{ll}        
        \textsf{Types}: & $\tau\quad\coloneqq\quad \alpha ~\mid~ \tau\arrow\rho$\\[5pt]
        \textsf{Environments}: & $\Gamma\quad\coloneqq\quad x_1:\tau_1,\ldots,x_n:\tau_n$\\[5pt]
        \textsf{Judgments}: & $\pi\quad\coloneqq\quad \judg{\Gamma}{M}{\tau}$\\
        \begin{minipage}{.25\textwidth}\textsf{Typing Rules}:\end{minipage} &
        \begin{minipage}{.7\textwidth}
        \[
        \begin{array}{c}
        \infer{\judg{\Gamma,x:\tau}{x}{\tau}}{}\qquad\quad
        \infer{\judg{\Gamma}{\x.M}{\tau\arrow\rho}}{\judg{\Gamma,x:\tau}M\rho}\qquad\quad
        \infer{\judg{\Gamma}{\ttrm{!a.M}}{\tau}}{\judg{\Gamma}{M}{\tau}}
        \\\\
        \infer{\judg{\Gamma}{MN}{\rho}}{\judg{\Gamma}{M}{\tau\arrow\rho} & \judg{\Gamma}{N}{\tau}}\qquad\quad
        \infer{\judg{\Gamma}{\ttrm{M +a N}}{\tau}}{\judg{\Gamma}{M}{\tau} & \judg{\Gamma}{N}{\tau}}
        \end{array}
        \]
        \end{minipage}
        \\
      \end{tabular}
    \end{minipage}
  }
  \caption{Types, Environments, Judgments, and Rules}
  \label{fig:typing}
\end{figure}
The type structure being precisely the usual one (although terms are of course
different), we can reuse most of the usual proof of strong normalization, for
example in the version given by Ralph Loader's notes, page 17. In the following, we only
report the elements which make our proof different.

\begin{lem}
\label{lemma:cloredsum}
  The set SN is closed under the following rule:
  $$
  \infer{\trm{M +a N}L_1\ldots L_m}{ML_1\ldots L_m & NL_1\ldots L_m}
  $$
\end{lem}
\begin{proof}
  Let $\theta$ be such that
  $$
  \labjudg{\theta}{\trm{M +a N}L_1\ldots L_m}
  $$
  and let $h(a,\theta)$ be the height of $a$ in the sequence $\theta$.
  The proof goes by lexicographic induction on the following quadruple:
  \begin{equation}\label{equ:redord}
  (m,h(a,\theta),\sum_{i=1}^m\mathit{sn}(L_i)+\mathit{sn}(M)+\mathit{sn}(N),|M|+|N|)
  \end{equation}
  We proceed by showing that all terms to which
  $\trm{M +a N}L_1\ldots L_m$ reduces are strongly normalizing:
  \begin{itemize}
  \item
    If reduction happens in one between $M,N,L_1,\ldots,L_m$, then we
    are done, because we get an instance of the rule where the first two
    components of \ref{equ:redord} stay constant, and the third
    strictly decreases.
  \item
    If reduction happens at the leftmost component $\trm{M +a N}$
    due to the rule $\trm{P +a P}\rw_\perm P$, then one of the two
    hypotheses apply trivially.
  \item
    If reduction happens at the leftmost component $\trm{M +a N}$
    due to the rule $\trm{(P +a Q) +a R}\rw_\perm \trm{P +a R}$,
    then the IH holds due to the fourth component being strictly
    smaller. Similarly when the rule is
    $\trm{P +a (Q +a R)}\rw_\perm \trm{P +a R}$.    
  \item
    If reduction happens in the leftmost application due to
    the rule $\trm{(P +a Q) R}\rw_\perm \trm{(PR) +a (QR)}$,
    then the IH can be applied, because the number of arguments $m$
    strictly decreases. Similarly when the rule is
    $\trm{N (M +a P)}\rw_\perm\trm{(NM) +a (NP)}$.
  \item
    If reduction happens at the leftmost component $\trm{M +a N}$
    due to the rule $\trm{(P +b Q) +a R}\rw_\perm \trm{(P +a R) +b (Q +a R)}$,
    then $M$ can be written as $\trm{P +b Q}$, and the
    following two terms are strongly normalizing (because
    $\trm{(P +b Q)L_1\ldots L_m}$ is by hypothesis strongly normalizing
      itself):
    $$
    PL_1\ldots L_m\qquad QL_1\ldots L_m
    $$
    Moreover, $\mathit{sn}(PL_1\ldots L_m),\mathit{sn}(QL_1\ldots
    L_m)\leq\mathit{sn}(\trm{(P +b Q)L_1\ldots L_m}$.  We can then
    conclude that $\trm{(P +a N)}L_1\ldots L_m$ and $\trm{(Q +a
        N)}L_1\ldots L_m$ are both strongly normalizing by IH, because
    the fourth component is strictly smaller. Finally, we can conclude
    again by induction hypothesis, since the number of arguments stays
    the same, while the level of $b$ must be smaller than that of
    $a$. Similarly if the rule applied is $\trm{P +a (Q +b
      R)}\rw_\perm \trm{(P +a Q) +b (P +a R)}$.
  \end{itemize}
\end{proof}

\begin{lem}
  The set SN is closed under the following rule:
  $$
  \infer{\trm{(!a.M)}L_1\ldots L_m}{\trm{M}L_1\ldots L_m}
  $$
\end{lem}
\begin{proof}
  The proof is structurally very similar to the one of
  Lemma~\ref{lemma:cloredsum}. The lexicographic order
  is however the following one:
  $$
  (m,\sum_{i=1}^m\mathit{sn}(L_i)+\mathit{sn}(M),|M|)
  $$
  There is one case in which we need to use
  Lemma \ref{lemma:cloredsum}, namely the one in which the
  considered reduction rule is the following:
  $$
  \trm{!b.(P +a Q)}\rw_\perm\trm{(!b.P) +a (!b.Q)}.
  $$
  Since $M=\trm{P +a Q}$ and $ML_1\ldots L_m$ by hypothesis,
  we conclusde that $PL_1\ldots L_m$ and $QL_1\ldots L_m$
  are both strongly normalizing. By induction hypothesis,
  since $\mathit{sn}(P),\mathit{sn}(Q)\leq\mathit{sn}(M)$,
  it holds that $\trm{(!b.P)}L_1\ldots L_m$ and $\trm{(!b.Q)}L_1\ldots L_m$
  are both strongly normalizing themselves. Lemma~\ref{lemma:cloredsum},
  yields the thesis.
\end{proof}

\begin{lem}
  The set SN is closed under the following rule:
  $$
  \infer{\trm{(\x.M)}L_0\ldots L_m}{\trm{M[L_0/x]}L_1\ldots L_m & L_0}
  $$
\end{lem}
\begin{proof}
  Again, the proof is structurally very similar to the one
  of Lemma~\ref{lemma:cloredsum}. The underlying order,
  needs to be slightly adapted, and is the lexicographic
  order on
  $$
  (\mathit{sn}(\trm{M[L_0/x]}L_1\ldots L_m)+\mathit{sn}(L_0),|M|)
  $$
  As usual, we proceed by showing that all terms to which
  $\trm{(\x.M)}L_0\ldots L_m$ reduces are strongly normalizing:
  \begin{itemize}
  \item
    If reduction happens in $L_0$, then we can mimick
    the same reduction in by zero or more reduction
    steps in $\trm{M[L_0/x]}L_1\ldots L_m$, and conclude
    by induction hypothesis.
  \item
    If reduction happens in $M$ or in $L_1,\ldots,L_m$,
    then we can mimick the same reduction in one or more
    reduction in $\trm{M[L_0/x]}L_1\ldots L_m$, and conclude
    by induction hypothesis.
  \item
    If the reduction step we perform is 
  \end{itemize}
\end{proof}

The definition of a reducible term stays the same:

Lemma 3.5 must be complemented with two new clauses, as follows:
\newcommand{\RedSet}[1]{\mathit{Red}_{#1}}
\begin{lem}
  \begin{itemize}
  \item
    If $(\Gamma,ML_1\ldots L_m)\in\RedSet{\tau}$
    and $(\Gamma,NL_1\ldots L_m)\in\RedSet{\tau}$,
    then $(\Gamma,\trm{(M +a N)}L_1\ldots L_m)\in\RedSet{\tau}$.
  \item
    If $(\Gamma,ML_1\ldots L_m)\in\RedSet{\tau}$,
    then $(\Gamma,\trm{(!a.M)}L_1\ldots L_m)\in\RedSet{\tau}$.
  \end{itemize}
\end{lem}
\begin{proof}
  The proofs are just very simple inductions on $\tau$.
\end{proof}


\hrule

\newcommand\proj[3]{\pi^{#1}_{#2}(\trm{#3})}

\section{Projective reduction}
\label{sec:projective reduction}

Permutative reduction $\rw_\perm$ evaluates probabilistic sums purely by rewriting. Here we look at an alternative \emph{projective} notion of reduction, which conforms more closely to the intuition that $\ttrm{!a}$ generates a probabilistic event to determine the choice $\ttrm{+a}$. We would like to evaluate $\ttrm{!a.N}$ by the probabilistic sum $N_0+N_1$, where $N_i$ is $N$ with any subterm of the form $\ttrm{M_0+aM_1}$ projected to $M_i$. The meta-level sum $+$ must be distinct from the abbreviation $N\+M=\ttrm{!a.N+aM}$, since otherwise reduction on this term would be circular. We then need a call-by-need strategy for evaluating $\ttrm{!a.N}$, which we implement through a \emph{head context}.

\begin{defn}
The \emph{$a$-projections} $\proj a0N$ and $\proj a1N$ are defined as follows, where $a\neq b$.
\begin{align*}
	\proj a0{N+aM} &= \proj a0N		&	\proj ai{\x.N} &= \x.\proj aiN
\\	\proj a1{N+aM} &= \proj a1M		&	\proj ai{NM}   &= (\proj aiN)(\proj aiM)
\\	\proj ai{!a.N} &= \trm{!a.N}	& 	\proj ai{N+bM} &= (\proj aiN)\trm{+b}(\proj aiM)
\\	\proj aix      &= x				&	\proj ai{!b.N} &= \trm{!b.}\proj aiN
\end{align*}
\end{defn}

\begin{defn}
A \emph{head context} $H[\,]$ is given by the following grammar.
\[
	H[\,] \coloneqq [\,] ~\mid~ \lambda x.H[\,] ~\mid~ H[\,]N
\]
\end{defn}

\begin{defn}
\emph{Projective} reduction $\rw_\pi$ is the following reduction step.
\[
	H[\,\trm{!a.N}] ~\rw_\pi~ H[\proj a0N] + H[\proj a1N]
\]
\end{defn}

Observe that projective reduction is a strategy, and not a rewrite relation, as it applies only in head contexts---that is, we do not evaluate inside arguments or under other generators $\ttrm{!a}$ or choices $\ttrm{+a}$. 

We will demonstrate that $\rw_\pi$ is included in $\rws_\perm$. Since $\rws_\perm$ is ignorant of the external sum $+$ (it instead permutes the internal sum $\+$ to the surface), to make the connection formal we need to interpret each top-level $\+$ by $+$. Then let $N^+$ denote the term $N$ with every top-level internal sum $\+$ evaluated as an external sum $+$, as follows. 
\[
	\trm{(N\+M)}^+=N^+\!+M^+ \qquad\qquad N^+=N \quad(N\neq \trm{M\+P})
\]

\begin{rmrk}
	\label{rmrk:proj}
	Let $N, M$ be terms with $\fl{N} \cup \fl{M} \subseteq \{a\}$. 
	Then $\trm{!a. N +a M} \rws_\perm \trm{!a}. \proj{a}{0}{N} \trm{+a} \proj{a}{1}{M} $, where the number of $\rw_\perm$-steps is the number of free occurrences of the label $a$ in $N$ and $M$ not in the scope of some box.
	More in general, under the same hypothesis, if $H$ is a head context then $H[\trm{!a. N +a M}] \rws_\perm \trm{!a}. H[\proj{a}{0}{N}] \trm{+a} H[\proj{a}{1}{M}]$.
	The proof is a straightforward induction on $H$.
\end{rmrk}

\begin{lem}\label{lem:plus-projection}
	Let $N$ be a term such that $\fl{N} \subseteq \{a\}$.
	\begin{enumerate}
		\item\label{lem:plus-projection-base} 	Then, $\proj{a}{i}{N}^+ = \proj{a}{i}{N}$ for all $i \in \{0,1\}$.
		\item\label{lem:plus-projection-head} If $H$ is a head context, then $H[\proj{a}{i}{N}]^+ = H[\proj{a}{i}{N}]$.
	\end{enumerate}
\end{lem}

\begin{proof}
	\begin{enumerate}
		\item By straightforward induction on $N$.
		\item By straightforward induction on $H$, the base case is \Cref{lem:plus-projection-base}.
		\qedhere 
	\end{enumerate}
\end{proof}

\begin{prop}
Let $N$ a label-closed term. If $N\rw_\pi M$ then there is a $P$ such that $N\rws_\perm P$ with $P^+=M$.
\end{prop}

%\begin{proof}
%	By induction on the definition of $N \rw_\pi M$. Cases:
%	\begin{itemize}
%		\item \emph{Step at the root}, \ie\ $N = \trm{!a.N'} \rw_\pi \proj{a}{0}{N'} + \proj{a}{1}{N'}$.
%		
%		\item \emph{Abstraction}, \ie\ $N = \lambda x. N' \rw_\pi \lambda x. M' = M$ with $N' \rw_\pi M'$.
%		Let $P = M$: thus, $N  \rws_\perm = P$ (since $\rws_\perm$ is reflexive) with $P^+ =  (\lambda x.P')^+ = \lambda x. P' $.
%		
%		\item \emph{Application}, \ie\ $N = N'Q \rw_\pi M'Q = M$ with $N' \rw_\pi M'$.
%		By \ih, there is $P'$ such that $N' \rws_\perm P'$ and $P'^+ = M'$. 
%		\qed
%	\end{itemize}
%\end{proof}
\begin{proof}
	Since $N\rw_\pi M$, then $N = H[\trm{!a.N'}]$ and $M = H[\proj a0{N'}] + H[\proj a1{N'}]$.
	We prove the proposition by induction on $N'$. Cases:
	\begin{itemize}
		\item \emph{Superposition}, \ie\ $N = H[\trm{!a.N_0 +b N_1}] \rw_\pi H[\proj{a}{0}{N_0 +b N_1}] + H[\proj{a}{1}{N_0 +b N_1}] \allowbreak= M$.
		Since $N$ is label-closed and the head context cannot close $\trm{+b}$, then $b = a$.
		Therefore, $M = H[\proj{a}{0}{N_0}] + H[\proj{a}{1}{N_1}]$.
		Let $P = \trm{!a}. H[\proj{a}{0}{N_0}] \trm{+a} \allowbreak H[\proj{a}{1}{N_1}]$.
		According to \Cref{rmrk:proj}, $N = H[\trm{!a.N_0 +a N_1}] \rws_\perm P 
			%\trm{!a}. H[\proj{a}{0}{N_0}] \trm{+a} H[\proj{a}{1}{N_1}]
		$ where $P^+ = \allowbreak (\trm{!a}. H[\proj{a}{0}{N_0}] \trm{+a} H[\proj{a}{1}{N_1}])^+ = (H[\proj{a}{0}{N_0}])^+ + (H[\proj{a}{1}{N_1}])^+ = \allowbreak H[\proj{a}{0}{N_0}] \allowbreak+ H[\proj{a}{1}{N_1}] = M$ (the last identity holds by \Cref{lem:plus-projection}.\ref{lem:plus-projection-head}).
		
		\item \emph{Variable}, \ie\ $N = H[\trm{!a}. x] \rw_\pi H[\proj{a}{0}{x}] + H[\proj{a}{1}{x}] =\allowbreak H[x] + H[x] = H[x] = M$.
%		$\proj{a}{0}{N''} + \proj{a}{1}{N''} = M$ with $N' \rw_\pi M'$.
		Let $P = \trm{!a}. H[x]$: thus, $N  \rws_\perm P$ with $P^+ =  \trm{!a}.H[x] \neq H[x] = M$.
		
		\item \emph{Abstraction}, \ie\ $N = H[\trm{!a}.\lambda x. Q] \rw_\pi H[\proj{a}{0}{\lambda x.Q}] + H[\proj{a}{1}{\lambda x.Q}] =\allowbreak H[\lambda x.\proj{a}{0}{Q}] + H[\lambda x.\proj{a}{1}{Q}] = M$.
		%		$\proj{a}{0}{N''} + \proj{a}{1}{N''} = M$ with $N' \rw_\pi M'$.
		Let $P = \trm{!a}. H[\lambda x.\proj{a}{0}{Q}] \trm{+a} H[\lambda x.\proj{a}{1}{Q}]$: thus, $N  \rws_\perm P$ with $P^+ =  H[\lambda x.\proj{a}{0}{Q}]^+ + H[\lambda x.\proj{a}{1}{Q}]^+ = H[\lambda x.\proj{a}{0}{Q}] + H[\lambda x.\proj{a}{1}{Q}] = M$.
		
		\item \emph{Application}, \ie\ $N = N'Q \rw_\pi M'Q = M$ with $N' \rw_\pi M'$.
		By \ih, there is $P'$ such that $N' \rws_\perm P'$ and $P'^+ = M'$. 
		\qedhere
	\end{itemize}
\end{proof}

\hrule



\subsection{Call-by-value translation}


The call-by-value interpretation $\uncbv{N}$ of a probabilistic lambda-term $N$ is a given as follows. First, we translate $N$ to an open $\PEL$-term $\unopen N=\labjudg\theta P$, and then $\uncbv{N}$ is the label closure $\uncbv{N}=\labclose\theta P$, which prefixes $P$ with a generator $\trm{!a}$ for every $a$ in $\theta$.

\begin{defn}
The \emph{label closure} $\labclose\theta P$ is given inductively as follows.
\[
	\labclose{}P = P \qquad \labclose{a\cdot\theta}P = \labclose\theta{\trm{!a.P}}
\]
The \emph{open interpretation} $\unopen N$ is given as follows, where $\unopen{N_i}=\labjudg{\theta_i}{P_i}$ for $i\in\{1,2\}$, and all labels are fresh.
\[
\begin{array}{r@{\quad}c@{\quad}l@{\qquad}r@{\quad}c@{\quad}l}
		\unopen x 		 &=& \labjudg{}x				& \unopen {N_1N_2}   &=& \labjudg{\theta_2\cdot\theta_1}{P_1P_2}
\\[5pt]	\unopen {\x.N_1} &=& \labjudg{\theta_1}{\x.P_1} & \unopen {N_1\+N_2} &=& \labjudg{\theta_2\cdot\theta_1\cdot a}{\trm{P_1 +a P_2}}
\end{array}
\]
The \emph{call-by-value interpretation} of a probabilistic lambda-term $N$ is
\[
	\uncbv N=\lfloor\unopen N\rfloor~.
\]
\end{defn}

{\color{red}NOTE: Please check thoroughly that I haven't messed up the order of labels in the notion of ``label closure''.}


\bibliographystyle{plain}
\bibliography{biblio}
\addcontentsline{toc}{section}{References}

\end{document}

%============================================================

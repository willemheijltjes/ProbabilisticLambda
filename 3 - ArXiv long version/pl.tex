\documentclass[runningheads,orivec]{llncs}

\let\proof\relax %To avoid incompatibility between llncs and amsthm
\let\endproof\relax %To avoid incompatibility between llncs and amsthm
\let\proofname\relax %To avoid incompatibility between llncs and ntheorem


%\usepackage[hidelinks]{hyperref}
\usepackage{amsmath,amssymb,mathtools,stmaryrd}
\usepackage[amsthm,hyperref,thmmarks]{ntheorem}
\usepackage{marvosym}
\usepackage{nicefrac}
\usepackage{xargs}

%\usepackage{fullpage}

\usepackage{xcolor}
\usepackage{tikz}
  \usetikzlibrary{arrows.meta}
  \usetikzlibrary{calc}
  \usetikzlibrary{matrix}
\usepackage{proof}

% Hyperlinks

\makeatletter
\RequirePackage[bookmarks,unicode,colorlinks=true]{hyperref}%
\def\@citecolor{blue}%
\def\@urlcolor{blue}%
\def\@linkcolor{blue}%
\def\UrlFont{\rmfamily}
\def\orcidID#1{\smash{\href{http://orcid.org/#1}{\protect\raisebox{-1.25pt}{\protect\includegraphics{orcid_color.eps}}}}}

%% theorem environments
\usepackage{cleveref}

\theoremstyle{definition}
\newtheorem{defn}{Definition}
\newtheorem{rmrk}[defn]{Remark}
%%
\theoremstyle{plain}
\newtheorem{conj} [defn]{Conjecture}
\newtheorem{cor}  [defn]{Corollary}
\newtheorem{lem}  [defn]{Lemma}
\newtheorem{prop} [defn]{Proposition}
\newtheorem{thm}  [defn]{Theorem}
\newtheorem{lemmaAppendix}{Lemma}
%%


%text
\newcommand{\eg}{\textit{e.g.}}
\newcommand{\ie}{\textit{i.e.}}
\newcommand{\ih}{\textit{i.h.}}

% coloneqq
\newcommand*\coloneq{
 \mathrel{%
  \rlap{\raisebox{0.3ex}{$\m@th\cdot$}}%
        \raisebox{-0.3ex}{$\m@th\cdot$}%
 {=}}}
\newcommand*\coloneqq{
 \mathrel{%
  \rlap{\raisebox{0.3ex}{$\m@th\cdot$}}%
        \raisebox{-0.3ex}{$\m@th\cdot$}%
  \rlap{\raisebox{0.3ex}{$\m@th\cdot$}}%
        \raisebox{-0.3ex}{$\m@th\cdot$}%
 {=}}}

% vcenter
\newcommand\vc[1]{\vcenter{\hbox{$#1$}}}

% Small operators:

\newcommand\smallbin[1]{\mathchoice
      {\mathbin{\raise.2ex \hbox{$\scriptstyle      #1$}}}%
      {\mathbin{\raise.2ex \hbox{$\scriptstyle      #1$}}}%
      {\mathbin{\raise.12ex\hbox{$\scriptscriptstyle#1$}}}%
      {\mathbin{           \hbox{$\scriptscriptstyle#1$}}}}%

\newcommand\smallsquare{\mathchoice{{\scriptstyle\square}}{{\scriptstyle\square}}{{\scriptscriptstyle\square}}{{\scriptscriptstyle\square}}}

\newcommand\Con{\wedge}
\newcommand\Imp{\rightarrow}

\newcommand\con{\kern1pt{\smallbin\Con}\kern1pt}
\newcommand\imp{\kern1pt{\smallbin\Imp}}


% ===== TERMS AND TYPES

% Probabilistic lambda-calculus
\newcommand\PEL{\Lambda_{\textsf{PE}}}

% Free variables
\newcommand\fv[1]{\mathsf{fv}(\trm{#1})}
\newcommand\fl[1]{\mathsf{fl}(\trm{#1})}

% colours
\colorlet{mgray}{black!40}
\colorlet{lgray}{black!25}
\colorlet{llgray}{black!15}

\colorlet{dblue}{blue!80!black}
\colorlet{dred}{red!80!black}

\colorlet{typecolor}{dblue}
\colorlet{termcolor}{dred}

\newcommand\typecolor{\color{typecolor}}
\newcommand\termcolor{\color{termcolor}}

\newcommand\black{\color{black}}
\newcommand\dblue{\color{dblue}}
\newcommand\dred{\color{dred}}


% types
\newcommand\type[1]{{\let\type@sup@color\termcolor\typecolor\typ{#1}}}
\newcommand\typ[1]{%
  %\vphantom J%
  \let\type@loop=\type@next%
  \type@loop#1,%
}
\newcommand\type@next[1]{%
  \ifx#1,\let\type@loop\type@end\else%
  \ifx#1_\let\type@loop\type@sub\else%
  \ifx#1^\let\type@loop\type@sup\else%
  \ifx#1*\con\else%
  \ifx#1-\kern1pt{\imp}\else%
  #1%
  \fi\fi\fi\fi\fi%
  \type@loop%
}
\newcommand\type@sup@color{}
\newcommand\type@sub[1]{_{#1}\let\type@loop\type@next\type@loop}
\newcommand\type@sup[1]{^{{\type@sup@color #1}}\let\type@loop\type@next\type@loop}
\newcommand\type@vec[1]{\vec{\kern.5pt#1\kern.5pt}\let\type@loop\type@next\type@loop}
\newcommand\type@end{\let\type@sup@color\relax}

% terms
\newcommand\x{\lambda x}
\newcommand\y{\lambda y}
\newcommand\z{\lambda z}

\newcommand\+[1][{}]{\kern1pt{\smallbin\oplus}_{#1}\kern1pt}

\newcommand\1{\bullet}
\newcommand\0{\circ}

\newcommand{\full}{\bullet}

\newcommand\ttrm[1]{\smash{\trm{#1}}}

\newcommand\term[1]{{\let\term@typecolor\typecolor\termcolor\trm{#1}}}
\newcommand\trm[1]{%
  \vphantom(%
  \let\term@loop=\term@next%
  \term@loop#1,%
}
\newcommand\term@next[1]{%
  \ifx#1,\let\term@loop\term@end\else%
  \ifx#1:\black\colon\term@typecolor\let\term@loop\term@type\else%
  \ifx#1_\let\term@loop\term@sub\else%
  \ifx#1^\let\term@loop\term@sup\else%
  \ifx#1!\let\term@loop\term@box\else%
  \ifx#1+\let\term@loop\term@prob\else%
  \ifx#1*^\1\else%
  \ifx#1o_\1\else%
  \ifx#1p_\perm\else%
  \ifx#1q_{\1\perm}\else%
  \ifx#1i{\kern1pt}^i\else
  \ifx#1v\plusval\else%
  \ifx#1<\lfloor\else%
  \ifx#1>\rfloor\else%
  \ifx#1..\,\else%
  \ifx#1=\kern1pt{\smallbin=}\kern1pt\else
  #1%
  \fi\fi\fi\fi\fi\fi\fi\fi\fi\fi\fi\fi\fi\fi\fi\fi%
  \term@loop%
}
\newcommand\term@typecolor{}
\newcommand\term@end{\let\term@typecolor\relax}
\newcommand\term@sub[1]{_{#1}\let\term@loop\term@next\term@loop}
\newcommand\term@sup[1]{^{#1}\let\term@loop\term@next\term@loop}
\newcommand\term@vec[1]{\vec{\kern.5pt#1\kern.5pt}\let\term@loop\term@next\term@loop}
\newcommand\term@val[1]{\kern1pt\raisebox{-.5pt}{$\overset{\raisebox{-1pt}{$\scriptstyle#1$}}{{\smallbin\oplus_{\makebox[0pt][l]{$\scriptstyle\val$}}}}$}\kern5pt\let\term@loop\term@next\term@loop}
\newcommand\term@prob[1]{\kern1pt\raisebox{-.5pt}{$\overset{\raisebox{-1pt}{$\scriptstyle#1$}}{{\smallbin\oplus}}$}\kern1pt\let\term@loop\term@next\term@loop}
\newcommand\term@type{\let\type@loop=\type@next\type@loop}
\newcommand\term@box[1]{\probox{#1}\let\term@loop\term@next\term@loop}

\newcommand\probox[1]{\begin{tikzpicture}[baseline=0]\node[anchor=base](a){$\scriptstyle #1\vphantom)$};\draw[line width=.6pt] (-5pt,-2.5pt) rectangle (5pt,7.5pt);\end{tikzpicture}}


% label judgments
\newcommand{\labjudg}[2]{#1\vdash_{L} #2}
\newcommand{\arrow}{\Rightarrow}
\newcommand{\judg}[3]{#1\vdash #2:#3}

% rewriting
\newcommand\rw[1][{}]{\stackrel{#1}\rightsquigarrow}
\newcommand\dw{\rotatebox[origin=c]{270}{$\rw$}}
\newcommand\lw{\rotatebox[origin=c]{180}{$\rw$}}
\newcommand\lrw{\rotatebox[origin=c]{180}{$\lw\!\rw$}}
\newcommand\perm{\mathsf p}
\newcommand\ph{{\pi{\mathsf h}}}

\newcommand\confluence[4]{\begin{array}{ccc} \trm{#1} & \rw & \trm{#2} \\ \dw && \dw \\ \trm{#3} & \rw & \trm{#4} \end{array}}

\newcommand\rstrut{\rule{0pt}{13pt}}

\newcommand\SN{\textsf{SN}}

\newcommand\proj[3]{\pi^{#1}_{#2}(\trm{#3})}

% strategies
\newcommand\cbn{\mathsf{cbn}}
\newcommand\cbv{\mathsf{cbv}}

\newcommand\val{\mathsf{v}}
\newcommand\plusval{\mathbin{\smallbin\oplus_\val}}

% translations
\newcommand\uncbv[1]{\llbracket#1\rrbracket_\val}
\newcommand\unopen[1]{\llbracket#1\rrbracket_{\mathsf{open}}}
\newcommand\labclose[2]{\lfloor\labjudg{#1}{#2}\rfloor}

% new rewriting

\tikzstyle{implied}=[dashed]
\tikzstyle{rwhead}=[>/.tip={Triangle[open,length=2.5pt,width=4.5pt]},|/.tip={Rectangle[length=.5pt,width=4.5pt]}]
\tikzstyle{rwblack}=[>/.tip={Triangle[length=2.5pt,width=4.5pt]},|/.tip={Rectangle[length=.5pt,width=4.5pt]}]
\tikzstyle{rw} =[line width=.5pt,rwhead,->]
\tikzstyle{rwb}=[line width=.5pt,rwblack,->]
\tikzstyle{rwbs}=[line width=.5pt,rwblack,->.>]
\tikzstyle{rws}=[line width=.5pt,rwhead,->.>]
\tikzstyle{rwn}=[line width=.5pt,rwhead,->.>|]
\tikzstyle{rwbn}=[line width=.5pt,rwblack,->.>|]
\tikzstyle{rwp}=[line width=.5pt,rwhead,->,double]
\tikzstyle{rwx}=[line width=.5pt,rwhead,->.>,double]

\renewcommand\rw{\mathrel{\tikz\draw[rw](0,0)--(10pt,0pt);}}
\newcommand\rwb{\mathrel{\tikz\draw[rwb](0,0)--(10pt,0pt);}}
\newcommand\rwbs{\mathrel{\tikz\draw[rwbs](0,0)--(10pt,0pt);}}
\newcommand\rws{\mathrel{\tikz\draw[rws](0,0)--(10pt,0pt);}}
\newcommand\rwn{\mathrel{\tikz\draw[rwn](0,0)--(10pt,0pt);}}
\newcommand\rwbn{\mathrel{\tikz\draw[rwbn](0,0)--(10pt,0pt);}}
\newcommand\rwp{\mathrel{\tikz\draw[rwp](0,0)--(10pt,0pt);}}
\newcommand\rwx{\mathrel{\tikz\draw[rwx](0,0)--(10pt,0pt);}}
\newcommand\rwps{\mathrel{\tikz\draw[rwx](0,0)--(10pt,0pt);}}

\newcommand\rwpleft{\mathrel{\tikz\draw[rwp](10pt,0pt)--(0,0);}}
\newcommand\rwxleft{\mathrel{\tikz\draw[rwx](10pt,0pt)--(0,0);}}
\newcommand\rwsleft{\mathrel{\tikz\draw[rws](10pt,0pt)--(0,0);}}

% rule names

\newcommand\idem{\ensuremath{\mathsf i}}
\newcommand\cancelL{\ensuremath{\mathsf c_1}}
\newcommand\cancelR{\ensuremath{\mathsf c_2}}
\newcommand\plusAbs{\ensuremath{{\smallbin\oplus}\lambda}}
\newcommand\plusArg{\ensuremath{{\smallbin\oplus}\mathsf a}}
\newcommand\plusFun{\ensuremath{{\smallbin\oplus}\mathsf f}}
\newcommand\plusBox{\ensuremath{{\smallbin{\oplus}\smallsquare}}}
\newcommand\plusL{\ensuremath{{\smallbin\oplus}{\smallbin\oplus}_1}}
\newcommand\plusR{\ensuremath{{\smallbin\oplus}{\smallbin\oplus}_2}}
\newcommand\plusX{\ensuremath{{\smallbin\oplus}{\star}}}
\newcommand\boxVoid{\ensuremath{\not{\kern-2pt\smallsquare}}}
\newcommand\boxAbs{\ensuremath{\smallsquare\lambda}}
\newcommand\boxFun{\ensuremath{\smallsquare\mathsf f}}


\makeatother

% reducibility

\newcommand{\RedSet}[1]{\mathit{Red}_{#1}}

% streams

\newcommand\Streams{\mathbb S}

% environments

\newdimen\boxwidth
\setlength\boxwidth{\linewidth}
\addtolength\boxwidth{-10pt}

\newcommandx\figframe[3][1=0pt,3=0pt]{\noindent\framebox[\textwidth][c]{\begin{minipage}{\boxwidth}\vspace*{#1}#2\vspace*{#3}\end{minipage}}}

\newenvironment{varitemize}
{
\begin{list}{\labelitemi}
{\setlength{\itemsep}{0pt}
 \setlength{\topsep}{0pt}
 \setlength{\parsep}{0pt}
 \setlength{\partopsep}{0pt}
 \setlength{\leftmargin}{15pt}
 \setlength{\rightmargin}{0pt}
 \setlength{\itemindent}{0pt}
 \setlength{\labelsep}{5pt}
 \setlength{\labelwidth}{10pt}
}}
{
 \end{list}
}

% top-level "item" command
\newcommand\itm[2]{\medskip\noindent(#1)}

%============================================================ FRONTMATTER

\title{Decomposing Probabilistic Lambda-Calculi}
\subtitle{(Long version)}


\author{
	 Ugo Dal Lago\inst{1}\orcidID{0000-0001-9200-070X}
\and Giulio Guerrieri\inst{2}\textsuperscript{(\Letter)}\orcidID{0000-0002-0469-4279}
\and Willem Heijltjes\inst{2}
}

\authorrunning{U.\ Dal Lago, G.\ Guerrieri, and W.\ Heijltjes}
%\titlerunning{

\institute{%
	Dipartimento di Informatica - Scienza e Ingegneria
\\	Universit\`a di Bologna, Bologna, Italy
\\	\email{ugo.dallago@unibo.it}
\\[10pt]\and%
	Department of Computer Science
\\	University of Bath, Bath, UK
\\	\email{\{w.b.heijltjes,g.guerrieri\}@bath.ac.uk}
}



%============================================================ DOCUMENT

\begin{document}

\maketitle

\begin{abstract}
A notion of probabilistic lambda-calculus usually comes with a prescribed reduction strategy, typically call-by-name or call-by-value, as the calculus is non-confluent and these strategies yield different results. This is a break with one of the main advantages of lambda-calculus: confluence, which means results are independent from the choice of strategy.
We present a probabilistic lambda-calculus where the probabilistic operator is decomposed into two syntactic constructs: a generator, which represents a probabilistic event; and a consumer, which acts on the term depending on a given event. The resulting calculus, the Probabilistic Event Lambda-Calculus, is confluent, and interprets the call-by-name and call-by-value strategies through different interpretations of the probabilistic operator into our generator and consumer constructs.
We present two notions of reduction, one via fine-grained local rewrite steps, and one by generation and consumption of probabilistic events. Simple types for the calculus are essentially standard, and they convey strong normalization. We demonstrate how we can encode call-by-name and call-by-value probabilistic evaluation.
\end{abstract}

\section{Introduction}

Probabilistic lambda-calculi \cite{SahebDjahromi78,Manber-Tompa-1982,JonesPlotkin89,deLiguoroPiperno95,JungTix98,DalLagoZorzi12,FaggianRonchi19} extend the standard lambda-calculus with a probabilistic choice operator $N\+[p]M$, which chooses $N$ with probability $p$ and $M$ with probability $1-p$ (throughout this paper, we let $p$ be $\nicefrac12$ and will omit it). Duplication of $N\+M$, as is wont to happen in lambda-calculus, raises a fundamental question about its semantics: do the duplicate occurrences represent \emph{the same} probabilistic event, or \emph{different} ones with the same probability? For example, take the formula $\top\+\bot$ that represents a coin flip between boolean values \emph{true} $\top$ and \emph{false} $\bot$. If we duplicate this formula, do the copies represent two distinct coin flips with possibly distinct outcomes, or do these represent a single coin flip that determines the outcome for both copies? Put differently again, when we duplicate $\top\+\bot$, do we duplicate the \emph{event}, or only its \emph{outcome}?

In probabilistic lambda-calculus, these two interpretations are captured by the evaluation strategies of call-by-name ($\rw_\cbn$), which duplicates events, and call-by-value ($\rw_\cbv$), which evaluates any probabilistic choice before it is duplicated, and thus only duplicates outcomes. Consider the following example, where $=$ tests equality of boolean values.
\[
	\top \quad {}_\cbv\!\rwsleft \quad (\x.\,x = x)(\top\+\bot) \quad \rws_\cbn \quad \trm{\top\+\bot}
\]
This situation is not ideal, for several, related reasons. Firstly, it demonstrates how probabilistic lambda-calculus is non-confluent, negating one of the central properties of the lambda-calculus, and one of the main reasons why it is the prominent model of computation that it is. Secondly, it means that a probabilistic lambda-calculus must derive its semantics from a prescribed reduction strategy, and its terms only have meaning in the context of that strategy. Thirdly, combining different kinds of probabilities becomes highly involved~\cite{FaggianRonchi19}, as it would require specialized reduction strategies. These issues present themselves even in a more general setting, namely that of commutative (algebraic) effects, which in general do not commute with copying.

We address these issues by a decomposition of the probabilistic operator into a \emph{generator} $\ttrm{!a}$ and a \emph{choice} $\ttrm{+a}$, as follows.
\[
	\trm{N \+ M} \quad\stackrel\Delta=\quad \trm{!a. N +a M}
\]
Semantically, $\ttrm{!a}$ represents a probabilistic event, that generates a boolean value recorded as $a$. The choice $\ttrm{N+aM}$ is simply a conditional on $a$, choosing $N$ if $a$ is false and $M$ if $a$ is true. Syntactically, $a$ is a boolean variable with an occurrence in $\ttrm{+a}$, and $\ttrm{!a}$ acts as a probabilistic quantifier, binding all occurrences in its scope. (To capture a non-equal chance, one would attach a probability $p$ to a generator, as $\ttrm{!a}{\kern1pt}_p$, though we will not do so in this paper.)

The resulting \emph{probabilistic event lambda-calculus} $\PEL$, which we present in this paper, is confluent. Our decomposition allows us to separate duplicating an \emph{event}, represented by the generator $\ttrm{!a}$, from duplicating only its \emph{outcome} $a$, through having multiple choice operators $\trm{+a}$. In this way our calculus may interpret both original strategies, call-by-name and call-by-value, by different translations of standard probabilistic terms into $\PEL$: call-by-name by the above decomposition (see also Section~\ref{sec:PEL}), and call-by-value by a different one (see Section~\ref{sec:cbv}). For our initial example, we get the following translations and reductions.
%
\begin{alignat}{3}
\cbn: \quad & \trm{(\x.x = x)(!a.\top+a\bot)} & \quad \rw_\beta \quad & \trm{(!a.\top+a\bot)=(!b.\top+b\bot)} & \quad \rws \quad & \top\+\bot \label{eq:cbn}
\\
\cbv: \quad & \trm{!a.(\x.x = x)(\top+a\bot)} & \quad \rw_\beta \quad & \trm{!a.(\top+a\bot)=(\top+a\bot)}    & \quad \rws \quad & \top \label{eq:cbv}
\end{alignat}

We present two reduction relations for our probabilistic constructs, both independent of beta-reduction. Our main focus will be on \emph{permutative} reduction (Sections~\ref{sec:PEL},~\ref{sec:p-reduction}), a small-step local rewrite relation which is computationally inefficient but gives a natural and very fine-grained operational semantics. \emph{Projective} reduction (Section~\ref{sec:projective-reduction}) is a more standard reduction, following the intuition that $\ttrm{!a}$ generates a coin flip to evaluate $\ttrm{+a}$, and is courser but more efficient.

We further prove confluence (Section~\ref{sec:confluence}), and we give a system of simple types and prove strong normalization for typed terms by reducibility (Section~\ref{sec:SN}).

This is the longer version of~\cite{fossacs} that includes all proofs.

\subsection{Related Work}

Probabilistic $\lambda$-calculi are a topic of study since the pioneering work by Saheb-Djaromi~\cite{SahebDjahromi78}, the first to give the syntax and operational semantics of a $\lambda$-calculus with binary probabilistic choice. Giving well-behaved denotational models for probabilistic $\lambda$-calculi has proved to be challenging, as witnessed by the many contributions spanning the last thirty years: from Jones and Plotkin's early study of the probabilistic powerdomain~\cite{JonesPlotkin89}, to Jung and Tix's remarkable (and mostly negative) observations~\cite{JungTix98}, to the very recent encouraging results by Goubault-Larrecq~\cite{GoubaultLarrecq19}. A particularly well-behaved model for probabilistic $\lambda$-calculus can be obtained by taking a probabilistic variation of Girard's coherent spaces~\cite{DanosEhrhard11}, this way getting full abstraction~\cite{EPT18}.

On the operational side, one could mention a study about the various ways the operational semantics of a calculus with binary probabilistic choice can be specified, namely by small-step or big-step semantics, or by inductively or coinductively defined sets of rules~\cite{DalLagoZorzi12}. Termination and complexity analysis of higher-order probabilistic programs seen as $\lambda$-terms have been studied by way of type systems in a series of recent results about size~\cite{DalLagoGrellois19}, intersection~\cite{BreuvartDalLago18}, and refinement type disciplines \cite{AvanziniDalLagoGhyselen19}. Contextual equivalence on probabilistic $\lambda$-calculi has been studied, and compared with equational theories induced by B\"ohm Trees~\cite{Leventis18}, applicative bisimilarity~\cite{DalLagoSangiorgiAlberti14}, or environmental bisimilarity~\cite{SangiorgiVignudelli16}.

In all the aforementioned works, probabilistic $\lambda$-calculi have been taken as implicitly endowed with either call-by-name or call-by-value strategies, for the reasons outlined above. There are only a few exceptions, namely some works on Geometry of Interaction~\cite{DLFVY17}, Probabilistic Coherent Spaces~\cite{EhrhardTasson19}, and Standardization~\cite{FaggianRonchi19}, which achieve, in different contexts, a certain degree of independence from the underlying strategy, thus accomodating both call-by-name and call-by-value evaluation. The way this is achieved, however, invariably relies on Linear Logic or related concepts. This is deeply different from what we do here.

Some words of comparison with Faggian and Ronchi's work on confluence and standardization~\cite{FaggianRonchi19} are also in order. The main difference between their approach and the one we pursue here is that the operator $!$ in their calculus $\Lambda_\oplus^!$ plays \emph{both} the roles of a marker for duplicability and of a checkpoint for any probabilistic choice "flowing out" of the term (\ie\ being fired). In our calculus, we do not control duplication, but we definitely make use of checkpoints. Saying it another way, Faggian and Ronchi's work is inspired by linear logic, while our approach is inspired by deep inference, even though this is, on purpose, not evident in the design of our calculus. 

Probabilistic $\lambda$-calculi can also be seen as vehicles for expressing probabilistic models in the sense of bayesian programming~\cite{Ramsey-Pfeffer-2002,BDLGS16}. This, however, requires an operator for modeling conditioning, which complictes the metatheory considerably, and that we do not consider here.

Our permutative reduction is a refinement of that for the call-by-name probabilistic $\lambda$-calculus~\cite{Leventis19}, and is an implementation of the equational theory of \emph{(ordered) binary decision trees} via rewriting~\cite{Zantema-Pol-2001}. Probabilistic decision trees have been proposed with a primitive binary probabilistic operator~\cite{Manber-Tompa-1982}, but not a decomposition as we explore here.


%============================================================ PEL

\section{\texorpdfstring{The Probabilistic Event $\lambda$-Calculus $\PEL$}{The Probabilistic Event Lambda-Calculus PEL}}
\label{sec:PEL}

\begin{defn}
The \emph{probabilistic event $\lambda$-calculus} ($\PEL$) is given by the following grammar, with from left to right: a \emph{variable} (denoted by $x, y, z, \dots$), an \emph{abstraction}, an \emph{application}, a \emph{(labeled) choice}, and a \emph{(probabilistic) generator}.
\[
	M,N \quad\coloneqq\quad x ~\mid~ \x.N ~\mid~ NM ~\mid~ \trm{N +a M} ~\mid~ \trm{!a.N}
\]
\end{defn}
%
\noindent
In a term $\trm{\x.M}$ the abstraction $\x$ binds the free occurrences of the variable $x$ in its scope $\trm{M}$, and in $\ttrm{!a.N}$ the generator $\ttrm{!a}$ binds the \emph{label} $a$ in $\trm{N}$. The calculus features a decomposition of the usual probabilistic sum $\trm{\+}$, as follows.
%
\begin{align}
\label{eq:unlabeled}
	N\+M \quad\stackrel\Delta=\quad \trm{!a. N +a M}
\end{align}
%
The generator $\ttrm{!a}$ represents a probabilistic \emph{event}, whose outcome, a binary value $\{0,1\}$ represented by the label $a$, is used by the choice operator $\ttrm{+a}$. That is, $\ttrm{!a}$ flips a coin setting $a$ to $0$ (resp. $1$), and depending on this $\ttrm{N+aM}$ reduces to $N$ (resp. $M$). We will use the unlabeled choice $\+$ as in \eqref{eq:unlabeled}. %the above abbreviation. 
This convention also gives the translation from a \emph{call-by-name} probabilistic $\lambda$-calculus into $\PEL$ %(we formalize
(the interpretation of a \emph{call-by-value} probabilistic $\lambda$-calculus is in Section~\ref{sec:cbv}).



\begin{figure}[!t]
\figframe[-4pt]{\begin{align}
	(\x.N)M 				&\rw_\beta N[M/x]																\tag{$\beta$}
\\																											\notag
\\	\trm{N +a N}			&\rw_\perm N																	\tag{\idem}
\\	\trm{(N +a M) +a P}		&\rw_\perm \trm{N +a P}					\rstrut									\tag{\cancelL}
\\	\trm{N +a (M +a P)}		&\rw_\perm \trm{N +a P}					\rstrut									\tag{\cancelR}
\\																											\notag
\\	\trm{\x.(N +a M)}		&\rw_\perm \trm{(\x.N) +a (\x.M)}												\tag{\plusAbs}
\\	\trm{(N +a M) P}		&\rw_\perm \trm{(NP) +a (MP)}			\rstrut									\tag{\plusFun}
\\	\trm{N (M +a P)}		&\rw_\perm \trm{(NM) +a (NP)}			\rstrut									\tag{\plusArg}
\\	\trm{(N +a M) +b P}		&\rw_\perm \trm{(N +b P) +a (M +b P)} 	\rstrut	&& (\text{if } a\smallbin<b)	\tag{\plusL}
\\	\trm{N +b (M +a P)}		&\rw_\perm \trm{(N +b M) +a (N +b P)} 	\rstrut	&& (\text{if } a\smallbin<b)	\tag{\plusR}
\\	\trm{!b.(N +a M)}		&\rw_\perm \trm{(!b.N) +a (!b.M)}		\rstrut	&& (\text{if } a\neq b)			\tag{\plusBox}
\\																								\notag
\\	\trm{!a.N}				&\rw_\perm N 									&& (\text{if } a\notin \fl{N})	\tag{\boxVoid}
\\	\trm{\x.!a.N} 			&\rw_\perm \trm{!a.\x. N}				\rstrut									\tag{\boxAbs}
\\	\trm{(!a.N)M}			&\rw_\perm \trm{!a.(NM)}				\rstrut	&& (\text{if } a\notin \fl{M})	\tag{\boxFun}
\end{align}
}[-10pt]
\caption{Reduction rules for $\beta$-reduction and $\perm$-reduction.}
\label{fig:reduction rules}
\end{figure}

\subsubsection{Reduction.}

Reduction in $\PEL$ will consist of standard $\beta$-reduction $\rw_\beta$ plus an evaluation mechanism for generators and choice operators, which implements probabilistic choice. We will present two such mechanisms: \emph{projective} reduction~$\rw_\pi$ and \emph{permutative} reduction~$\rw_\perm$. While projective reduction implements the given intuition for the generator and choice operator, we relegate it to Section~\ref{sec:projective-reduction} and make permutative reduction our main evaluation mechanism, for the reason that it is more fine-grained, and thus more general.

Permutative reduction is based on the idea that any operator distributes over the labeled choice operator (see the reduction steps in Figure~\ref{fig:reduction rules}), even other choice operators, as below.
\[
	\trm{(N +a M) +b P}	~\sim~ \trm{(N +b P) +a (M +b P)}
\]
To orient this as a rewrite rule, we need to give priority to one label over another. Fortunately, the relative position of the associated generators $\ttrm{!a}$ and $\ttrm{!b}$ provides just that. Then to define $\rw_\perm$, we will want every choice to belong to some generator, and make the order of generators explicit.

\begin{defn}
	The set $\fl{N}$ of \emph{free labels} of a term $\trm{N}$ is defined inductively by:
	\begin{align*}
		\fl{x} &= \emptyset & \fl{MN} &= \fl{M} \cup \fl{N}  & \fl{\x.M} &= \fl{M} \\
		\fl{!a.M} &= \fl{M} \smallsetminus \{a\} & \fl{M +a N} &= \fl{M}\cup \fl{N} \cup \{a\}
	\end{align*}
	A term $\trm{M}$ is \emph{label-closed} if $\fl{M} = \emptyset$.
\end{defn}

From here on, we consider only label-closed terms (we implicitly assume this, unless otherwise stated). All terms are identified up to renaming of their bound variables and labels. Given some terms $\trm{M}$ and $\trm{N}$ and a variable $\trm{x}$, $\trm{M[N/x]}$ is the capture-avoiding (for both variables and labels) substitution of $\trm{N}$ for the free occurrences of $\trm{x}$ in $\trm{M}$.
We speak of a \emph{representative} $\trm{M}$ of a term when $\trm{M}$ is not considered up to such a renaming. A representative $\trm{M}$ of a term is \emph{well-labeled} if for every occurrence of $\probox a$ in $\trm{M}$ there is no $\probox a$ occurring in its scope.

\begin{defn}[Order for labels]
\label{def:orderlabels}
	Let $\trm{M}$ be a well-labeled representative of a term.
	We define an \emph{order} $<_{{\trm{M}}}$ for the labels occurring in $\trm{M}$ as follows: $a <_{\trm{M}} b$ if and only if $\probox b$ occurs in the scope of $\probox a$.
\end{defn}

\noindent
For a well-labeled and label-closed representative $\trm{M}$, $<_{\trm{M}}$ is a finite tree order.


\begin{defn}
\emph{Reduction} $\rw \,=\, \rw_\beta \cup \rw_\perm$ in $\PEL$ consists of \emph{$\beta$-reduction}~$\rw_\beta$ and \emph{permutative} or \emph{$\perm$-reduction}~$\rw_\perm$, both defined as the contextual closure of the rules given in Figure~\ref{fig:reduction rules}. We write $\rws$ for the reflexive--transitive closure of $\rw$, and $\rwn$ for reduction to normal form; similarly for $\rw_\beta$ and $\rw_\perm$. We write $=_\perm$ for the symmetric and reflexive--transitive closure of $\rw_\perm$.
\end{defn}

Two example reductions are \eqref{eq:cbn}-\eqref{eq:cbv} on p.~\pageref{eq:cbn}; a third, complete reduction is in Figure~\ref{fig:example reduction}. The crucial feature of $\perm$-reduction is that a choice $\ttrm{+a}$ \emph{does} permute out of the argument position of an application, but a generator $\ttrm{!a}$ does \emph{not}, as below. Since the argument of a redex may be duplicated, this is how we characterize the difference between the \emph{outcome} of a probabilistic event, whose duplicates may be identified, and the event itself, whose duplicates may yield different outcomes.
\[
	\trm{N\,(M +a P)}~\rw_\perm~ \trm{(NM) +a (NP)}
	\qquad
	\qquad
	\trm{N\,(!a.M)}~\not\rw_\perm~\trm{!a.N\,M}
\]
By inspection of the rewrite rules in Figure~\ref{fig:reduction rules}, we can then characterize the normal forms of $\rw_\perm$ and $\rw$ as follows.

\begin{prop}[Normal forms]
The normal forms $P_0$ of $\rw_\perm$, respectively $N_0$ of $\rw$, are characterized by the following grammars.
\[
	\begin{array}{ccc@{~}c@{~}c@{}l}
		P_0 &\coloneqq& P_1 &\mid& \trm{P_0 \+ P_0'}
	\\	P_1	&\coloneqq& x   &\mid& \x.P_1 			 &~\mid~ P_1\,P_0
	\end{array}
	\qquad\qquad
	\begin{array}{ccc@{~}c@{~}c}
		N_0 &\coloneqq& N_1 &\mid& \trm{N_0 \+ N_0'}
	\\	N_1	&\coloneqq& N_2 &\mid& \x.N_1
	\\	N_2 &\coloneqq& x	&\mid& N_2\,N_0
	\end{array}
\]
\end{prop}

\begin{figure}[!t]
  \newcommand\fit[1]{\makebox[36pt][c]{$#1$}}%
    \fbox{
    \begin{minipage}{.97\textwidth}
      \vspace{-4pt}
      \begin{align*}
	\trm{!a.(\x.x = x)(\top+a\bot)}
	& \fit{\rw_\perm}	\trm{!a.(\x.x=x)\top~+a~(\x.x=x)\bot}	\tag\plusArg
        \\		& \fit{\rws_\beta}	\trm{!a.(\top=\top)\,+a\,(\bot=\bot)}
        \\		& \fit{=}			\trm{!a. \top +a \top}
	\fit{\rw_\perm} 	\trm{!a. \top}
	\fit{\rw_\perm}	\top           						 	\tag{\idem,\boxVoid}
      \end{align*}
      \vspace{-10pt}
      \end{minipage}}
  \caption{Example reduction of the $\cbv$-translation of the term on p.~\pageref{eq:cbv}.}
  \label{fig:example reduction}
\end{figure}

%============================================================ P-REDUCTION

\section{Properties of Permutative Reduction}
\label{sec:p-reduction}

We will prove strong normalization and confluence of $\rw_\perm$. 
For strong normalization, the obstacle is the interaction between different choice operators, which may duplicate each other, creating super-exponential growth.\footnote{This was inferred only from a simple simulation; we would be interested to know a rigorous complexity result.} Fortunately, Dershowitz's \emph{recursive path orders}~\cite{Dershowitz82} seem tailor-made for our situation.


Observe that the set $\PEL$ endowed with $\rw_\perm$ is a first-order term rewriting system over a countably infinite set of variables and the signature $\Sigma$ given by:
\begin{varitemize}
	\item the binary function symbol $\trm{+a}$, for any label $a$;
	\item the unary function symbol $\ttrm{!a}$, for any label $a$;
	\item the unary function symbol $\trm{\x}$, for any variable $x$;
	\item the binary function symbol $\trm{@}$, letting $@(\trm{M},\trm{N})$ stand for $MN$.
\end{varitemize}

\begin{defn}
Let $\trm{M}$ be a well-labeled representative of a label-closed term, and let $\Sigma_M$ be the set of signature symbols occurring in $\trm{M}$. We define $\prec_M$ as the (strict) partial order on $\Sigma_M$ generated by the following rules.
\[
\begin{array}{rcl@{\qquad\quad}l}
	\trm{+a} &\prec_M& \trm{+b} & \text{ if } a <_M b
\\	\trm{+a} &\prec_M& \trm{!b} & \text{ for any labels } a,b
\\	\trm{!b} &\prec_M& @,\x		& \text{ for any label } b
\end{array}
\]
\end{defn}

\begin{lem}
\label{lemma:strong-normalization}
	The reduction $\rw_\perm$ is strongly normalizing.
\end{lem}

\begin{proof}
For the first-order term rewriting system $(\PEL, \rw_\perm)$ we derive a well-founded recursive path ordering $<$ from $\prec_M$ following \cite[p. 289]{Dershowitz82}. Let $f$ and $g$ range over function symbols, let $[N_1,\dots,N_n]$ denote a multiset and extend $<$ to multisets by the standard multiset ordering, and let $N = f(N_1,\dots,N_n)$ and $M = g(M_1,\dots,M_m)$; then
\[
N < M \iff
\left\{
\begin{array}{ll}
	[N_1,\dots,N_n] < [M_1,\dots,M_m] & \text{ if } f = g
\\[5pt]
	[N_1,\dots,N_n] < [M]			  & \text{ if } f \prec_M g
\\[5pt]
	[N] \leq [M_1,\dots,M_m]		  & \text{ if } f \npreceq_M g~.
\end{array}
\right.
\]
While $\prec_M$ is defined only relative to $\Sigma_M$, reduction may only reduce the signature. Inspection of Figure~\ref{fig:reduction rules} then shows that $M \rw_\perm N$ implies $N<M$.
\end{proof}

\subsubsection{Confluence of Permutative Reduction.}

With strong normalization, confluence of $\rw_\perm$ requires only local confluence. We reduce the number of cases to consider, by casting the permutations of $\ttrm{+a}$ as instances of a common shape.
%
\begin{defn}
We define a \emph{context} $C[\,]$ (with exactly one hole $[\,]$) as follows, and let $C[N]$ represent $C[\,]$ with the hole $[\,]$ replaced by $N$.
\[
\begin{array}{lll@{~}l@{~}l@{~}l@{~}l}
	C[\,] &\coloneqq& [\,] &\mid& \lambda x.C[\,] &\mid& C[\,]M ~\mid~ NC[\,] ~\mid~ \trm{C[\,]+aM} ~\mid~ \trm{N+aC[\,]} ~\mid~ \trm{!a.C[\,]}
\end{array}
\]
\end{defn}
%
Observe that the six reduction rules $\plusAbs$ through $\plusBox$ in Figure~\ref{fig:reduction rules} are all of the following form. We refer to these collectively as $\plusX$.
\begin{align}
	\trm{C[N+aM]} \rw_\perm \trm{C[N]+aC[M]}
	\tag\plusX
\end{align}

\begin{lem}[Confluence of $\rw_\perm$]
\label{lem:confluence-perm}
Reduction $\rw_\perm$ is confluent.
\end{lem}

\begin{proof}
We prove local confluence; by Newman's lemma and strong normalization of $\rw_\perm$ (\Cref{lemma:strong-normalization}), confluence follows. We consider each reduction rule against those lower down in Figure~\ref{fig:reduction rules}. For the symmetric rule pairs $\cancelL$/$\cancelR$, $\plusL$/$\plusR$, and $\plusFun/\plusArg$ we present only the first case. Unless otherwise specified, we let $a<b<c$.

%=====
\itm\idem{\trm{N +a N}\rw N}
\[
	\vc{\begin{tikzpicture}[x=20pt,y=1.5ex]
		\node[anchor=base east] (a) at (0,0) {$\trm{(N+aN)+aM}$};
		\node[anchor=base west] (b) at (1,0) {$\trm{N+aM}$};
		\draw[rw] (0,1) --node[above]{$\idem$}    (1,1);
		\draw[rw] (0,0) --node[below]{$\cancelL$} (1,0);
	\end{tikzpicture}}
\]
\[
	\vc{\begin{tikzpicture}[x=80pt,y=40pt]
		\node (N) at (0,1) {$\trm{(N+aM)+a(N+aM)}$};
		\node (M) at (1,1) {$\trm{N+aM}$};
		\node (P) at (0,0) {$\trm{N+a(N+aM)}$};
		\draw[rw] (N) --node[above]{$\idem$}    (M);
		\draw[rw] (N) --node[left] {$\cancelL$} (P);
		\draw[rw,implied] (P) --node[below right=-2pt] {$\cancelR$} (M);
	\end{tikzpicture}}
	\qquad
	\vc{\begin{tikzpicture}[x=80pt,y=40pt]
		\node (N) at (0,1) {$\trm{C[N+aN]}$};
		\node (M) at (1,1) {$\trm{C[N]}$};
		\node (P) at (0,0) {$\trm{C[N]+aC[N]}$};
		\draw[rw] (N) --node[above]{$\idem$}  (M);
		\draw[rw] (N) --node[left] {$\plusX$} (P);
		\draw[rw,implied] (P) --node[below right=-2pt] {$\idem$} (M);
	\end{tikzpicture}}
\]
\[
	\vc{\begin{tikzpicture}[x=180pt,y=40pt]
		\node (N) at (0,2) {$\trm{(N+aM)+b(N+aM)}$};
		\node (M) at (1,2) {$\trm{N+aM}$};
		\node (P) at (0,1) {$\trm{(N+b(N+aM))+a(M+b(N+aM))}$};
		\node (Q) at (0,0) {$\trm{((N+bN)+a(N+bM))+a((M+bN)+a(M+bM))}$};
		\node (R) at (1,0) {$\trm{(N+bN)+a(M+bM)}$};
		\draw[rw] (N) --node[above]{$\idem$}  (M);
		\draw[rw] (N) --node[left] {$\plusL$} (P);
		\draw[rws,implied] (P) --node[left] {$\plusR$}   (Q);
		\draw[rws,implied] (R) --node[right]{$\idem$}    (M);
		\draw[rws,implied] (Q) --node[below]{$\cancelL,\cancelR$} (R);
	\end{tikzpicture}}
\]

%=====
\itm\cancelL{\trm{(N +a M) +a P}\rw\trm{N +a P}}
\[
	\vc{\begin{tikzpicture}[x=100pt,y=40pt]
		\node (N) at (0,1) {$\trm{(N+aM)+a(P+aQ)}$};
		\node (M) at (1,1) {$\trm{N+a(P+aQ)}$};
		\node (P) at (0,0) {$\trm{(N+aM)+a Q}$};
		\node (Q) at (1,0) {$\trm{N+aQ}$};
		\draw[rw] (N) --node[above]{$\cancelL$} (M);
		\draw[rw] (N) --node[left] {$\cancelR$} (P);
		\draw[rw,implied] (M) --node[right]{$\cancelR$} (Q);
		\draw[rw,implied] (P) --node[below]{$\cancelL$} (Q);
	\end{tikzpicture}}
	\vcenter{\hbox{\begin{tikzpicture}[x=100pt,y=40pt]
		\node (N) at (0,2) {$\trm{C[(N+aM)+aP]}$};
		\node (M) at (1,2) {$\trm{C[N+aM]}$};
		\node (P) at (0,1) {$\trm{C[N+aM]+aC[P]}$};
		\node (Q) at (0,0) {$\trm{(C[N]+aC[M])+aC[P]}$};
		\node (R) at (1,0) {$\trm{C[N]+aC[M]}$};
		\draw[rw] (N) --node[above]{$\cancelL$} (M);
		\draw[rw] (N) --node[left] {$\plusX$}   (P);
		\draw[rw,implied] (P) --node[left] {$\plusX$}   (Q);
		\draw[rw,implied] (M) --node[right]{$\plusX$}   (R);
		\draw[rw,implied] (Q) --node[below]{$\cancelL$} (R);
	\end{tikzpicture}}}
\]
\[
	\vcenter{\hbox{\begin{tikzpicture}[x=140pt,y=40pt]
		\node (N) at (0,1) {$\trm{(N+bM)+b(P+aQ)}$};
		\node (M) at (1,1) {$\trm{N+b(P+aQ)}$};
		\node (P) at (0,0) {$\trm{((N+bM)+bP)+a((N+bM)+bQ)}$};
		\node (Q) at (1,0) {$\trm{(N+bP)+a(N+bQ)}$};
		\draw[rw] (N) --node[above]{$\cancelL$} (M);
		\draw[rw] (N) --node[left] {$\plusR$}   (P);
		\draw[rw, implied] (M) --node[right]{$\plusR$} (Q);
		\draw[rws,implied] (P) --node[below]{$\cancelL$} (Q);
	\end{tikzpicture}}}
\]

%=====
\itm\plusX{\trm{C[N+aM]}\rw\trm{C[N]+a C[M]}}
\[
	\vc{\begin{tikzpicture}[x=140pt,y=40pt]
		\node (N) at (0,2) {$\trm{C[(N+aM)+bP]} $};
		\node (M) at (1,2) {$\trm{C[N+aM]+bC[P]}$};
		\node (P) at (0,1) {$\trm{C[(N+bP)+a(M+bP)]}$};
		\node (Q) at (1,1) {$\trm{(C[N]+aC[M])+bC[P]}$};
		\node (R) at (0,0) {$\trm{C[N+bP]+aC[M+bP]}$};
		\node (S) at (1,0) {$\trm{(C[N]+bC[P])+a(C[M]+bC[P])}$};
		\draw[rw] (N) --node[above]{$\plusX$} (M);
		\draw[rw] (N) --node[left] {$\plusL$} (P);
		\draw[rw, implied] (M) --node[right]{$\plusX$} (Q);
		\draw[rw, implied] (P) --node[left] {$\plusX$} (R);
		\draw[rw, implied] (Q) --node[right]{$\plusL$} (S);
		\draw[rws,implied] (R) --node[below]{$\plusX$} (S);
	\end{tikzpicture}}
\]
		
%=====
\itm\plusL{\trm{(N+aM)+bP}\rw\trm{(N+bP)+a(M+bP)}}
\[
	\vc{\begin{tikzpicture}[x=340pt,y=40pt]
		\node[anchor=west] (a) at (0,2) {$\trm{(N+aM)+b(P+aQ)}$};
		\node[anchor=west] (b) at (0,1) {$\trm{((N+aM)+bP)+a((N+aM)+bQ)}$};
		\node[anchor=west] (c) at (0,0) {$\trm{((N+bP)+a(M+bP))+a((N+bQ)+a(M+bQ))}$};
		%
		\node[anchor=east] (d) at (1,2) {$\trm{(N+b(P+aQ))+a(M+b(P+aQ))}$};
		\node[anchor=east] (e) at (1,1) {$\trm{((N+bP)+a(N+bQ))+a((M+bP)+a(M+bQ))}$};
		\node[anchor=east] (f) at (1,0) {$\trm{(N+bP)+a(M+bQ)}$};
		%
		\draw[rw] (a) --node[above]{$\plusL$} (d);
		\draw[rw] 			($(a.south west)+( 43.5pt,0pt)$) --node[left] {$\plusR$} ($(b.north west)+( 43.5pt,0pt)$);
		\draw[rws,implied]	($(d.south east)+(-43.5pt,0pt)$) --node[right]{$\plusR$} ($(e.north east)+(-43.5pt,0pt)$);
		\draw[rws,implied]	($(b.south west)+( 43.5pt,0pt)$) --node[left] {$\plusL$} ($(c.north west)+( 43.5pt,0pt)$);
		\draw[rws,implied]	($(e.south east)+(-43.5pt,0pt)$) --node[right]{$\cancelL,\cancelR$} ($(f.north east)+(-43.5pt,0pt)$);
		\draw[rws,implied] (c) --node[below]{$\cancelL,\cancelR$} (f);
	\end{tikzpicture}}
\]
\[
	\vc{\begin{tikzpicture}[x=180pt,y=40pt]
		\node (N) at (0,2) {$\trm{(N+bM)+c(P+aQ)}$};
		\node (M) at (1,2) {$\trm{(N+c(P+aQ))+b(M+c(P+aQ))}$};
		\node (P) at (1,1) {$\trm{((N+cP)+a(N+cQ))+b((M+cP)+a(M+cQ))}$};
		\node (Q) at (0,0) {$\trm{((N+bM)+cP)+a((N+bM)+cQ)}$};
		\node (R) at (1,0) {$\trm{((N+cP)+b(M+cP))+a((N+cQ)+b(M+cQ))}$};
		\draw[rw] (N) --node[above]{$\plusL$} (M);
		\draw[rw] (N) --node[left] {$\plusR$} (Q);
		\draw[rws,implied] (M) --node[right]{$\plusR$} (P);
		\draw[rws,implied] (P) --node[right]{$\plusL,\plusR,\cancelL,\cancelR$} (R);
		\draw[rws,implied] (Q) --node[below]{$\plusL$} (R);
	\end{tikzpicture}}
\]

%=====
\itm\plusFun{\trm{(N+aM)P}\rw\trm{(NP)+a(MP)}}
\[
	\vc{\begin{tikzpicture}[x=140pt,y=40pt]
		\node (N) at (0,2) {$\trm{(N+aM)(P+aQ)}$};
		\node (M) at (1,2) {$\trm{(N(P+aQ))+a(M(P+aQ))}$};
		\node (P) at (0,1) {$\trm{((N+aM)P)+a((N+aM)Q)}$};
		\node (Q) at (1,1) {$\trm{((NP)+a(NQ))+a((MP)+a(MQ))}$};
		\node (R) at (0,0) {$\trm{((NP)+a(MP))+a((NQ)+a(MQ))}$};
		\node (S) at (1,0) {$\trm{(NP)+a(MQ)}$};
    	\draw[rw] (N) --node[above]{$\plusFun$} (M);
    	\draw[rw] (N) --node[left] {$\plusArg$} (P);
    	\draw[rws,implied] (M) --node[right]{$\plusArg$} (Q);
    	\draw[rws,implied] (P) --node[left] {$\plusFun$} (R);
    	\draw[rws,implied] (Q) --node[right]{$\cancelL,\cancelR$} (S);
    	\draw[rws,implied] (R) --node[below]{$\cancelL,\cancelR$} (S);
    \end{tikzpicture}}
\]
\[
	\vc{\begin{tikzpicture}[x=180pt,y=40pt]
		\node (N) at (0,2) {$\trm{(N+bM)(P+aQ)}$};
		\node (M) at (1,2) {$\trm{(N(P+aQ))+b(M(P+aQ))}$};
		\node (P) at (1,1) {$\trm{((NP)+a(NQ))+b((MP)+a(MQ))}$};
		\node (Q) at (0,0) {$\trm{((N+bM)P)+a((N+bM)Q)}$};
		\node (R) at (1,0) {$\trm{((NP)+b(MP))+a((NQ)+b(MQ))}$};
		\draw[rw] (N) --node[above]{$\plusFun$} (M);
		\draw[rw] (N) --node[left] {$\plusArg$} (Q);
		\draw[rws,implied] (M) --node[right]{$\plusArg$} (P);
		\draw[rws,implied] (P) --node[right]{$\plusL,\plusR,\cancelL,\cancelR$} (R);
		\draw[rws,implied] (Q) --node[below]{$\plusFun$} (R);
	\end{tikzpicture}}
\]

%=====
\itm\plusBox{\trm{!b.(N +a M)} \rw \trm{(!b.N) +a (!b.M)}}
\[
	\vc{\begin{tikzpicture}[x=80pt,y=40pt]
		\node (N) at (0,1) {$\trm{!b.(N+aM)}$};
		\node (M) at (1,1) {$\trm{(!b.N)+a(!b.M)}$};
		\node (P) at (0,0) {$\trm{N+aM}$};
		\draw[rw] (N) --node[above]{$\plusBox$}    (M);
		\draw[rw] (N) --node[left] {$\boxVoid$} (P);
		\draw[rw,implied] (P) --node[below right=-2pt] {$\boxVoid$} (M);
	\end{tikzpicture}}
\quad (a \neq b, \ b \notin\trm{N+a M})
\]
\end{proof}


\begin{defn}
We denote the unique $\perm$-normal form of a term $N$ by $N_\perm$.
\end{defn}

%============================================================ CONFLUENCE
%
%\section{Confluence}
%\label{sec:confluence}
%
%We aim to prove that $\rw \,=\, \rw_\beta \cup \rw_\perm$ is confluent. We will use the standard technique of \emph{parallel} $\beta$-reduction~\cite{Takahashi95}, a simultaneous reduction step on an arbitrary number of $\beta$-redexes in the source term, which we define via a labeling of the redexes to be reduced. The central point is to find a notion of reduction that is \emph{diamond}, \ie\ every critical pair can be closed in one (or zero) steps. This will be our \emph{complete} reduction, which consists of parallel $\beta$-reduction followed by $\perm$-reduction to normal form.
%%
%%\begin{lem}[Substitution for $\rw_\perm$]
%%	\label{lemma:substitution}
%%	\hfill
%%	\begin{enumerate}
%%		\item If $\trm{N \rw_\perm N'}$ then $\trm{M[N/x] \rw_\perm^* M[N'/x]}$.
%%		\item If $\trm{M \rw_\perm M'}$ then $\trm{M[N/x] \rw_\perm M'[N/x]}$.
%%		%\item If $\trm{x \in {\fv{M}}}$ and $a <_M b$ for any $\trm{b \in {\fl{M}}}$ then $\trm{M[N +a P/x]} \rw_\perm^* \trm{M[N/x] +a M[P/x]}$.
%%	\end{enumerate}
%%\end{lem}
%
%%\begin{proof}\hfill
%%	\begin{enumerate}
%%		\item By induction on $\trm{M}$.
%%		\item By induction on the definition of $\trm{M \rw_\perm M'}$. %\qedhere
%%	\end{enumerate}
%%\end{proof}
%
%
%
%
%%		\item By induction on $\trm{M}$.
%%		Cases:
%%		\begin{itemize}
%%			\item \emph{Variable}, \ie\ $\trm{M = x}$ (as $\trm{x} \in \fv{M}$), and then $\trm{M[N +a P/x]} = \trm{N +a P} = \trm{M[N/x] +a M[P/x]}$.
%%
%%			\item \emph{Application}, \ie\ $\trm{M = M_1M_2}$.
%%			Since $\trm{x \in {\fv{M}}}$ there are three cases:
%%			\begin{itemize}
%%				\item $\trm{x \in {\fv{M_1}} \cup \fv{M_2}}$ and then, by \ih, $\trm{M_i[N +a P/x]} \rw_\perm^* \trm{M_i[N/x] +a M_i[P/x]}$ for all $i \in \{1,2\}$.
%%				So,
%%				$\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] M_2[N +a P/x]} \rw_\perm^* \trm{(M_1[N/x] +a M_1[P/x])(M_2[N/x] +a M_2[P/x])} \allowbreak\rw_\perm^* \trm{M_1[N/x]M_2[N/x] +a M_1[P/x]M_2[P/x]} = \trm{M[N/x] +a M[P/x]}$.
%%
%%				\item $\trm{x \in {\fv{M_{1}}}}$ and $\trm{x \notin {\fv{M_2}}}$ and then, by \ih, $\trm{M_1[N +a P/x]} \rw_\perm^* \trm{M_1[N/x] +a M_1[P/x]}$.
%%				So,
%%				$\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] M_2} \rw_\perm^* \trm{(M_1[N/x] +a M_1[P/x])M_2} \allowbreak\rw_\perm^* \trm{M_1[N/x]M_2 +a M_1[P/x]M_2} = \trm{M[N/x] +a M[P/x]}$.
%%
%%				\item $\trm{x \notin {\fv{M_{1}}}}$ and $\trm{x \in {\fv{M_2}}}$: analogous to the previous case.
%%			\end{itemize}
%%
%%			\item \emph{Abstraction}, \ie\ $\trm{M = \y.M'}$.
%%			By \ih, as $\trm{x \in {\fv{M}} \subseteq \fv{M'}}$ $\trm{M'[N +a P/x]} \rw_\perm^* \trm{M'[N/x] +a M'[P/x]}$
%%			So, $\trm{M [N +a P/x] = \y.(M'[N +a P/x]) \rw_\perm^* \y.(M'[N/x] +a M'[P/x]) \rw_\perm \y.(M'[N/x]) +a \y.(M'[P/x])}$ $= \trm{M[N/x] +a M[P/x]}$.
%%
%%			\item \emph{Superposition}, \ie\ $\trm{M = M_1 +b M_2}$.
%%			By \ih, $\trm{M_i[N +a P/x]} \rw_\perm^* \trm{M_i[N/x] +a M_i[P/x]}$ for all $i \in \{1,2\}$.
%%			Since $a <_M b$ by hypothesis, $\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] +b M_2[N +a P/x]} \rw_\perm^* \trm{(M_1[N/x] +a M_1[P/x])
%%				\allowbreak+b (M_2[N/x] +a M_2[P/x])} \rw_\perm
%%			\trm{((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[N/x]) +a ((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[P/x])}
%%			\allowbreak\rw_\perm^*
%%			\trm{((M_1[N/x]\allowbreak+b M_2[N/x]) +a (M_1[P/x] \allowbreak+b M_2[N/x]))  +a ((M_1[N/x] \allowbreak+b M_2[P/x]) +a (M_1[P/x] \allowbreak+b M_2[P/x])) }
%%			\allowbreak\rw_\perm^*
%%			\trm{(M_1[N/x] +b M_2[N/x]) +a (M_1[P/x] +b M_2[P/x])} = \trm{M[N/x] +a M[P/x]}$.
%%
%%			\item \emph{Superposition}, \ie\ $\trm{M = M_1 +b M_2}$.
%%			Since $\trm{x \in {\fv{M}}}$ there are three cases:
%%			\begin{itemize}
%%				\item $\trm{x \in {\fv{M_1}} \cup \fv{M_2}}$ and then, by \ih, $\trm{M_i[N +a P/x]} \rw_\perm^* \trm{M_i[N/x] +a M_i[P/x]}$ for all $i \in \{1,2\}$.
%%				Since $a <_M b$ by hypothesis, $\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] +b M_2[N +a P/x]} \rw_\perm^* \trm{(M_1[N/x] +a M_1[P/x])
%%					\allowbreak+b (M_2[N/x] +a M_2[P/x])} \rw_\perm
%%				\trm{((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[N/x]) +a ((M_1[N/x] +a M_1[P/x]) \allowbreak+b M_2[P/x])}
%%				\allowbreak\rw_\perm^*
%%				\trm{((M_1[N/x]\allowbreak+b M_2[N/x]) +a (M_1[P/x] \allowbreak+b M_2[N/x]))  +a ((M_1[N/x] \allowbreak+b M_2[P/x]) +a (M_1[P/x] \allowbreak+b M_2[P/x])) }
%%				\allowbreak\rw_\perm^*
%%				\trm{(M_1[N/x] +b M_2[N/x]) +a (M_1[P/x] +b M_2[P/x])} = \trm{M[N/x] +a M[P/x]}$.
%%
%%				\item $\trm{x \in {\fv{M_{1}}}}$ and $\trm{x \notin {\fv{M_2}}}$ and then, by \ih, $\trm{M_1[N +a P/x]} \rw_\perm^* \trm{M_1[N/x] +a M_1[P/x]}$.
%%
%%				Since $a <_M b$ by hypothesis, $\trm{M[N +a P/x]} = \trm{M_1[N +a P/x] +b M_2} \rw_\perm^* \trm{(M_1[N/x] +a M_1[P/x])
%%					\allowbreak+b M_2} \rw_\perm
%%				\trm{((M_1[N/x]\allowbreak+b M_2) +a (M_1[P/x] \allowbreak+b M_2) }
%%				= \trm{M[N/x] +a M[P/x]}$.
%%
%%				\item $\trm{x \notin {\fv{M_{1}}}}$ and $\trm{x \in {\fv{M_2}}}$: analogous to the previous case.
%%			\end{itemize}
%%
%%			\item \emph{Box}, \ie\ $\trm{M} = \trm{!b.M'}$.
%%			We can suppose without loss of generality that $b \neq a$.
%%			By \ih, as $\trm{x \in {\fv{M}} = \fv{M'}}$ $\trm{M'[N +a P/x]} \rw_\perm^* \trm{M'[N/x] +a M'[P/x]}$
%%			So, $\trm{M [N +a P/x] = !b.(M'[N +a P/x]) \rw_\perm^* !b.(M'[N/x] +a M'[P/x]) \rw_\perm !b.(M'[N/x]) +a !b.(M'[P/x])}$ $= \trm{M[N/x] +a M[P/x]}$.
%%			%\qedhere
%%		\end{itemize}
%%
%%\begin{remark}
%%	If $\trm{x \notin {\fv{M}}}$ then $\trm{M[N +a P/x] \not\rw_\perm^* M[N/x] +a M[P/x]}$.
%%	For instance, take $\trm{M} = \trm{y} \neq \trm{x}$: then, $\trm{M[N +a P/x]} \allowbreak= y \neq \trm{y +a y} = \trm{M[N/x] +a M[P/x]}$ where $\trm{y}$ is $\perm$-normal.
%%	In fact, if $\trm{x \notin {\fv{M}}}$ then $\trm{M[N/x] +a M[P/x] \allowbreak= M +a M \rw_\perm M = M[N +a P/x]}$.
%%\end{remark}
%%
%%Two problematic cases to join critical pairs: the first two ones mean that we cannot use commutation and Hindley--Rosen lemma to prove that $\rw$ is confluent;
%%the second two ones suggest that the proof of confluence of $\rw$ is delicate (see the remark above).
%%
%%$
%%\begin{array}{c@{~}c@{~}c}
%%\trm{(\x.!a.M)P} &\rw_\perm & \trm{(!a.(\x. M))P}
%%\\	\dw_\beta && \dw_\perm
%%\\ \trm{(!a.M)[P/x]} & & \trm{!a.(\x. M)P}
%%\\	= & \rotatebox[origin=c]{210}{$\rw_\beta$}
%%\\	\trm{!a.M[P/x]} &&
%%\end{array}
%%$
%%\qquad
%%$
%%\begin{array}{c@{~}c@{~}c}
%%\trm{(\x.(N +a M))P} &\rw_\perm & \trm{((\x.N) +a (\x. M))P}
%%\\	\dw_\beta && \dw_\perm
%%\\ \trm{(N +a M)[P/x]} & & \trm{(\x.N)P +a (\x. M)P}
%%\\	= & \rotatebox[origin=c]{210}{$\rw_\beta^+$}
%%\\	\trm{N[P/x] +a M[P/x]} &&
%%\end{array}
%%$
%
%%Two problematic cases to join critical pairs: the first two ones mean that we cannot use commutation and Hindley--Rosen lemma to prove that $\rw$ is confluent;
%%the second two ones suggest that the proof of confluence of $\rw$ is delicate (see the remark above);
%%
%%$
%%\begin{array}{c@{~}c@{~}c}
%%\trm{(\x.!a.M)P} &\rw_\perm & \trm{(!a.(\x. M))P}
%%\\	\dw_\beta && \dw_\perm
%%\\ \trm{(!a.M)[P/x]} & & \trm{!a.(\x. M)P}
%%\\	= & \rotatebox[origin=c]{210}{$\rw_\beta$}
%%\\	\trm{!a.M[P/x]} &&
%%\end{array}
%%$
%%\qquad
%%$
%%\begin{array}{c@{~}c@{~}c}
%%\trm{(\x.(N +a M))P} &\rw_\perm & \trm{((\x.N) +a (\x. M))P}
%%\\	\dw_\beta && \dw_\perm
%%\\ \trm{(N +a M)[P/x]} & & \trm{(\x.N)P +a (\x. M)P}
%%\\	= & \rotatebox[origin=c]{210}{$\rw_\beta^+$}
%%\\	\trm{N[P/x] +a M[P/x]} &&
%%\end{array}
%%$
%%
%%\begin{align*}
%%\trm{x \in {\fv{M}}} \qquad & & & \qquad \trm{x \notin {\fv{M}}} \\
%%\begin{array}{c@{~}c@{~}c}
%%\trm{(\x.M)(N +a P)} &\rw_\perm & \trm{((\x.M)N) +a ((\x. M)P)}
%%\\	\dw_\beta && \dw_{\beta^+}
%%\\ \trm{M[(N +a P)/x]} & \rw_\perm^* & \trm{M[N/x] +a M[P/x]}
%%\end{array}
%%&&&
%%\begin{array}{c@{~}c@{~}c}
%%\trm{(\x.M)(N +a P)} &\rw_\perm & \trm{((\x.M)N) +a ((\x. M)P)}
%%\\	\dw_\beta && \dw_{\beta^+}
%%\\ \trm{M} & {}_\perm \lw & \trm{M +a M}
%%\end{array}
%%\end{align*}
%
%%\hrule
%
%\begin{defn}
%A \emph{labeled} term $\trm{N*}$ is a term $N$ with chosen $\beta$-redexes annotated as $\trm{(\x.M)*P}$. The \emph{labeled reduct} $\trm{No}$ of a labeled term is defined by induction on $N$ as follows:
%\begin{align*}
%	\trm{<(\x.N*)*M*>} &= \trm{No[Mo/x]}	&	\trm{<N*M*>} 	&= \trm{NoMo}
%\\	\trm{<x>}		&= x						&	\trm{<N*+aM*>}	&= \trm{No+aMo}
%\\	\trm{<\x.N*>}	&= \trm{\x.No}			&	\trm{<\,!a.N*>}	&= \trm{!a.No}
%\end{align*}
%A \emph{parallel $\beta$-step} is a reduction $N\rwp_\beta\trm{No}$ for some labeling $\trm{N*}$ of $N$. The \emph{full} labeling $N^\full$ of $N$ labels every redex and induces the \emph{full} parallel $\beta$-step $N\rwp_\beta\trm{<N^\full>}$.
%\end{defn}
%
%\noindent
%We write $\trm{N*}\rwp_\beta\trm{No}$ for the specific parallel step indicated by the labeling $\trm{N*}$. Observe that $\trm{No}$ is a regular unlabeled term, since all labels are removed in the reduction. For the empty labeling, $\trm{N} = \trm{No}$, so that parallel reduction is reflexive: $\trm{N} \rwp_\beta \trm{N}$.
%
%\begin{lem}
%A parallel $\beta$-step $N\rwp_\beta M$ is a $\beta$-reduction $N\rws_\beta M$.
%\end{lem}
%
%\begin{proof}
%By induction on the labeled term $\trm{N*}$ generating $N\rwp_\beta\trm{No}=M$.
%\end{proof}
%
%The crucial property of parallel reduction is that any parallel step can be extended to the full one by another parallel step, as illustrated below.
%\[
%	N\rwp_\beta\trm{No}\rwp_\beta\trm{<N^\full>}
%\]
%We prove this in \Cref{lemma:full-development}. As a direct corollary, parallel reduction is diamond. We need some simple technical results first.
%
%\begin{lem}
%\label{lem:parallel-properties}
%If $M\rwp_\beta M'$ and $N\rwp_\beta N'$ then:\\
%\begin{tabular}{@{\quad}l@{\quad}r@{~}c@{~}l}
%		1. & $MN$		& $\rwp_\beta$ & $M'N'$
%\\		2. & $(\x.M)N$	& $\rwp_\beta$ & $M'[N'/x]$
%\\		3. & $M[N/x]$	& $\rwp_\beta$ & $M'[N'/x]$
%\end{tabular}
%\end{lem}
%
%%
%%\newcounter{lemma:application-parallel-beta}
%%\addtocounter{lemma:application-parallel-beta}{\value{defn}}
%%\begin{lem}
%%\label{lemma:application-parallel-beta}
%%	If $\trm{M} \rwp_\beta \trm{M'}$ and $\trm{N} \rwp_\beta \trm{N'}$,
%%\marginpar{\footnotesize Proof in the Appendix}
%%	then $\trm{MN} \rwp_\beta \trm{M'N'}$.
%%	If moreover $M = \lambda x.R$ and $M'^ = \lambda x R'$ with $R \rwp_\beta R'$, then  $\trm{MN} \rwp_\beta \trm{R'[N'/x]}$.
%%\end{lem}
%
%%\begin{proof}
%%	Since $\trm{M} \rwp_\beta \trm{Mo} = M'$ and $\trm{N} \rwp_\beta \trm{No} = N'$ for some labelings $\trm{M*}$ and $\trm{N*}$ of $M$ and $N$ respectively, let $\trm{(MN)*}$ be the labeling of $\trm{MN}$ obtained by putting together the labelings $\trm{M*}$ and $\trm{N*}$.
%%	Clearly, $\trm{MN} \rwp_\beta \trm{<(MN)*>} = \trm{MoNo} = M'N'$.
%%
%%	Concerning the part of the statement after ``moreover'', since $\trm{R} \rwp_\beta \trm{<R*>} = R'$ and $\trm{N} \rwp_\beta \trm{No} = N'$ for some labelings $\trm{R*}$ and $\trm{N*}$ of $R$ and $N$ respectively, let $\trm{(MN)*}$ be the labeling of $\trm{MN}$ obtained by putting together the labelings $\trm{R*}$ and $\trm{N*}$ plus the labeled $\beta$-redex $\trm{(\x.R)*N}$.
%%	Clearly, $\trm{MN} \rwp_\beta \trm{<(MN)*>} = \trm{<R*>[No/x]} = \trm{R'[N'/x]}$.
%%\end{proof}
%
%%\begin{lem}[Substitution]
%%\label{lemma:substitution}
%%	If $\trm{M} \rwp_\beta \trm{M'}$ and $\trm{N} \rwp_\beta \trm{N'}$, then $\trm{M<N/x>} \rwp_\beta \trm{M'<N'/x>}$.
%%\end{lem}
%%
%%\begin{proof}
%%	By straightforward induction on $M$.
%%\end{proof}
%
%
%\begin{lem}[Full reduction]
%\label{lemma:full-development}
%Any parallel step $P\rwp_\beta\trm{Po}$ can be extended by $\trm{Po}\rwp_\beta\trm{<P^\full>}$ to a full step.
%\end{lem}
%
%\begin{proof}
%By induction on $\trm{P*}$. We treat the two main cases below, where the inductive hypothesis gives $\trm{Mo}\rwp_\beta\trm{<M^\full>}$ and $\trm{No}\rwp_\beta\trm{<N^\full>}$. The remaining cases are immediate from the inductive hypothesis and \Cref{lem:parallel-properties}.1. Observe that the full step on $P$ reduces every redex as follows.
%\[
%	\trm{(\x.M^\full)^\full N^\full} \rwp_\beta \trm{<M^\full>[<N^\full>/x]}
%\]
%
%\begin{itemize}
%	\item
%\emph{Labelled redex}: $\trm{(\x.M*)*N*}\rwp_\beta \trm{Mo[No/x]}$. By the inductive hypothesis and \Cref{lem:parallel-properties}.3 $\trm{Mo[No/x]}\rwp_\beta\trm{<M^\full>[<N^\full>/x]}$, as required.
%
%	\medskip
%	\item
%\emph{Unlabelled redex}: $\trm{(\x.M*)N*}\rwp_\beta\trm{(\x.Mo)No}$. By the inductive hypothesis and \Cref{lem:parallel-properties}.2 $\trm{(\x.Mo)No}\rwp_\beta\trm{<M^\full>[<N^\full>/x]}$, as required.%\qedhere
%\end{itemize}
%\end{proof}
%
%\hrule
%
%\bigskip
%{\color{red} Alternatively:}
%
%\addtocounter{section}{-1}

\section{Confluence}
\label{sec:confluence}

We aim to prove that $\rw \,=\, \rw_\beta \cup \rw_\perm$ is confluent. We will use the standard technique of \emph{parallel} $\beta$-reduction~\cite{Takahashi95}, a simultaneous reduction step on a number of $\beta$-redexes, which we define via a labeling of the redexes to be reduced. The central point is to find a notion of reduction that is \emph{diamond}, \ie\ every critical pair can be closed in one (or zero) steps. This will be our \emph{complete} reduction, which consists of parallel $\beta$-reduction followed by $\perm$-reduction to normal form.

\begin{defn}
A \emph{labeled} term $P^\1$ is a term $P$ with chosen $\beta$-redexes annotated as $\trm{(\x.N)*M}$. The unique \emph{labeled $\beta$-step} $P^\1\rwp_\beta P_\1$ from $P^\1$ to the \emph{labeled reduct} $P_\1$ reduces every labeled redex, and is defined inductively as follows.
\begin{align*}
	\trm{(\x.N*)*M*} &\rwp_\beta \trm{No[Mo/x]}	&	\trm{N*M*} 	 &\rwp_\beta \trm{No Mo}
\\	\trm{x}		 	 &\rwp_\beta x				&	\trm{N*+aM*} &\rwp_\beta \trm{No +a Mo}
\\	\trm{\x.N*}		 &\rwp_\beta \trm{\x.No}	&	\trm{!a.N*}	 &\rwp_\beta \trm{!a.No}
\end{align*}
A \emph{parallel $\beta$-step} $P\rwp_\beta P_\1$ is a labeled step $P^\1\rwp_\beta P_\1$ for some labeling $P^\1$.
\end{defn}

\noindent
Note that $P_\1$ is an unlabeled term, since all labels are removed in the reduction. For the empty labeling, $P^\1 = P_\1 = P$, so parallel reduction is reflexive: $P \rwp_\beta P$.

\begin{lem}
A parallel $\beta$-step $P\rwp_\beta P_\1$ is a $\beta$-reduction $P\rws_\beta P_\1$.
\end{lem}

\begin{proof}
By induction on the labeled term $P^\1$ generating $P\rwp_\beta P_\1$.
\end{proof}

\begin{lem}
\label{lem:parallel diamond}
Parallel $\beta$-reduction is diamond.
\[
\begin{tikzpicture}[x=40pt, y=40pt]
	\node (N) at (0,1) {$N$};
	\node (M) at (1,1) {$M$};
	\node (P) at (0,0) {$P$};
	\node (Q) at (1,0) {$Q$};
	\draw[rwp] (N) --node[above]{$\scriptstyle\beta$} (M);
	\draw[rwp] (N) --node[left] {$\scriptstyle\beta$} (P);
	\draw[rwp,implied] (M) --node[right]{$\scriptstyle\beta$} (Q);
	\draw[rwp,implied] (P) --node[below]{$\scriptstyle\beta$} (Q);
\end{tikzpicture}
\]
\end{lem}

\begin{proof}
Let $P^\1\rwp_\beta P_\1$ and $P^\0\rwp_\beta P_\0$ be two labeled reduction steps on a term $P$. We annotate each step with the  label of the other, preserved by reduction, to give the span from the doubly labeled term $P^{\1\0}=P^{\0\1}$ below left. Reducing the remaining labels will close the diagram, as below right.
\[
	P_\1^\0
		~\mathrel{{}_\beta{\rwpleft}}~
	P^{\1\0}
		=
	P^{\0\1}
		~\rwp_\beta~
	P_\0^\1
\qquad\qquad
	P_\1^\0
		~\rwp_\beta~
	P_{\1\0}
		=
	P_{\0\1}
		~\mathrel{{}_\beta{\rwpleft}}~
	P_\0^\1
\]
This is proved by induction on $P^{\1\0}$, where only two cases are not immediate: those where a redex carries one but not the other label. One case follows by the below diagram; the other case is symmetric. Below, for the step top right, induction on $N^\1$ shows that $N^\1[M^\1/x]\rwp_\beta N_\1[M_\1/x]$.
\[
\begin{array}[b]{ccccc}
    				\trm{(\x.N^{\0\1})^\0 M^{\0\1}}
    &~\rwp_\beta~&	\trm{N_\0^\1[M_\0^\1/x]}
    &~\rwp_\beta~&	\trm{N_{\0\1}[M_{\0\1}/x]}
    \\ = &&&& = \\
    				\trm{(\x.N^{\1\0})^\0 M^{\1\0}}
    &~\rwp_\beta~&	\trm{(\x.N_\1^\0)^\0 M_\1^\0}
    &~\rwp_\beta~&	\trm{N_{\1\0}[M_{\1\0}/x]}
\end{array}
\]
\end{proof}

\subsection{Parallel Reduction and Permutative Reduction}

For the commutation of (parallel) $\beta$-reduction with $\perm$-reduction, we run into the minor issue that a permuting generator or choice operator may block a redex: in both cases below, before $\rw_\perm$ the term has a redex, but after $\rw_\perm$ it is blocked.
%
\begin{align*}
	\trm{(\x.N+aM)\,P} & \rw_\perm  \trm{((\x.N)+a(\x.M))\,P}
&&& \trm{(\x.!a.N)\,M} & \rw_\perm  \trm{(!a.\x.N)\,M}
\end{align*}
%
We address this by an adaptation $\rwb_\perm$ of $\perm$-reduction on labeled terms, which is a strategy in $\rws_\perm$ that permutes past a labeled redex in one step.

\begin{defn}
A \emph{labeled} $\perm$-reduction $\trm{N*}\rwb_\perm\trm{M*}$ on labeled terms is a $\perm$-reduction of one of the forms
\[
\begin{array}{rcl}
	\trm{(\x.N*+aM*)*P*} &~\rws_\perm~& \trm{(\x.N*)*P*+a(\x.M*)*P*}
\\[8pt]
	\trm{(\x.!a.N*)*M*} &~\rws_\perm~& \trm{!a.(\x.N*)*M*}
\end{array}
\]
or a single $\perm$-step $\rw_\perm$ on unlabeled constructors in $\trm{N*}$.
\end{defn}

\begin{lem}
\label{lem:parallel p-reduction}
Reduction to normal form in $\rwb_\perm$ is equal to $\rwn_\perm$ (on labeled terms).
\end{lem}

\begin{proof}
Observe that $\rw_\perm$ and $\rwb_\perm$ have the same normal forms. Then in one direction, since $\rwb_\perm\,\subseteq\,\rws_\perm$ we have $\rwbn_\perm\,\subseteq\,\rwn_\perm$. Conversely, let $N\rwn_\perm M$. On this reduction, let $P\rw_\perm Q$ be the first step such that $P\not\rwb_\perm Q$. Then there is an $R$ such that $P\rwb_\perm R$ and $Q\rw_\perm R$. Note that we have $N\rwbs_\perm R$. By confluence, $R\rwn_\perm M$, and by induction on the sum length of paths in $\rw_\perm$ from $R$ (smaller than from $N$) we have $R\rwbn_\perm M$, and hence $N\rwbn_\perm M$.
\end{proof}

The following lemmata then give the required commutation properties of the relations $\rwb_\perm$, $\rwn_\perm$, and $\rwp_\beta$. Figure~\ref{fig:confluence diagrams} illustrates these by commuting diagrams.

\begin{lem}
\label{lem:parallel p - parallel beta}
If $\trm{N*}\rwb_\perm\trm{M*}$ then $\trm{No}=_\perm\trm{Mo}$.
\end{lem}

\begin{proof}
By induction on the rewrite step $\rwb_\perm$. The two interesting cases are:
\[
\begin{array}[b]{cl}
\vcenter{\hbox{\begin{tikzpicture}
	\matrix[matrix of math nodes] (m) {
	  		\trm{(\x.M*)*(N* +a P*)} &[20pt] \trm{((\x.M*)*N*) +a ((\x. M*)*P*)}
	\\[20pt]\trm{Mo[(No +a Po)/x]} & \trm{Mo[No/x] +a Mo[Po/x]}
	\\ };
	\draw[rwb] (m-1-1) --node[above]{$\perm$} (m-1-2);
	\draw[rwp] (m-1-1) --node[left] {$\beta$} (m-2-1);
	\draw[rwp,implied] (m-1-2) --node[right]{$\beta$} (m-2-2);
	\draw[rws,implied] (m-2-1) --node[below]{$\perm$} (m-2-2);
\end{tikzpicture}}}
&	(x\in\fv M)
\\ \\
\vcenter{\hbox{\begin{tikzpicture}
	\matrix[matrix of math nodes] (m) {
	  		\trm{(\x.M*)*(N* +a P*)} &[20pt] \trm{((\x.M*)*N*) +a ((\x. M*)*P*)}
	\\[20pt]\trm{Mo}\vphantom{\trm{+a}} & \trm{Mo +a Mo}
	\\ };
	\draw[rwb] (m-1-1) --node[above]{$\perm$} (m-1-2);
	\draw[rwp] (m-1-1) --node[left] {$\beta$} (m-2-1);
	\draw[rwp,implied] (m-1-2) --node[right]{$\beta$} (m-2-2);
	\draw[rw, implied] (m-2-2) --node[below]{$\perm$} (m-2-1);
\end{tikzpicture}}}
&	(x\notin\fv M)
\end{array}
\]
\end{proof}

\noindent
Because of the way the critical pairs in the above diagrams are joined, we cannot use the Hindley-Rosen Lemma \cite[Prop. 3.3.5]{Barendregt84} to prove confluence of $\rw_\beta \cup \rw_\perm$.


\begin{lem}
\label{lem:exhaustive p - parallel beta}
$\trm{No}=_\perm N_{\perm\1}$.
\end{lem}

\begin{proof}
Using \Cref{lem:parallel p-reduction} we decompose $\trm{N*}\rwn_\perm\trm{N*p}$ as
\[
	\trm{N*}=\trm{N_1*}\rwb_\perm\trm{N_2*}\rwb_\perm \dots \rwb_\perm \trm{N_n*}=\trm{N*p}
\]
where $\trm{(N_i)o}=_\perm\trm{(N_{i+1})o}$ by \Cref{lem:parallel p - parallel beta}.
\end{proof}

\subsection{Complete Reduction}

To obtain a reduction strategy with the diamond property for $\rw$, we combine parallel reduction $\rwp_\beta$ with permutative reduction to normal form $\rwn_\perm$ into a notion of \emph{complete reduction} $\rwp$. We will show that it is diamond (\Cref{lem:complete diamond}), and that any step in $\rw$ maps onto a complete step of $\perm$-normal forms (\Cref{lem:p to complete reduction}). Confluence of $\rw$ (\Cref{thm:confluence}) then follows: any two paths $\rws$ map onto complete paths $\rwps$ on $\perm$-normal forms, which then converge by the diamond property.

\begin{defn}
A \emph{complete} reduction step $N\rwp\trm{Nq}$ is a parallel $\beta$-step followed by $\perm$-reduction to normal form:
\[
	N\rwp \trm{Nq} \quad\coloneq\quad N\rwp_\beta \trm{No} \rwn_\perm \trm{Nq}~.
\]
\end{defn}

\begin{lem}[Complete reduction is diamond]
\label{lem:complete diamond}
	If $P\rwpleft N\rwp M$ then for some $Q$, $P\rwp Q\rwpleft M$.
\end{lem}

\begin{proof}
By the following diagram, where $M=N_{\0\perm}$ and $P=N_{\1\perm}$, and $Q=N_{\0\1\perm}$. The square top left is by \Cref{lem:parallel diamond}, top right and bottom left are by \Cref{lem:exhaustive p - parallel beta}, and bottom right is by confluence and strong normalization of $\perm$-reduction.
\[
\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  \trm{N^{\0\1}} &[20pt] & \trm{N_\0^\1} &[20pt] & \trm{N_{\0\perm}^\1} \\[20pt]
	  \\
	  \trm{N_\1^\0}	&& \trm{N_{\0\1}} && \trm{N_{\0\perm\1}} \\[20pt]
		\\
	  \trm{N_{\1\perm}^\0} && \trm{N_{\1\perm\0}} && \trm{N_{\0\1\perm}} \\
	};
	\draw[rwp] (m-1-1) --node[above]{$\scriptstyle\beta$} (m-1-3);
	\draw[rwp] (m-1-1) --node[left] {$\scriptstyle\beta$} (m-3-1);
	\draw[rwp] (m-1-3) --node[left] {$\scriptstyle\beta$} (m-3-3);
	\draw[rwp] (m-3-1) --node[above]{$\scriptstyle\beta$} (m-3-3);
	%
	\draw[rwn] (m-1-3) --node[above]{$\scriptstyle\perm$} (m-1-5);
	\draw[rwn] (m-3-1) --node[left] {$\scriptstyle\perm$} (m-5-1);
	\draw[rwp] (m-5-1) --node[above]{$\scriptstyle\beta$} (m-5-3);
	\draw[rwp] (m-1-5) --node[left] {$\scriptstyle\beta$} (m-3-5);
	%
	\path (m-3-3) --node{$=_\perm$} (m-3-5);
	\path (m-3-3) --node{$=_\perm$} (m-5-3);
	\draw[rwn] (m-5-3) --node[above]{$\scriptstyle\perm$} (m-5-5);
	\draw[rwn] (m-3-5) --node[left] {$\scriptstyle\perm$} (m-5-5);
\end{tikzpicture}
\]
\end{proof}

\begin{lem}[$\perm$-Normalization maps reduction to complete reduction]
\label{lem:p to complete reduction}
If $N\rw M$ then $N_\perm\rwp M_\perm$.
\end{lem}

\begin{proof}
For a $\perm$-step $N\rw_\perm M$ we have $N_\perm=M_\perm$ while $\rwp_\beta$ is reflexive. For a $\beta$-step $N\rw_\beta M$ we label the reduced redex in $N$ to get $\trm{N*}\rwp_\beta\trm{No}=M$. Then \Cref{lem:exhaustive p - parallel beta} gives $N_{\perm\1}=_\perm M$, and hence $\trm{Np}\rwp_\beta N_{\perm\1}\rwn_\perm M_\perm$.
\end{proof}


\begin{figure}[!t]
\figframe{
    \[
\begin{array}{c@{\qquad}c@{\qquad}c@{\qquad}c}
  \vcenter{\hbox{\begin{tikzpicture}
	        \matrix (m) [matrix of math nodes,ampersand replacement=\&] {
	          \trm{N} \&\& \trm{M} \\[20pt] \\ \trm{P} \& =_\perm \& \trm{Q} \\
	        };
	        \draw[rwb] (m-1-1) --node[above]{$\scriptstyle\perm$} (m-1-3);
	        \draw[rwp] (m-1-1) --node[left] {$\scriptstyle\beta$} (m-3-1);
	        \draw[rwp] (m-1-3) --node[right]{$\scriptstyle\beta$} (m-3-3);
  \end{tikzpicture}}}
  &
  \vcenter{\hbox{\begin{tikzpicture}
	        \matrix (m) [matrix of math nodes,ampersand replacement=\&] {
	          \trm{N} \&\& \trm{M} \\[20pt] \\ \trm{P} \& =_\perm \& \trm{Q} \\
	        };
	        \draw[rwn] (m-1-1) --node[above]{$\scriptstyle\perm$} (m-1-3);
	        \draw[rwp] (m-1-1) --node[left] {$\scriptstyle\beta$} (m-3-1);
	        \draw[rwp] (m-1-3) --node[right]{$\scriptstyle\beta$} (m-3-3);
  \end{tikzpicture}}}
  &
  \vcenter{\hbox{\begin{tikzpicture}
	        \matrix (m) [matrix of math nodes,ampersand replacement=\&] {
	          \trm{N} \&[20pt] \& \trm{M} \\[20pt] \\ \trm{P} \&\& \trm{Q} \\
	        };
	        \draw[rwp] (m-1-1) -- (m-1-3);
	        \draw[rwp] (m-1-1) -- (m-3-1);
	        \draw[rwp] (m-1-3) -- (m-3-3);
	        \draw[rwp] (m-3-1) -- (m-3-3);
  \end{tikzpicture}}}
  &
  \vcenter{\hbox{\begin{tikzpicture}
	        \matrix (m) [matrix of math nodes,ampersand replacement=\&] {
	          \trm{N} \&[20pt] \& \trm{M} \\[20pt] \\ P \&\& Q \\
	        };
	        \draw[rw]  (m-1-1) -- (m-1-3);
	        \draw[rwn] (m-1-1) --node[left] {$\scriptstyle\perm$} (m-3-1);
	        \draw[rwn] (m-1-3) --node[right]{$\scriptstyle\perm$} (m-3-3);
	        \draw[rwp] (m-3-1) -- (m-3-3);
  \end{tikzpicture}}}
  \\ \\
  \text{\Cref{lem:parallel p - parallel beta}}
  & \text{\Cref{lem:exhaustive p - parallel beta}}
  & \text{\Cref{lem:complete diamond}}
  & \text{\Cref{lem:p to complete reduction}}
  \\[4pt]
\end{array}
\]
}
\caption{Diagrams for the lemmata leading up to confluence}
\label{fig:confluence diagrams}
\end{figure}

\begin{thm}
\label{thm:confluence}
Reduction $\rw$ is confluent.
\end{thm}

\begin{proof}
By the following diagram. For the top and left areas, by Lemma~\ref{lem:p to complete reduction} any reduction path $N\rws M$ maps onto one $N_\perm \rwx M_\perm$. The main square follows by the diamond property of complete reduction, \Cref{lem:complete diamond}.
\[
\begin{tikzpicture}
	\matrix (m) [matrix of math nodes] {
	  N &[10pt] &[10pt] M &[10pt] \\[10pt] & N_\perm && M_\perm \\[10pt] P \\[10pt] & P_\perm && Q \\
	};
	\draw[rws] (m-1-1) -- (m-1-3);
	\draw[rws] (m-1-1) -- (m-3-1);
	\draw[rwn] (m-1-1) --node[below left =-2pt] {$\scriptstyle\perm$} (m-2-2);
	\draw[rwn] (m-1-3) --node[above right=-2pt]{$\scriptstyle\perm$} (m-2-4);
	\draw[rwn] (m-3-1) --node[below left =-2pt] {$\scriptstyle\perm$} (m-4-2);
	\draw[rwx] (m-2-2) -- (m-2-4);
	\draw[rwx] (m-2-2) -- (m-4-2);
	\draw[rwx] (m-2-4) -- (m-4-4);
	\draw[rwx] (m-4-2) -- (m-4-4);
\end{tikzpicture}
\]
\end{proof}

%=====================================================================================

\section{Strong Normalization for Simply-Typed Terms}
\label{sec:SN}

In this section, we prove that the relation $\rw$ enjoys strong
normalization in \emph{simply typed} terms. Our proof of strong
normalization is based on the classic reducibility technique,
and inherently has to deal with label-open terms. It thus make great
sense to turn the order $<_{{\trm{M}}}$ from
Definition~\ref{def:orderlabels} into something more formal, at the same time
allowing terms to be label-\emph{open}. 
This is in Figure~\ref{fig:order}.
%
\begin{figure}[!t]
\figframe[4pt]{
\begin{tabular}{ll}
    \textsf{Label Sequences}: & $\theta\quad\coloneqq\quad \varepsilon ~\mid~ a\cdot\theta$\\[5pt]
    \textsf{Label Judgments}: & $\xi\quad\coloneqq\quad \labjudg{\theta}{M}$\\
    \begin{minipage}{.25\linewidth}
    	\textsf{Label Rules}:	  
	\end{minipage}
	&
    \begin{minipage}{.70\linewidth}
    \[
    \begin{array}{c}
    \infer{\labjudg{\theta}{x}}{}\qquad\quad
    \infer{\labjudg{\theta}{\x.M}}{\labjudg{\theta}{M}}\qquad\quad
    \infer{\labjudg{\theta}{\ttrm{!a.M}}}{\labjudg{a\cdot\theta}{M}}
    \\\\
    \infer{\labjudg{\theta}{MN}}{\labjudg{\theta}{M} & \labjudg{\theta}{N}}\qquad\quad
    \infer{\labjudg{\theta}{\ttrm{M +a N}}}{\labjudg{\theta}{M} & \labjudg{\theta}{N} & a\in\theta}
    \end{array}
    \]
    \end{minipage}
    \\
\end{tabular}
}[4pt]
\caption{Labeling terms}
\label{fig:order}
\end{figure}
%
It is easy to realize that, of course modulo label $\alpha$-equivalence, for
every term $M$ there is at least one $\theta$ such that $\labjudg{\theta}{M}$.
An easy fact to check is that if $\labjudg{\theta}{M}$ and $M\rw^\theta N$, then $\labjudg{\theta}{N}$.
It thus makes sense to parametrize $\rw$ on a sequence
of labels $\theta$, \ie, one can define a family of reduction
relations $\rw^\theta$ on pairs in the form $(M,\theta)$.
The set of strongly normalizable terms, and the number of steps
to normal forms become themselves parametric:
\begin{varitemize}
\item
  The set $\mathit{SN}^\theta$ of those terms $M$ such
  that $\labjudg{\theta}{M}$ and $(M,\theta)$ is strongly
  normalizing modulo $\rw^\theta$;
\item
  The function $\mathit{sn}^\theta$ assigning to any
  term in $\mathit{SN}^\theta$ the maximal number of $\rw^\theta$
  steps to normal form.
\end{varitemize}

\noindent
We can now define types, environments, judgments, and typing rules in
Figure~\ref{fig:typing}.
%
\begin{figure}
\figframe[4pt]{
    \begin{tabular}{ll@{}l}
        \textsf{Types}: & $\tau$ & $\quad\coloneqq\quad \alpha ~\mid~ \tau\arrow\rho$\\[5pt]
        \textsf{Environments}: & $\Gamma$ & $\quad\coloneqq\quad x_1:\tau_1,\ldots,x_n:\tau_n$\\[5pt]
        \textsf{Judgments}: & $\pi$ & $\quad\coloneqq\quad \judg{\Gamma}{M}{\tau}$\\
        \begin{minipage}{.20\textwidth}\textsf{Typing Rules}:\end{minipage} &
        \multicolumn{2}{@{}c@{}}{
        \begin{minipage}{.75\textwidth}
        \[
        \begin{array}{@{}c@{}}
        \infer{\judg{\Gamma,x:\tau}{x}{\tau}}{}\qquad\quad
        \infer{\judg{\Gamma}{\x.M}{\tau\arrow\rho}}{\judg{\Gamma,x:\tau}M\rho}\qquad\quad
        \infer{\judg{\Gamma}{\ttrm{!a.M}}{\tau}}{\judg{\Gamma}{M}{\tau}}
        \\\\
        \infer{\judg{\Gamma}{MN}{\rho}}{\judg{\Gamma}{M}{\tau\arrow\rho} & \judg{\Gamma}{N}{\tau}}\qquad\quad
        \infer{\judg{\Gamma}{\ttrm{M +a N}}{\tau}}{\judg{\Gamma}{M}{\tau} & \judg{\Gamma}{N}{\tau}}
        \end{array}
        \]
        \end{minipage}}
        \\
      \end{tabular}
}[4pt]
\caption{Types, environments, judgments, and rules}
\label{fig:typing}
\end{figure}
%
Please notice that the type structure is precisely the one of the
usual, vanilla, simply-typed $\lambda$-calculus (although terms are of
course different), and we can thus reuse most of the usual proof of
strong normalization, for example in the version given by Ralph
Loader's notes~\cite{Loader98}, page 17.

\begin{lem}
\label{lemma:cloredsum}
  The following rule is sound:
  \[
  \infer{\trm{M +a N}L_1 \ldots L_m\in\mathit{SN}^\theta}{ML_1\ldots L_m\in\mathit{SN}^\theta & NL_1\ldots L_m\in\mathit{SN}^\theta & a\in\theta}
  \]
\end{lem}
\begin{proof}
  Let $h(a,\theta)$ be the height of $a$ in the sequence $\theta$.
  The proof goes by lexicographic induction on the following quadruple:
  \begin{align}
  \label{equ:redord}
  (m,h(a,\theta),\sum_{i=1}^m\mathit{sn}^\theta(L_i)+\mathit{sn}^\theta(M)+\mathit{sn}^\theta(N),|M|+|N|)
  \end{align}
  We proceed by showing that all terms to which
  $\trm{M +a N}L_1\ldots L_m$ reduces are in $\mathit{SN}^\theta$, and thus
  $\trm{M +a N}L_1\ldots L_m$ is itself in $\mathit{SN}^\theta$:
  \begin{varitemize}
  \item
    If reduction happens in one between $M,N,L_1,\ldots,L_m$, then we
    are done, because we get an instance of the rule where the first two
    components of (\ref{equ:redord}) stay constant, and the third
    strictly decreases.
  \item
    If reduction happens at the leftmost component $\trm{M +a N}$
    due to the rule $\trm{P +a P}\rw_\perm P$, then one of the two
    hypotheses apply trivially.
  \item
    If reduction happens at the leftmost component $\trm{M +a N}$
    due to the rule $\trm{(P +a Q) +a R}\rw_\perm \trm{P +a R}$,
    then the \ih\ holds due to the fourth component being strictly
    smaller. Similarly when the rule is
    $\trm{P +a (Q +a R)}\rw_\perm \trm{P +a R}$.
  \item
    If reduction happens in the leftmost application due to
    the rule $\trm{(P +a Q) R}\rw_\perm \trm{(PR) +a (QR)}$,
    then the \ih\ can be applied, because the number of arguments $m$
    strictly decreases. Similarly when the rule is
    $\trm{N (M +a P)}\rw_\perm\trm{(NM) +a (NP)}$.
  \item
    If reduction happens at the leftmost component $\trm{M +a N}$
    due to the rule $\trm{(P +b Q) +a R}\rw_\perm \trm{(P +a R) +b (Q +a R)}$,
    then $M$ can be written as $\trm{P +b Q}$, and the
    following two terms are strongly normalizing (because
    $\trm{(P +b Q)L_1\ldots L_m}$ is by hypothesis strongly normalizing
      itself):
    \[
    PL_1\ldots L_m\qquad QL_1\ldots L_m
    \]
    Moreover, $\mathit{sn}^\theta(PL_1\ldots L_m),\mathit{sn}^\theta(QL_1\ldots
    L_m)\leq\mathit{sn}^\theta(\trm{(P +b Q)L_1\ldots L_m}$.  We can then
    conclude that $\trm{(P +a N)}L_1\ldots L_m$ and $\trm{(Q +a
        N)}L_1\ldots L_m$ are both strongly normalizing by \ih, because
    the fourth component is strictly smaller. Finally, we can conclude
    again by induction hypothesis, since the number of arguments stays
    the same, while the level of $b$ must be smaller than that of
    $a$. Similarly if the rule applied is $\trm{P +a (Q +b
      R)}\rw_\perm \trm{(P +a Q) +b (P +a R)}$.
  \end{varitemize}
\end{proof}

\begin{lem}\label{lemma:cloredbox}
The following rule is sound:
\[
  \infer{\trm{(!a.M)}L_1\ldots L_m\in\mathit{SN}^\theta}{\trm{M}L_1\ldots L_m\in\mathit{SN}^{a\cdot\theta} & \forall i.a\not\in L_i}
\]
\end{lem}
\begin{proof}
  The proof is structurally very similar to the one of
  Lemma~\ref{lemma:cloredsum}. The lexicographic order
  is however the following one:
  \[
  (m,\sum_{i=1}^m\mathit{sn}^{a\cdot\theta}(L_i)+\mathit{sn}^{a\cdot\theta}(M),|M|)~.
  \]
  There is one case in which we need to use
  Lemma \ref{lemma:cloredsum}, namely the one in which the
  considered reduction rule is the $\plusBox$ rule, \ie\ the following:
  \[
  \trm{!b.(P +a Q)}\rw_\perm\trm{(!b.P) +a (!b.Q)}~.
  \]
  Since $M=\trm{P +a Q}$ and $ML_1\ldots L_m$ by hypothesis,
  we conclusde that $PL_1\ldots L_m$ and $QL_1\ldots L_m$
  are both strongly normalizing. By induction hypothesis,
  since $\mathit{sn}^{a\cdot\theta}(P),\mathit{sn}^{a\cdot\theta}(Q)\leq\mathit{sn}^{a\cdot\theta}(M)$,
  it holds that both terms $\trm{(!b.P)}L_1\ldots L_m$ and $\trm{(!b.Q)}L_1\ldots L_m$
  are strongly normalizing themselves. Lemma~\ref{lemma:cloredsum} then
  yields the thesis.
\end{proof}

\begin{lem}\label{lemma:cloredheadvar}
  The following rule is sound
  \[
  \infer{xL_1\ldots L_m\in\mathit{SN}^\theta}{L_1\in\mathit{SN}^\theta &\cdots & L_m\in\mathit{SN}^\theta}
  \]
\end{lem}

\begin{proof}
	Trivial, since the term $xL_1\ldots L_m$ cannot create new redexes.
\end{proof}

\begin{lem}
\label{lemma:cloredbeta}
  The following rule is sound
  \[
  \infer{\trm{(\x.M)}L_0\ldots L_m\in\mathit{SN}^\theta}{\trm{M[L_0/x]}L_1\ldots L_m\in\mathit{SN}^\theta & L_0\in\mathit{SN}^\theta}
  \]
\end{lem}
\begin{proof}
  Again, the proof is structurally very similar to the one
  of Lemma~\ref{lemma:cloredsum}. The underlying order,
  needs to be slightly adapted, and is the lexicographic
  order on
  \begin{align}
  \label{equ:redordbet}
  (\mathit{sn}(\trm{M[L_0/x]}L_1\ldots L_m)+\mathit{sn}(L_0),|M|)
  \end{align}
  As usual, we proceed by showing that all terms to which
  $\trm{(\x.M)}L_0\ldots L_m$ reduces are strongly normalizing:
  \begin{itemize}
  \item
    If reduction happens in $L_0$, then we can mimick
    the same reduction in by zero or more reduction
    steps in $\trm{M[L_0/x]}L_1\ldots L_m$, and conclude
    by induction hypothesis, because the first component
    of (\ref{equ:redordbet}) strictly decreases.
  \item
    If reduction happens in $M$ or in $L_1,\ldots,L_m$,
    then we can mimick the same reduction in one or more
    reduction in $\trm{M[L_0/x]}L_1\ldots L_m$, and conclude
    by induction hypothesis since, again, the first component
    of (\ref{equ:redordbet}) strictly decreases.
  \item
    If the reduction step we perform reduces
    $\trm{(\x.M)}L_0$, then the thesis follows from the
    hypothesis about $\trm{M[L_0/x]}L_1\ldots L_m$.
  \item
    If $M$ is in the form $\trm{P +a Q}$ and
    the reduction step we perform reduces the term
    $\trm{(\x.M)}L_0\ldots L_m$
    to $\trm{((\x.P)+a(\x.Q))}L_0\ldots L_m$,
    we proceed by observing that
    $\trm{(\x.P)}L_0\ldots L_m$
    and $\trm{(\x.Q)}L_0\ldots L_m$ are
    both in $\mathit{SN}^\theta$ and we
    can apply the induction hypothesis to them,
    because the first component of (\ref{equ:redordbet})
    stays the same, but the second one strictly decreases.
    We then obtain that
    $\trm{P[x/L_0])}L_1\ldots L_m$
    and $\trm{Q[x/L_0]}L_1\ldots L_m$ are both
    in $\mathit{SN}^\theta$, and from Lemma~\ref{lemma:cloredsum}
    we get the thesis.
  \item
    If $M$ is in the form $\trm{!a.P}$ and
    the reduction step we perform reduces the term
    $\trm{(\x.M)}L_0\ldots L_m$ to
    $\trm{!a.(\x.P)}L_0\ldots L_m$. We can
    first of all that we can assume that
    $a\not\in L_i$ for every $0\leq i\leq m$.
    We proceed by observing that
    $\trm{(\x.P)}L_0\ldots L_m$ is in $\mathit{SN}^\theta$
    and we can apply the \ih\ to it, because
    the first component of (\ref{equ:redordbet})
    stays the same, but the second one strictly decreases.
    We then obtain that
    $\trm{P[x/L_0]}L_1\ldots L_m$
    is in $\mathit{SN}^\theta$, and from Lemma~\ref{lemma:cloredbox}
    we get the thesis.
  \end{itemize}
\end{proof}

Since the structure of the type system is the one of plain, simple
types, the definition of reducibility sets is the classic one:
\begin{align*}
  \RedSet{\alpha}&=\{(\Gamma,\theta,M)\mid M\in\mathit{SN}^\theta\wedge\judg{\Gamma}{M}{\alpha}\};\\
  \RedSet{\tau\arrow\rho}&=\{(\Gamma,\theta,M)\mid(\judg{\Gamma}{M}{\tau\arrow\rho})\wedge(\labjudg{\theta}{M}) \ \wedge\\
    &\qquad\forall(\Gamma\Delta,\theta,N)\in\RedSet{\tau}.(\Gamma\Delta,\theta,MN)\in\RedSet{\rho}\}.
\end{align*}
Before proving that all terms are reducible, we need some
auxiliary results.
\begin{lem}\label{lemma:redprop}
  \begin{enumerate}
  \item\label{point:impl}
    If $(\Gamma,\theta,M)\in\RedSet{\tau}$, then $M\in\mathit{SN}^\theta$.
  \item\label{point:headvar}
    If $\judg{\Gamma}{x L_1\ldots L_m}{\tau}$ and $L_1,\ldots,L_m\in\mathit{SN}^\theta$,
    then $(\Gamma,\theta,x L_1\ldots L_m)\in\RedSet{\tau}$.
  \item\label{point:beta}
    If $(\Gamma,\theta,\trm{M[L_0/x]}L_1\ldots L_m)\in\RedSet{\tau}$
    with $\judg{\Gamma}{L_0}{\rho}$ and $L_0\in\mathit{SN}^\theta$,
    then $(\Gamma,\theta,\trm{(\x.M)}L_0\ldots L_m)\in\RedSet{\tau}$.
  \item\label{point:sum}
    If $(\Gamma,\theta,ML_1\ldots L_m)\in\RedSet{\tau}$ with
    $(\Gamma,\theta,NL_1\ldots L_m)\in\RedSet{\tau}$ and $a\in\theta$,
    then $(\Gamma,\theta,\trm{(M +a N)}L_1\ldots L_m)\in\RedSet{\tau}$.
  \item\label{point:box}
    \begin{sloppypar}
    If $(\Gamma,a\cdot\theta,ML_1\ldots L_m)\in\RedSet{\tau}$
    and $a\not\in L_i$ for all $i$,\\
    then $(\Gamma,\theta,\trm{(!a.M)}L_1\ldots L_m)\in\RedSet{\tau}$.
    \end{sloppypar}
  \end{enumerate}
\end{lem}
\begin{proof}
  The proof is an induction on $\tau$:
  If $\tau$ is an atom $\alpha$, then Point \ref{point:impl} follows
  by definition, while points \ref{point:headvar} to \ref{point:box}
  come from Lemma~\ref{lemma:cloredsum}, Lemma~\ref{lemma:cloredbox},
  Lemma~\ref{lemma:cloredheadvar}, and Lemma~\ref{lemma:cloredbeta}.
  If $\tau$ is $\rho\arrow\mu$, Points \ref{point:headvar} to \ref{point:box}
  come directly from the induction hypothesis, while Point \ref{point:impl}
  can be proved by observing that $M$ is in $\mathit{SN}^\theta$
  if $Mx$ is itself $\mathit{SN}^\theta$, where $x$ is a fresh variable.
  By induction hypothesis (on Point~\ref{point:headvar}), we can
  say that $(\Gamma(x:\rho),\theta,x)\in\RedSet{\rho}$, and
  conclude that $(\Gamma(x:\rho),\theta,Mx)\in\RedSet{\mu}$.
\end{proof}

The following is the so-called Main Lemma:
\begin{prop}\label{lemma:mainlemma}
  Suppose $\judg{y_1:\tau_1,\ldots,y_n:\tau_n}{M}{\rho}$ and
  $\labjudg{\theta}{M}$, with
  $(\Gamma,\theta,N_j)\in\RedSet{\tau_j}$ for all $1\leq j\leq
  n$. Then
  $(\Gamma,\theta,M[N_1/y_1,\ldots,N_n/y_n])\in\RedSet{\rho}$.
\end{prop}
\begin{proof}
  This is an induction on the structure of the term $M$:
  \begin{varitemize}
  \item
    If $M$ is a variable, necessarily one among $y_1,\ldots,y_n$,
    then the result is trivial.
  \item
    If $M$ is an application $LP$, then there exists
    a type $\xi$ such that
    $\judg{y_1:\tau_1,\ldots,y_n:\tau_n}{L}{\xi\arrow\rho}$
    and $\judg{y_1:\tau_1,\ldots,y_n:\tau_n}{P}{\xi}$. Moreover,
    $\labjudg{\theta}{L}$ and $\labjudg{\theta}{P}$ we can
    then safely apply the induction hypothesis and conclude
    that
    $$
    (\Gamma,\theta,L[\overline{N}/\overline{y}])\in\RedSet{\xi\arrow\rho}
    \qquad
    (\Gamma,\theta,P[\overline{N}/\overline{y}])\in\RedSet{\xi}~.
    $$
    By definition, we get
    $$
    (\Gamma,\theta,(LP)[\overline{N}/\overline{y}])\in\RedSet{\rho}~.
    $$
  \item
    \begin{sloppypar}
    If $M$ is an abstraction $\trm{\x.L}$, then $\rho$
    is an arrow type $\xi\arrow\mu$ and
    $\judg{y_1:\tau_1,\ldots,y_n:\tau_n,x:\xi}{L}{\mu}$.
    Now, consider any $(\Gamma\Delta,\theta,P)\in\RedSet{\xi}$.
    Our objective is to prove with this hypothesis
    that $(\Gamma\Delta,\theta,(\x.L[\overline{N}/\overline{y}])P)\in\RedSet{\mu}$.
    By induction hypothesis, since $(\Gamma\Delta,N_i)\in\RedSet{\tau_i}$,
    we get that $(\Gamma\Delta,\theta,L[\overline{N}/\overline{y},P/x])\in\RedSet{\mu}$.
    The thesis follows from Lemma~\ref{lemma:redprop}.
    \end{sloppypar}
  \item
    If $M$ is a sum $\trm{L+a P}$, we can make use of Lemma~\ref{lemma:redprop}
    and the induction hypothesis, and conclude.
  \item
    If $M$ is a generator $\trm{!a.P}$, we can make use of Lemma~\ref{lemma:redprop}
    and the induction hypothesis. We should however observe that $\labjudg{a\cdot\theta}{P}$,
    since $\labjudg{\theta}{M}$.
  \end{varitemize}
\end{proof}

We now have all the ingredients for our proof of strong normalization:
\begin{thm}
  If $\judg{\Gamma}{M}{\tau}$ and $\labjudg{\theta}{M}$, then $M\in\mathit{SN}^\theta$.
\end{thm}
\begin{proof}
  Suppose that $\judg{x_1:\rho_1,\ldots,x_n:\rho_n}{M}{\tau}$.
  Since $\judg{x_1:\rho_1,\ldots,x_n:\rho_n}{x_i}{\rho_i}$ for all
  $i$, and clearly $\labjudg{\theta}{x_i}$ for every $i$, we
  can apply Lemma \ref{lemma:mainlemma} and
  obtain that $(\Gamma,\theta,M[\overline{x}/\overline{x}])\in\RedSet{\tau}$
  from which, via Lemma~\ref{lemma:redprop}, one gets the thesis.
\end{proof}


%============================================================ PROJECTIVE


\section{Projective Reduction}
\label{sec:projective-reduction}

Permutative reduction $\rw_\perm$ evaluates probabilistic sums purely by rewriting. Here we look at a more standard \emph{projective} notion of reduction, which conforms more closely to the intuition that $\ttrm{!a}$ generates a probabilistic event to determine the choice $\ttrm{+a}$. Using $+$ for an external probabilistic sum, we expect to reduce $\ttrm{!a.N}$ to $N_0+N_1$ where each $N_i$ is obtained from $N$ by projecting every subformula $\ttrm{M_0+aM_1}$ to $M_i$. The question is, in what context should we admit this reduction? We first limit ourselves to reducing in \emph{head} position.

\begin{defn}
The \emph{$a$-projections} $\proj a0N$ and $\proj a1N$ are defined as follows:
\begin{align*}
	\proj a0{N+aM} &= \proj a0N		&	\proj ai{\x.N} &= \x.\proj aiN
\\	\proj a1{N+aM} &= \proj a1M		&	\proj ai{NM}   &= \proj aiN\,\proj aiM
\\	\proj ai{!a.N} &= \trm{!a.N}	& 	\proj ai{N+bM} &= \proj aiN\,\trm{+b}\,\proj aiM && \text{if } a \neq b
\\	\proj aix      &= x				&	\proj ai{!b.N} &= \trm{!b.}\proj aiN 			 && \text{if } a \neq b.
\end{align*}
\end{defn}

\begin{defn}
A \emph{head context} $H[\,]$ is given by the following grammar.
\[
	H[\,] \coloneqq [\,] ~\mid~ \x.\,H[\,] ~\mid~ H[\,]N
\]
\end{defn}

\begin{defn}
\label{defn:projective head reduction}
\emph{Projective head reduction} $\rw_\ph$ is given by
\[
	\trm{H[\,!a.N]} ~\rw_\ph~ H[\proj a0N] + H[\proj a1N]~.
\]
\end{defn}

We can simulate $\rw_\ph$ by permutative reduction if we interpret the external sum $+$ by an outermost $\+$ (taking special care if the label does not occur).

\begin{prop}
\label{prop:permutative-simulates-projective}
Permutative reduction simulates projective head reduction:
\[
	H[\,\trm{!a.N}] ~\rws_\perm~
	\left\{\begin{array}{l@{\qquad}l}
		H[N]						 & \text{if }a\notin\fl N \\[5pt]
		H[\proj a0N] \+ H[\proj a1N] & \text{otherwise}.
	\end{array}\right.
\]
\end{prop}

\begin{proof}
The case $a\notin\fl N$ is immediate by a $\boxVoid$ step. For the other case, observe that $\trm{H[\,!a.N]}\rws_\perm\trm{!a.H[N]}$ by $\boxAbs$ and $\boxFun$ steps, and since $a$ does not occur in $H[\,]$, that $H[\proj aiN]=\proj ai{H[N]}$. By induction on $N$, if $a$ is minimal in $N$ (\ie\ $a\in\fl N$ and $a\leq b$ for all $b\in\fl N$) then $N\rws_\perm \proj a0N\trm{+a}\proj a1N$. As required,
\[
	H[\,\trm{!a.N}]~\rws_\perm~ \trm{!a.}\,H[\proj a0N]\, \trm{+a}\, H[\proj a1N] \quad\text{if }a\in\fl N~.%\qedhere
\]
%The case $a\notin\fl N$ is immediate by a $\boxVoid$ step. For the other case, observe that $\trm{H[\,!a.N]}\rws_\perm\trm{!a.H[N]}$ by $\boxAbs$ and $\boxFun$ steps, and since $a$ does not occur in $H[\,]$, we have $H[\proj aiN]=\proj ai{H[N]}$. Unfolding also the definition of $\+$, we may thus restrict ourselves to proving the following.
%\[
%	\trm{!a.N} ~\rws_\perm~ \trm{!a.} \proj a0N~\trm{+a}~\proj a1N
%\]
%Given that $a$ is the smallest label in $N$, \ie\ $a<b$ for any other label $b$ in $N$, a straightforward induction on $N$ gives $N\rws_\perm\proj a0N~\ttrm{+a}~\proj a1N$, with as special base case $N\rws_\perm N$ for $a\notin\fl N$.
\end{proof}

A gap remains between which generators will not be duplicated, which we \emph{should} be able to reduce, and which generators projective head reduction \emph{does} reduce. In particular, to interpret call-by-value probabilistic reduction in Section~\ref{sec:cbv}, we would like to reduce under other generators. However, permutative reduction does not permit exchanging generators, and so only simulates reducing in head position. While (independent) probabilistic events are generally considered interchangeable, it is a question whether the below equivalence is desirable.
%
\begin{align}
\label{eqn:permute-generators}
	\trm{!a.!b.N} \quad\smash{\stackrel?\sim}\quad \trm{!b.!a.N}
\end{align}
%
We elide the issue by externalizing probabilistic events, and reducing with reference to a predetermined binary stream $s\in\{0,1\}^{\mathbb N}$ representing their outcomes. In this way, we will preserve the intuitions of both permutative and projective reduction: we obtain a qualified version of the equivalence~\eqref{eqn:permute-generators} (see \eqref{eqn:permute-generators-streams} below), and will be able to reduce any generator on the \emph{spine} of a term: under (other) generators and choices as well as under abstractions and in function position.

\begin{defn}
The set of \emph{streams} is $\Streams=\{0,1\}^\mathbb{N}$, ranged over by $r,s,t$, and $i\cdot s$ denotes a stream with $i\in\{0,1\}$ as first element and $s$ as the remainder.
\end{defn}

\begin{defn}
The \emph{stream labeling} $N^s$ of a term $N$ with a stream $s\in\Streams$, which annotates generators as $\trm{!ai}$ with $i\in\{0,1\}$ and variables as $x^s$ with a stream $s$, is given inductively below. We lift $\beta$-reduction to stream-labeled terms by introducing a substitution case for stream-labeled variables: $x^s[M/x] = M^s$.
\begin{align*}
	\trm{(\x.N)^s} &= \trm{\x.N^s} & \trm{(!a.N)^{i\cdot s}} &= \trm{!ai.N^s} 
	\\
	\trm{(N\,M)^s} &= \trm{N^s\,M} & \trm{(N+a M)^s}		 &= \trm{N^s +a M^s}
\end{align*}

\end{defn}

\begin{defn}
\emph{Projective reduction} $\rw_\pi$ on stream-labeled terms is the rewrite relation given by
\[
	\trm{!ai.N} ~\rw_\pi~\proj aiN~.
\]
\end{defn}

Observe that in $N^s$ a generator that occurs under $n$ other generators on the spine of $N$, is labeled with the element of $s$ at position $n+1$. Generators in argument position remain unlabeled, until a $\beta$-step places them on the spine, in which case they become labeled by the new substitution case. We allow to annotate a term with a finite prefix of a stream, \eg\ $N^i$ with a singleton $i$, so that only part of the spine is labeled. Subsequent labeling of a partly labeled term is then by $(N^r)^s=N^{r\cdot s}$ (abusing notation). To introduce streams via the external probabilistic sum, and to ignore an unused remaining stream after completing a probabilistic computation, we adopt the following equation.
\[
 	N = N^0 + N^1
\]

\begin{prop}
Projective reduction generalizes projective head reduction:
\[
	\trm{H[\,!a.N]} ~=~ \trm{H[\,!a{}^0.N]} + \trm{H[\,!a{}^1.N]} ~\rw_\pi~ H[\proj a0N]+H[\proj a1N]~.
\]
\end{prop}

Returning to the interchangeability of probabilistic events, we refine~\eqref{eqn:permute-generators} by exchanging the corresponding elements of the annotating streams:
\begin{align}
\label{eqn:permute-generators-streams}
\vcenter{\hbox{
\begin{tikzpicture}[x=80pt,y=-15pt]
	\node     at (0,0) {$\trm{(!a.!b.N)}^{i\cdot j\cdot s}$};
	\node     at (0,2) {$\trm{(!b.!a.N)}^{j\cdot i\cdot s}$};
	\node (A) at (1,0) {$\trm{!ai.!b{}^j.N^s}$};
	\node (B) at (1,2) {$\trm{!b{}^j.!ai.N^s}$};
	\node (C) at (2,0) {$\pi^a_i(\proj bj{N^s})$};
	\node (D) at (2,2) {$\pi^b_j(\proj ai{N^s})$};
	\draw[rws] (A) --node[above] {$\scriptstyle\pi$}   (C);
	\draw[rws] (B) --node[above]{$\scriptstyle\pi$}   (D);
	\node at (0,1) {$\sim$};
	\node at (0.5,0) {$=$};
	\node at (0.5,2) {$=$};
	\node at (2,1) {$=$};
\end{tikzpicture}}}
\end{align}

Stream-labeling externalizes all probabilities, making reduction deterministic. This is expressed by the following proposition, that stream-labeling commutes with reduction: if a generator remains unlabeled in $M$ and becomes labeled after a reduction step $M\rw N$, what label it receives is predetermined. The deep reason is that stream labeling assigns an outcome to each generator in a way that corresponds to a call-by-name strategy for probabilistic reduction.


\begin{prop}
\label{prop:labeling-commutes}
If $M \rw N$ by a step other than $\boxVoid$ then $M^s \rw N^s$.
\end{prop}

\begin{rmrk}
The statement is false for the $\boxVoid$ rule $\trm{!a.N}\rw_\perm N~(a\notin\fl N)$, as it removes a generator but not an element from the stream. Arguably, for this reason the rule should be excluded from the calculus. On the other hand, the rule is necessary to implement idempotence of $\+$, rather than just $\ttrm{+a}$, as follows.
\[
	N\+N ~=~ \trm{!a.N+aN} ~\rw_\perm~ \trm{!a.N} ~\rw_\perm~ N \qquad \text{where } a\notin\fl N
\]
\end{rmrk}

The below proposition then expresses that projective reduction is an \emph{invariant} for permutative reduction. If $N\rw_\perm M$ by a step (that is not $\boxVoid$) on a labeled generator $\ttrm{!ai}$ or a corresponding choice $\ttrm{+a}$, then $N$ and $M$ reduce to a common term, $N\rw_\pi P\,{}_\pi\lw\,M$, by the projective steps evaluating $\ttrm{!ai}$.

\begin{prop}
Projective reduction is an invariant for permutative reduction, as follows (with a case for $\cancelR$ symmetric to $\cancelL$, and where $D[\,]$ is a context).
\[
\begin{tikzpicture}[x=40pt,y=30pt]
	\node (A) at (0,1) {$\trm{!ai.C[N+aN]}$};
	\node (B) at (2,1) {$\trm{!ai.C[N]}$};
	\node (C) at (1,0) {$\proj ai{C[N]}$};
	\draw[rw] (A) --node[above]{$\scriptstyle\perm$} (B);
	\draw[rw] (A.south) --node[below] {$\scriptstyle\pi$}  (C.north west);
	\draw[rw] (B.south) --node[below]{$\scriptstyle\pi$}   (C.north east);
	\node at (1,.5) {$\idem$};
\end{tikzpicture}
\qquad
\begin{tikzpicture}[x=50pt,y=30pt]
	\node (A) at (0,1) {$\trm{!ai.C[(N_0 +a M) +a N_1]}$};
	\node (B) at (2,1) {$\trm{!ai.C[N_0 +a N_1]}$};
	\node (C) at (1,0) {$\proj ai{C[N_i]}$};
	\draw[rw] (A) --node[above]{$\scriptstyle\perm$} (B);
	\draw[rw] (A.south) --node[below] {$\scriptstyle\pi$}  (C.north west);
	\draw[rw] (B.south) --node[below]{$\scriptstyle\pi$}   (C.north east);
	\node at (1,.5) {$\cancelL$};
\end{tikzpicture}
\]
\[
\begin{tikzpicture}[x=60pt,y=30pt]
	\node (A) at (0,1) {$\trm{!ai.C[D[N_0+aN_1]]}$};
	\node (B) at (2,1) {$\trm{!ai.C[D[N_0]+aD[N_1]]}$};
	\node (C) at (1,0) {$\proj ai{C[D[N_i]]}$};
	\draw[rw] (A) --node[above]{$\scriptstyle\perm$} (B);
	\draw[rw] (A.south) --node[below] {$\scriptstyle\pi$}  (C.north west);
	\draw[rw] (B.south) --node[below]{$\scriptstyle\pi$}   (C.north east);
	\node at (1,.5) {$\plusX$};
\end{tikzpicture}
\]
\[
\begin{tikzpicture}[x=36pt,y=30pt]
	\node (A) at (0,1) {$\trm{\x.!ai.N}$};
	\node (B) at (2,1) {$\trm{!ai.\x.N}$};
	\node (C) at (0,0) {$\x.\,\proj aiN$};
	\node (D) at (2,0) {$\proj ai{\x.N}$};
	\draw[rw] (A) --node[above]{$\scriptstyle\perm$} (B);
	\draw[rw] (A) --node[left] {$\scriptstyle\pi$}   (C);
	\draw[rw] (B) --node[right]{$\scriptstyle\pi$}   (D);
	\node at (1,0) {$=$};
	\node at (1,.5) {$\boxAbs$};
\end{tikzpicture}
\qquad\qquad
\begin{tikzpicture}[x=36pt,y=30pt]
	\node (A) at (0,1) {$\trm{(!ai.N)M}$};
	\node (B) at (2,1) {$\trm{!ai.NM}$};
	\node (C) at (0,0) {$\proj aiN\,M$};
	\node (D) at (2,0) {$\proj ai{N\,M}$};
	\draw[rw] (A) --node[above]{$\scriptstyle\perm$} (B);
	\draw[rw] (A) --node[left] {$\scriptstyle\pi$}   (C);
	\draw[rw] (B) --node[right]{$\scriptstyle\pi$}   (D);
	\node at (1,0) {$=$};
	\node at (1,.5) {$\boxFun$};
\end{tikzpicture}
\]
\end{prop}

%============================================================ CALL-BY-VALUE

\section{Call-by-value Interpretation}
\label{sec:cbv}

We consider the interpretation of a call-by-value probabilistic $\lambda$-calculus. For simplicity we will allow duplicating (or deleting) $\beta$-redexes, and only restrict duplicating probabilities; our \emph{values} $V$ are then just deterministic---\ie~without choices---terms, possibly applications and not necessarily $\beta$-normal (so that our $\rw_{\beta\val}$ is actually $\beta$-reduction on deterministic terms, unlike \cite{DalLagoZorzi12}). 
%
We evaluate the internal probabilistic choice $\ttrm{v{}}$ to an external probabilistic choice $+$.
%
\begin{align*}
   		 N    &\coloneqq x \mid \x.N \mid MN \mid \trm{M v N}	& (\x.N)V 		\rw_{\beta\val} \ & N[V/x]
\\[5pt]	 V, W &\coloneqq x \mid \x.V \mid VW  					& \trm{M v N}\, \rw_\val \, \ & M + N
\end{align*}

The interpretation $\uncbv{N}$ of a call-by-value term $N$ into $\PEL$ is given as follows. First, we translate $N$ to a label-open term $\unopen N=\labjudg\theta P$ by replacing each choice $\ttrm{v}$ with one $\ttrm{+a}$ with a unique label, where the label-context $\theta$ collects the labels used. Then $\uncbv{N}$ is the \emph{label closure} $\uncbv{N}=\labclose\theta P$, which prefixes $P$ with a generator $\ttrm{!a}$ for every $a$ in $\theta$.

\begin{defn}(Call-by-value interpretation)
The \emph{open interpretation} $\unopen N$ of a call-by-value term $N$ is as follows, where all labels are fresh, and inductively $\unopen{N_i}=\labjudg{\theta_i}{P_i}$ for $i\in\{1,2\}$.
\[
\begin{array}{r@{\quad}c@{\quad}l@{\qquad}r@{\quad}c@{\quad}l}
		\unopen x 		 &=& \labjudg{}x				& \unopen {N_1N_2}   &=& \labjudg{\theta_2\cdot\theta_1}{P_1P_2}
\\[5pt]	\unopen {\x.N_1} &=& \labjudg{\theta_1}{\x.P_1} & \unopen {N_1\plusval N_2} &=& \labjudg{\theta_2\cdot\theta_1\cdot a}{\trm{P_1 +a P_2}}
\end{array}
\]
The \emph{label closure} $\labclose\theta P$ is given inductively as follows.
\[
	\labclose{}P = P \qquad \labclose{a\cdot\theta}P = \labclose\theta{\trm{!a.P}}
\]
The \emph{call-by-value interpretation} of $N$ is $\uncbv N=\lfloor\unopen N\rfloor$.
\end{defn}

Our call-by-value reduction may choose an arbitrary order in which to evaluate the choices $\ttrm{v{}}$ in a term $N$, but the order of generators in the interpretation $\uncbv N$ is necessarily fixed. Then to simulate a call-by-value reduction, we cannot choose a fixed context stream a priori; all we can say is that for every reduction, there is some stream that allows us to simulate it. Specifically, a reduction step $\trm{C[N_0vN_1]}\rw_\val\trm{C[N_j]}$ where $C[\,]$ is a call-by-value term context is simulated by the following projective step.
\[
	\trm{\dots!ai.!b{}^j.!c{}^k\dots D[P_0+bP_1]}
	\quad \rw_\pi \quad
	\trm{\dots!ai.!c{}^k\dots D[P_j]}
\]
%\begin{tikzpicture}[x=80pt,y=30pt]
%	\node (A) at (0,1) {$\trm{C[N_0vN_1]}$};
%	\node (B) at (2,1) {$\trm{C[N_j]}$};
%	\node (C) at (0,0) {$\trm{\dots!ai.!b{}^j.!c{}^k\dots D[P_0+bP_1]}$};
%	\node (D) at (2,0) {$\trm{\dots!ai.!c{}^k\dots D[P_j]}$};
%	\draw[rw] (A) --node[above]{$\scriptstyle\val$} (B);
%	\draw[rw] (C) --node[above]{$\scriptstyle\pi$}   (D);
%\end{tikzpicture}
Here, $\unopen{\trm{C[N_0vN_1]}}=\labjudg{\theta}{\trm{D[P_0+bP_1]}}$ with $D[\,]$ a $\PEL$-context, and $\theta$ giving rise to the sequence of generators $\ttrm{\dots!a.!b.!c\dots}$ in the call-by-value translation. To simulate the reduction step, if $b$ occupies the $n$-th position in $\theta$, then the $n$-th position in the context stream $s$ must be the element $j$. Since $\beta$-reduction survives the translation and labeling process intact, we may simulate call-by-value probabilistic reduction by projective and $\beta$-reduction.

\begin{thm}
If $N\rws_{\val,\beta\val}V$ then $\uncbv N^s\rws_{\pi,\beta}\uncbv V$ for some stream $s\in\Streams$.
\end{thm}



\section{Conclusions and Future Work}

We believe our decomposition of probabilistic choice in $\lambda$-calculus to be an elegant and compelling way of restoring confluence, one of the core properties of the $\lambda$-calculus. Our probabilistic event $\lambda$-calculus captures traditional call-by-name and call-by-value probabilistic reduction, and offers finer control beyond those strategies. Permutative reduction implements a natural and fine-grained equivalence on probabilistic terms as internal rewriting, while projective reduction provides a complementary and more traditional external perspective.

There are a few immediate areas for future work. Firstly, within probabilistic $\lambda$-calculus, it is worth exploring if our decomposition opens up new avenues in semantics. Secondly, our approach might apply to probabilistic reasoning more widely, outside the $\lambda$-calculus. Most importantly, we will explore if our approach can be extended to other computational effects. Our use of streams interprets probabilistic choice as a \emph{read} operation from an external source, which means other read operations can be treated similarly. A complementary treatment of \emph{write} operations would allow us to express a considerable range of effects, including input/output and state.

\subsection*{Acknowledgements}

This work was supported by EPSRC Project EP/R029121/1 \emph{Typed Lambda-Calculi with Sharing and Unsharing}.
The first author is partially supported by the ANR project 19CE480014 PPS, the ERC Consolidator Grant 
818616 DIAPASoN, and the MIUR PRIN 201784YSZ5 ASPRA.
We thank the referees for their diligence and their helpful comments. 
We are grateful to Chris Barrett and---indirectly---Anupam Das for pointing us to Zantema and Van de Pol's work \cite{Zantema-Pol-2001}.


\bibliographystyle{splncs04}
\bibliography{biblio}
\addcontentsline{toc}{section}{References}

%%%%% To display Open Access text and logo, Please add below text and copy the cc_by_4-0.eps in the manuscript package %%%

\newpage
\vspace*{\fill}

{\small\medskip\noindent{\bf Open Access} This chapter is licensed under the terms of the Creative Commons\break Attribution 4.0 International License (\url{http://creativecommons.org/licenses/by/4.0/}), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.}

{\small \spaceskip .28em plus .1em minus .1em The images or other third party material in this chapter are included in the chapter's Creative Commons license, unless indicated otherwise in a credit line to the material.~If material is not included in the chapter's Creative Commons license and your intended\break use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.}

\medskip\noindent\includegraphics{cc_by_4-0.eps}

\end{document}

%\section{Technical appendix: omitted proofs}
%\label{sect:proofs}
%
%The enumeration of lemmas already stated in the body of the article is unchanged.
%
%\setcounter{lemmaAppendix}{\value{lem:confluence-perm}}
%\begin{lemmaAppendix}[Confluence of $\rw_\perm$]
%	\label{lemmaAppendix:confluence-perm}
%	Reduction $\rw_\perm$ is confluent.
%\end{lemmaAppendix}


	
	%=====
%	\SLV{The remaining cases are considered in the Appendix of \cite{arXiv}}{The remaining cases are considered in the proof in the Appendix (p.~\pageref{lemmaAppendix:confluence-perm}).}
%	\qedhere
	
	%\itm\plusFun{\trm{(N+aM)P}\rw\trm{(NP)+a(MP)}}
	%{\small
	%\[
	%\vcenter{\hbox{\begin{tikzpicture}
	%	\matrix [matrix of math nodes] (m) {
	%	  		\trm{(N+aM)(P+aQ)}                &[10pt] \trm{(N(P+aQ))+a(M(P+aQ))}
	%	\\[20pt]\trm{((N+aM)P)+a((N+aM)Q)}        &       \trm{((NP)+a(NQ))+a((MP)+a(MQ))}
	%	\\[20pt]\trm{((NP)+a(MP))+a((NQ)+a(MQ))}  &       \trm{(NP)+a(MQ)}
	%	\\ };
	%	\draw[rw] (m-1-1) --node[above]{$\plusFun$} (m-1-2);
	%	\draw[rw] (m-1-1) --node[left] {$\plusArg$} (m-2-1);
	%	\draw[rws,implied] (m-1-2) --node[right]{$\plusArg$} (m-2-2);
	%	\draw[rws,implied] (m-2-1) --node[left] {$\plusFun$} (m-3-1);
	%	\draw[rws,implied] (m-2-2) --node[right]{$\cancelL,\cancelR$} (m-3-2);
	%	\draw[rws,implied] (m-3-1) --node[below]{$\cancelL,\cancelR$} (m-3-2);
	%\end{tikzpicture}}}
	%\]
	%\[
	%\vcenter{\hbox{\begin{tikzpicture}
	%	\matrix [matrix of math nodes] (m) {
	%	  		\trm{(N+bM)(P+aQ)}         &[20pt] \trm{(N(P+aQ))+b(M(P+aQ))}
	%	\\[20pt]                           &       \trm{((NP)+a(NQ))+b((MP)+a(MQ))} %&[10pt] (a<b)
	%	\\[20pt]\trm{((N+bM)P)+a((N+bM)Q)} &       \trm{((NP)+b(MP))+a((NQ)+b(MQ))}
	%	\\ };
	%	\draw[rw] (m-1-1) --node[above]{$\plusFun$} (m-1-2);
	%	\draw[rw] (m-1-1) --node[left] {$\plusArg$} (m-3-1);
	%	\draw[rws,implied] (m-1-2) --node[right]{$\plusArg$} (m-2-2);
	%	\draw[rws,implied] (m-2-2) --node[right]{$\plusL,\plusR,\cancelL,\cancelR$} (m-3-2);
	%	\draw[rws,implied] (m-3-1) --node[below]{$\plusFun$} (m-3-2);
	%\end{tikzpicture}}}
	%\]
	%}
	%
	%%=====
	%\itm\plusBox{\trm{!b.(N +a M)} \rw \trm{(!b.N) +a (!b.M)}}
	%{\small
	%\[
	%\vcenter{\hbox{\begin{tikzpicture}
	%	\matrix [matrix of math nodes] (m) {
	%	  		\trm{!b.(N+aM)}    &[20pt] \trm{(!b.N)+a(!b.M)}
	%	\\[20pt]\trm{N+aM}
	%	\\ };
	%	\draw[rw] (m-1-1) --node[above]{$\plusBox$} (m-1-2);
	%	\draw[rw] (m-1-1) --node[left] {$\boxVoid$} (m-2-1);
	%	\draw[rws,implied] (m-1-2) --node[below right=-2pt] {$\boxVoid$} (m-2-1);
	%\end{tikzpicture}}}
	%\quad (a \neq b, \ b \notin\trm{N+a M})
	%\]
	%}
%\end{proof}

%\begin{proof}
%	We prove local confluence; by Newman's lemma and strong normalization of $\rw_\perm$ (\Cref{lemma:strong-normalization}), confluence follows. We consider each reduction rule against those lower down in Figure~\ref{fig:reduction rules}. For the symmetric rule pairs $\cancelL$/$\cancelR$, $\plusL$/$\plusR$, and $\plusFun/\plusArg$ we present only the first case. Unless otherwise specified, we let $a<b<c$.
%
%\newcommand\itm[2]{\medskip\noindent(#1)}% \qquad$#2$}
%
%	%=====
%	\itm\idem{\trm{N +a N}\rw N}
%	{\small
%		\[
%		\vc{\begin{tikzpicture}[x=20pt,y=1.5ex]
%			\node[anchor=base east] (a) at (0,0) {$\trm{(N+aN)+aM}$};
%			\node[anchor=base west] (b) at (1,0) {$\trm{N+aM}$};
%			\draw[rw] (0,1) --node[above]{$\idem$}    (1,1);
%			\draw[rw] (0,0) --node[below]{$\cancelL$} (1,0);
%			\end{tikzpicture}}
%		\]
%		\[
%		\vcenter{\hbox{\begin{tikzpicture}
%				\matrix [matrix of math nodes] (m) {
%					\trm{(N+aM)+a(N+aM)} &[20pt] \trm{N+aM}
%					\\[20pt]\trm{N+a(N+aM)}
%					\\ };
%				\draw[rw] (m-1-1) --node[above]{$\idem$}    (m-1-2);
%				\draw[rw] (m-1-1) --node[left] {$\cancelL$} (m-2-1);
%				\draw[rw,implied] (m-2-1) --node[below right=-2pt] {$\cancelR$} (m-1-2);
%				\end{tikzpicture}}}
%		\qquad
%		\vcenter{\hbox{\begin{tikzpicture}
%				\matrix [matrix of math nodes] (m) {
%					\trm{C[N+aN]}    &[20pt] C[N]
%					\\[20pt]\trm{C[N]+aC[N]}
%					\\ };
%				\draw[rw] (m-1-1) --node[above]{$\idem$}  (m-1-2);
%				\draw[rw] (m-1-1) --node[left] {$\plusX$} (m-2-1);
%				\draw[rw,implied] (m-2-1) --node[below right=-2pt] {$\idem$} (m-1-2);
%				\end{tikzpicture}}}
%		\]
%		\[
%		\vcenter{\hbox{\begin{tikzpicture}
%				\matrix [matrix of math nodes] (m) {
%					\trm{(N+aM)+b(N+aM)} &[30pt] \trm{N+aM}
%					\\[20pt]\trm{(N+b(N+aM))+a(M+b(N+aM))} %&&[10pt] (a<b)
%					\\[20pt]\trm{((N+bN)+a(N+bM))+a((M+bN)+a(M+bM))} & \trm{(N+bN)+a(M+bM)}
%					\\ };
%				\draw[rw] (m-1-1) --node[above]{$\idem$}    (m-1-2);
%				\draw[rw] (m-1-1) --node[left] {$\plusL$} (m-2-1);
%				\draw[rws,implied] (m-2-1) --node[left] {$\plusR$}   (m-3-1);
%				\draw[rws,implied] (m-3-2) --node[right]{$\idem$}    (m-1-2);
%				\draw[rws,implied] (m-3-1) --node[below]{$\cancelL,\cancelR$} (m-3-2);
%				\end{tikzpicture}}}
%		\]
%	}
%
%	%=====
%	\itm\cancelL{\trm{(N +a M) +a P}\rw\trm{N +a P}}
%	{\small
%		\[
%		\vcenter{\hbox{\begin{tikzpicture}
%				\matrix [matrix of math nodes] (m) {
%					\trm{(N+aM)+a(P+aQ)} &[15pt] \trm{N+a(P+aQ)}
%					\\[20pt]\trm{(N+aM)+a Q} & \trm{N+aQ}
%					\\ };
%				\draw[rw] (m-1-1) --node[above]{$\cancelL$} (m-1-2);
%				\draw[rw] (m-1-1) --node[left] {$\cancelR$} (m-2-1);
%				\draw[rw,implied] (m-1-2) --node[right]{$\cancelR$} (m-2-2);
%				\draw[rw,implied] (m-2-1) --node[below]{$\cancelL$} (m-2-2);
%				\end{tikzpicture}}}
%		\vcenter{\hbox{\begin{tikzpicture}
%				\matrix [matrix of math nodes] (m) {
%					\trm{C[(N+aM)+aP]} &[15pt] \trm{C[N+aM]}
%					\\[20pt]\trm{C[N+aM]+aC[P]}
%					\\[20pt]\trm{(C[N]+aC[M])+aC[P]} & \trm{C[N]+aC[M]}
%					\\ };
%				\draw[rw] (m-1-1) --node[above]{$\cancelL$} (m-1-2);
%				\draw[rw] (m-1-1) --node[left] {$\plusX$}   (m-2-1);
%				\draw[rw,implied] (m-2-1) --node[left] {$\plusX$}   (m-3-1);
%				\draw[rw,implied] (m-1-2) --node[right]{$\plusX$}   (m-3-2);
%				\draw[rw,implied] (m-3-1) --node[below]{$\cancelL$} (m-3-2);
%				\end{tikzpicture}}}
%		\]
%		\[
%		\vcenter{\hbox{\begin{tikzpicture}
%				\matrix [matrix of math nodes] (m) {
%					\trm{(N+bM)+b(P+aQ)} &[20pt]  \trm{N+b(P+aQ)}
%					\\[20pt]\trm{((N+bM)+bP)+a((N+bM)+bQ)} & \trm{(N+bP)+a(N+bQ)}
%					\\ };
%				\draw[rw] (m-1-1) --node[above]{$\cancelL$} (m-1-2);
%				\draw[rw] (m-1-1) --node[left] {$\plusR$}   (m-2-1);
%				\draw[rw, implied] (m-1-2) --node[right]{$\plusR$} (m-2-2);
%				\draw[rws,implied] (m-2-1) --node[below]{$\cancelL$} (m-2-2);
%				\end{tikzpicture}}}
%		%\qquad(a<b)
%		\]
%	}
%
%	%=====
%	\itm\plusX{\trm{C[N+aM]}\rw\trm{C[N]+a C[M]}}
%	{\small
%		\[
%		\vcenter{\hbox{\begin{tikzpicture}
%				\matrix [matrix of math nodes] (m) {
%					\trm{C[(N+aM)+bP]}      &[20pt] \trm{C[N+aM]+bC[P]}
%					\\[20pt]\trm{C[(N+bP)+a(M+bP)]} &       \trm{(C[N]+aC[M])+bC[P]}		 %&[10pt] (a<b)
%					\\[20pt]\trm{C[N+bP]+aC[M+bP]}  &       \trm{(C[N]+bC[P])+a(C[M]+bC[P])}
%					\\ };
%				\draw[rw] (m-1-1) --node[above]{$\plusX$} (m-1-2);
%				\draw[rw] (m-1-1) --node[left] {$\plusL$} (m-2-1);
%				\draw[rw, implied] (m-1-2) --node[right]{$\plusX$} (m-2-2);
%				\draw[rw, implied] (m-2-1) --node[left] {$\plusX$} (m-3-1);
%				\draw[rw, implied] (m-2-2) --node[right]{$\plusL$} (m-3-2);
%				\draw[rws,implied] (m-3-1) --node[below]{$\plusX$} (m-3-2);
%				\end{tikzpicture}}}
%		\]
%
%		%=====
%		\itm\plusL{\trm{(N+aM)+bP}\rw\trm{(N+bP)+a(M+bP)}}
%		\[
%		\vcenter{\hbox{\begin{tikzpicture}[x=340pt,y=40pt]
%				\node[anchor=west] (a) at (0,2) {$\trm{(N+aM)+b(P+aQ)}$};
%				\node[anchor=west] (b) at (0,1) {$\trm{((N+aM)+bP)+a((N+aM)+bQ)}$};
%				\node[anchor=west] (c) at (0,0) {$\trm{((N+bP)+a(M+bP))+a((N+bQ)+a(M+bQ))}$};
%				%
%				\node[anchor=east] (d) at (1,2) {$\trm{(N+b(P+aQ))+a(M+b(P+aQ))}$};
%				\node[anchor=east] (e) at (1,1) {$\trm{((N+bP)+a(N+bQ))+a((M+bP)+a(M+bQ))}$};
%				\node[anchor=east] (f) at (1,0) {$\trm{(N+bP)+a(M+bQ)}$};
%				%
%				\draw[rw] (a) --node[above]{$\plusL$} (d);
%				\draw[rw] 			($(a.south west)+( 43.5pt,0pt)$) --node[left] {$\plusR$} ($(b.north west)+( 43.5pt,0pt)$);
%				\draw[rws,implied]	($(d.south east)+(-43.5pt,0pt)$) --node[right]{$\plusR$} ($(e.north east)+(-43.5pt,0pt)$);
%				\draw[rws,implied]	($(b.south west)+( 43.5pt,0pt)$) --node[left] {$\plusL$} ($(c.north west)+( 43.5pt,0pt)$);
%				\draw[rws,implied]	($(e.south east)+(-43.5pt,0pt)$) --node[right]{$\cancelL,\cancelR$} ($(f.north east)+(-43.5pt,0pt)$);
%				\draw[rws,implied] (c) --node[below]{$\cancelL,\cancelR$} (f);
%				\end{tikzpicture}}}
%		%\vcenter{\hbox{\begin{tikzpicture}
%		%	\matrix [matrix of math nodes] (m) {
%		%	  		\trm{(N+aM)+b(P+aQ)}                      &[10pt] \trm{(N+b(P+aQ))+a(M+b(P+aQ))}
%		%	\\[20pt]\trm{((N+aM)+bP)+a((N+aM)+bQ)}            &       \trm{((N+bP)+a(N+bQ))+a((M+bP)+a(M+bQ))} %&[10pt] (a<b)
%		%	\\[20pt]\trm{((N+bP)+a(M+bP))+a((N+bQ)+a(M+bQ))}  &       \trm{(N+bP)+a(M+bQ)}
%		%	\\ };
%		%	\draw[rw] (m-1-1) --node[above]{$\plusL$} (m-1-2);
%		%	\draw[rw] (m-1-1) --node[left] {$\plusR$} (m-2-1);
%		%	\draw[rws,implied] (m-1-2) --node[right]{$\plusR$} (m-2-2);
%		%	\draw[rws,implied] (m-2-1) --node[left] {$\plusL$} (m-3-1);
%		%	\draw[rws,implied] (m-2-2) --node[right]{$\cancelL,\cancelR$} (m-3-2);
%		%	\draw[rws,implied] (m-3-1) --node[below]{$\cancelL,\cancelR$} (m-3-2);
%		%\end{tikzpicture}}}
%		\]
%		\[
%		\vcenter{\hbox{\begin{tikzpicture}
%				\matrix [matrix of math nodes] (m) {
%					\trm{(N+bM)+c(P+aQ)}            &[20pt] \trm{(N+c(P+aQ))+b(M+c(P+aQ))}
%					\\[20pt]                                &       \trm{((N+cP)+a(N+cQ))+b((M+cP)+a(M+cQ))} %&[10pt] (a<b<c)
%					\\[20pt]\trm{((N+bM)+cP)+a((N+bM)+cQ)}  &       \trm{((N+cP)+b(M+cP))+a((N+cQ)+b(M+cQ))}
%					\\ };
%				\draw[rw] (m-1-1) --node[above]{$\plusL$} (m-1-2);
%				\draw[rw] (m-1-1) --node[left] {$\plusR$} (m-3-1);
%				\draw[rws,implied] (m-1-2) --node[right]{$\plusR$} (m-2-2);
%				\draw[rws,implied] (m-2-2) --node[right]{$\plusL,\plusR,\cancelL,\cancelR$} (m-3-2);
%				\draw[rws,implied] (m-3-1) --node[below]{$\plusL$} (m-3-2);
%				\end{tikzpicture}}}
%		\]
%	}
%
%	%=====

%	We consider only the cases omitted in the proof on p.~\pageref{lem:confluence-perm}.

	\itm\plusFun{\trm{(N+aM)P}\rw\trm{(NP)+a(MP)}}
	{\small
		\[
		\vcenter{\hbox{\begin{tikzpicture}
				\matrix [matrix of math nodes] (m) {
					\trm{(N+aM)(P+aQ)}                &[10pt] \trm{(N(P+aQ))+a(M(P+aQ))}
					\\[20pt]\trm{((N+aM)P)+a((N+aM)Q)}        &       \trm{((NP)+a(NQ))+a((MP)+a(MQ))}
					\\[20pt]\trm{((NP)+a(MP))+a((NQ)+a(MQ))}  &       \trm{(NP)+a(MQ)}
					\\ };
				\draw[rw] (m-1-1) --node[above]{$\plusFun$} (m-1-2);
				\draw[rw] (m-1-1) --node[left] {$\plusArg$} (m-2-1);
				\draw[rws,implied] (m-1-2) --node[right]{$\plusArg$} (m-2-2);
				\draw[rws,implied] (m-2-1) --node[left] {$\plusFun$} (m-3-1);
				\draw[rws,implied] (m-2-2) --node[right]{$\cancelL,\cancelR$} (m-3-2);
				\draw[rws,implied] (m-3-1) --node[below]{$\cancelL,\cancelR$} (m-3-2);
				\end{tikzpicture}}}
		\]
		\[
		\vcenter{\hbox{\begin{tikzpicture}
				\matrix [matrix of math nodes] (m) {
					\trm{(N+bM)(P+aQ)}         &[20pt] \trm{(N(P+aQ))+b(M(P+aQ))}
					\\[20pt]                           &       \trm{((NP)+a(NQ))+b((MP)+a(MQ))} %&[10pt] (a<b)
					\\[20pt]\trm{((N+bM)P)+a((N+bM)Q)} &       \trm{((NP)+b(MP))+a((NQ)+b(MQ))}
					\\ };
				\draw[rw] (m-1-1) --node[above]{$\plusFun$} (m-1-2);
				\draw[rw] (m-1-1) --node[left] {$\plusArg$} (m-3-1);
				\draw[rws,implied] (m-1-2) --node[right]{$\plusArg$} (m-2-2);
				\draw[rws,implied] (m-2-2) --node[right]{$\plusL,\plusR,\cancelL,\cancelR$} (m-3-2);
				\draw[rws,implied] (m-3-1) --node[below]{$\plusFun$} (m-3-2);
				\end{tikzpicture}}}
		\]
	}

	%=====
	\itm\plusBox{\trm{!b.(N +a M)} \rw \trm{(!b.N) +a (!b.M)}}
	{\small
		\[
		\vcenter{\hbox{\begin{tikzpicture}
				\matrix [matrix of math nodes] (m) {
					\trm{!b.(N+aM)}    &[20pt] \trm{(!b.N)+a(!b.M)}
					\\[20pt]\trm{N+aM}
					\\ };
				\draw[rw] (m-1-1) --node[above]{$\plusBox$} (m-1-2);
				\draw[rw] (m-1-1) --node[left] {$\boxVoid$} (m-2-1);
				\draw[rws,implied] (m-1-2) --node[below right=-2pt] {$\boxVoid$} (m-2-1);
				\end{tikzpicture}}}
		\quad (a \neq b, \ b \notin\trm{N+a M})
		\]
	}
\end{proof}

%\setcounter{lemmaAppendix}{\value{lemma:application-parallel-beta}}
%\begin{lemmaAppendix}
%	\label{lemmaAppendix:application-parallel-beta}
%	If $\trm{M} \rwp_\beta \trm{M'}$ and $\trm{N} \rwp_\beta \trm{N'}$,
%%	\marginpar{\footnotesize Proof in the Appendix}
%	then $\trm{MN} \rwp_\beta \trm{M'N'}$.
%	If moreover $M = \lambda x.R$ and $M'^ = \lambda x R'$ with $R \rwp_\beta R'$, then  $\trm{MN} \rwp_\beta \trm{R'[N'/x]}$.
%\end{lemmaAppendix}
%
%\begin{proof}
%	Since $\trm{M} \rwp_\beta \trm{Mo} = M'$ and $\trm{N} \rwp_\beta \trm{No} = N'$ for some labelings $\trm{M*}$ and $\trm{N*}$ of $M$ and $N$ respectively, let $\trm{(MN)*}$ be the labeling of $\trm{MN}$ obtained by putting together the labelings $\trm{M*}$ and $\trm{N*}$.
%	Clearly, $\trm{MN} \rwp_\beta \trm{<(MN)*>} = \trm{MoNo} = M'N'$.
%
%	Concerning the part of the statement after ``moreover'', since $\trm{R} \rwp_\beta \trm{<R*>} = R'$ and $\trm{N} \rwp_\beta \trm{No} = N'$ for some labelings $\trm{R*}$ and $\trm{N*}$ of $R$ and $N$ respectively, let $\trm{(MN)*}$ be the labeling of $\trm{MN}$ obtained by putting together the labelings $\trm{R*}$ and $\trm{N*}$ plus the labeled $\beta$-redex $\trm{(\x.R)*N}$.
%	Clearly, $\trm{MN} \rwp_\beta \trm{<(MN)*>} = \trm{<R*>[No/x]} = \trm{R'[N'/x]}$.
%\end{proof}

\setcounter{lemmaAppendix}{\value{lemma:cloredbox}}
\begin{lemmaAppendix}\label{lemmaAppendix:cloredbox}
	The following rule is sound:
	$$
	\infer{\trm{(!a.M)}L_1\ldots L_m\in\mathit{SN}^\theta}{\trm{M}L_1\ldots L_m\in\mathit{SN}^{a\cdot\theta} & \forall i.a\not\in L_i}
	$$
\end{lemmaAppendix}
\begin{proof}
	The proof is structurally very similar to the one of
	Lemma~\ref{lemma:cloredsum}. The lexicographic order
	is however the following one:
	$$
	(m,\sum_{i=1}^m\mathit{sn}^{a\cdot\theta}(L_i)+\mathit{sn}^{a\cdot\theta}(M),|M|)
	$$
	There is one case in which we need to use
	Lemma \ref{lemma:cloredsum}, namely the one in which the
	considered reduction rule is the following:
	$$
	\trm{!b.(P +a Q)}\rw_\perm\trm{(!b.P) +a (!b.Q)}.
	$$
	Since $M=\trm{P +a Q}$ and $ML_1\ldots L_m$ by hypothesis,
	we conclusde that $PL_1\ldots L_m$ and $QL_1\ldots L_m$
	are both strongly normalizing. By induction hypothesis,
	since $\mathit{sn}^{a\cdot\theta}(P),\mathit{sn}^{a\cdot\theta}(Q)\leq\mathit{sn}^{a\cdot\theta}(M)$,
	it holds that $\trm{(!b.P)}L_1\ldots L_m$ and $\trm{(!b.Q)}L_1\ldots L_m$
	are both strongly normalizing themselves. Lemma~\ref{lemma:cloredsum},
	yields the thesis.
\end{proof}

%\begin{lem}\label{lemma:cloredheadvar}
%	The following rule is sound
%	$$
%	\infer{xL_1\ldots L_m\in\mathit{SN}^\theta}{L_1\in\mathit{SN}^\theta &\cdots & L_m\in\mathit{SN}^\theta}
%	$$
%\end{lem}
%
%\begin{proof}
%	Trivial, since the term $xL_1\ldots L_m$ cannot create new redexes.
%\end{proof}

\setcounter{lemmaAppendix}{\value{lemma:cloredbeta}}
\begin{lemmaAppendix}\label{lemmaAppendix:cloredbeta}
	The following rule is sound
	$$
	\infer{\trm{(\x.M)}L_0\ldots L_m\in\mathit{SN}^\theta}{\trm{M[L_0/x]}L_1\ldots L_m\in\mathit{SN}^\theta & L_0\in\mathit{SN}^\theta}
	$$
\end{lemmaAppendix}
\begin{proof}
	Again, the proof is structurally very similar to the one
	of Lemma~\ref{lemma:cloredsum}. The underlying order,
	needs to be slightly adapted, and is the lexicographic
	order on
	\begin{equation}\label{equ:redordbet}
	(\mathit{sn}(\trm{M[L_0/x]}L_1\ldots L_m)+\mathit{sn}(L_0),|M|)
	\end{equation}
	As usual, we proceed by showing that all terms to which
	$\trm{(\x.M)}L_0\ldots L_m$ reduces are strongly normalizing:
	\begin{itemize}
		\item
		If reduction happens in $L_0$, then we can mimick
		the same reduction in by zero or more reduction
		steps in $\trm{M[L_0/x]}L_1\ldots L_m$, and conclude
		by induction hypothesis, because the first component
		of (\ref{equ:redordbet}) strictly decreases.
		\item
		If reduction happens in $M$ or in $L_1,\ldots,L_m$,
		then we can mimick the same reduction in one or more
		reduction in $\trm{M[L_0/x]}L_1\ldots L_m$, and conclude
		by induction hypothesis since, again, the first component
		of (\ref{equ:redordbet}) strictly decreases.
		\item
		If the reduction step we perform reduces
		$\trm{(\x.M)}L_0$, then the thesis follows from the
		hypothesis about $\trm{M[L_0/x]}L_1\ldots L_m$.
		\item
		If $M$ is in the form $\trm{P +a Q}$ and
		the reduction step we perform reduces
		$\trm{(\x.M)}L_0\ldots L_m$
		to $\trm{((\x.P)+a(\x.Q))}L_0\ldots L_m$,
		we proceed by observing that
		$\trm{(\x.P)}L_0\ldots L_m$
		and $\trm{(\x.Q)}L_0\ldots L_m$ are
		both in $\mathit{SN}^\theta$ and we
		can apply the induction hypothesis to them,
		because the first component of (\ref{equ:redordbet})
		stays the same, but the second one strictly decreases.
		We then obtain that
		$\trm{P[x/L_0])}L_1\ldots L_m$
		and $\trm{Q[x/L_0]}L_1\ldots L_m$ are both
		in $\mathit{SN}^\theta$, and from Lemma~\ref{lemma:cloredsum}
		we get the thesis.
		\item
		If $M$ is in the form $\trm{!a.P}$ and
		the reduction step we perform reduces
		$\trm{(\x.M)}L_0\ldots L_m$ to
		$\trm{!a.(\x.P)}L_0\ldots L_m$. We can
		first of all that we can assume that
		$a\not\in L_i$ for every $0\leq i\leq m$.
		We proceed by observing that
		$\trm{(\x.P)}L_0\ldots L_m$ is in $\mathit{SN}^\theta$
		and we can apply the \ih\ to it, because
		the first component of (\ref{equ:redordbet})
		stays the same, but the second one strictly decreases.
		We then obtain that
		$\trm{P[x/L_0]}L_1\ldots L_m$
		is in $\mathit{SN}^\theta$, and from Lemma~\ref{lemma:cloredbox}
		we get the thesis.
	\end{itemize}
\end{proof}




%The choice of ordering in building up $\theta$ in an open interpretation will determine the order of the labels in a term, and thus which label will rise to the surface. If we want to simulate a call-by-value step $M\plusval N\rw_\val M+N$ with $\rws_\perm$, we need to permute $\theta$ so that the label $a$ assigned to the translation of the $\plusval$ will be the smallest.
%
%\begin{prop}
%If $N\rw_\val M+P$ and $\unopen N=\labjudg\theta{N'}$ then there is a permutation $\theta'\cdot a$ of $\theta$ that gives the following.
%\[
%	\labclose{\theta'\cdot a}{N'}~\rws_\perm~\trm{!a.}\uncbv M\trm{+a}\uncbv P
%\]
%\end{prop}

%\begin{proof}
%%	We prove the following statement, from which the thesis follows:
%	The result follows from the following, more general, statement:
%	if $N \rw_\val M +P$ and $\unopen N=\labjudg\theta{N'}$ then there is a permutation  $\theta'' \cdot \theta' \cdot a$ of $\theta$ such that
%	$\labclose{\theta'' \cdot \theta' \cdot a}{N'} \rws_\perm \labclose{\theta'' \cdot \theta' \cdot a}{Q \trm{+a} R}$ where $\unopen{M} =  \labjudg{\theta' }{Q}$ and  $\unopen{P} = \labjudg{\theta''}{R}$.
%	The proof of this statement is by induction on the structure of the context $C$ such that $N=C[Q\oplus_\val R]$ and $M=C[Q]$ and $P=C[R]$.
%%	The proof is by induction on the structure of the context C such that N=C[R\oplus Q], M=C[R] and
%%	P=C[Q]:
%%	* If C is the empty context, the result is trivial.
%%	* If C is SD, where S is a term and D is a context, then  ….
%\end{proof}

%
%
%
%
%
%
%
%\newpage
%
%\hrule
%
%\begin{defn}
%A \emph{head context} $H[\,]$ is given by the following grammar.
%\[
%	H[\,] \coloneqq [\,] ~\mid~ \x.\,H[\,] ~\mid~ H[\,]N
%\]
%\end{defn}
%
%\begin{defn}
%\emph{Projective} reduction $\rw_\pi$ is the following reduction step.
%\[
%	H[\,\trm{!a.N}]^{i\cdot s} ~\rw_\pi~ H[\proj aiN]^s
%\]
%\end{defn}
%
%To have a complete rewriting theory with projective reduction, we lift $\beta$-reduction to the context of streams: if $N\rw_\beta M$ then $N^s\rw_\beta M^s$; to contrast projective and permutative reduction, we do the same for the latter: if $N\rw_\perm M$ then $N^s\rw_\perm M^s$.
%
%Projective reduction is a strategy, and not a rewrite relation, as it applies only in head contexts---that is, we do not evaluate inside arguments, or under other generators $\ttrm{!a}$ or choices $\ttrm{+a}$. (Though note that we don't impose a strategy on $\beta$-reduction.) This ensures that the same generator $\ttrm{!a}$ consumes the same element on the stream $s$ regardless of the chosen reduction path---in other words, reduction on $N^s$ is confluent.
%
%
%This corresponds to the generator permuting outside of a head context by $\boxAbs$ and $\boxFun$ steps, as below. Naturally, both sides of this reduction have the same $\pi$-reduction.
%\[
%%	\trm{H[\,!a.N]}\rws_\perm \trm{!a.H[N]}
%\begin{tikzpicture}[x=40pt,y=30pt]
%	\node (HaN) at (0,1) {$\trm{H[\,!a.N]}^{i\cdot s}$};
%	\node (aHN) at (2,1) {$\trm{!a.H[N]}^{i\cdot s}$};
%	\node (pN)  at (1,0) {$H[\,\proj aiN]^s$};
%	\draw[rws] (HaN) --node[above]{$\scriptstyle\perm$} (aHN);
%	\draw[rw]  (HaN) --node[left] {$\scriptstyle\pi$}   (pN);
%	\draw[rw]  (aHN) --node[right]{$\scriptstyle\pi$}   (pN);
%\end{tikzpicture}
%\]
%Projective reduction is further an invariant to permutative reduction on a choice $\ttrm{+a}$ bound by an outermost generator $\ttrm{!a}$, as below (where $D[\,]$ is a context as used in a $\plusX$-step, and where $\pi^a_i$ remains to capture other instances of $\ttrm{+a}$).
%\[
%\begin{tikzpicture}[x=60pt,y=30pt]
%	\node (A) at (0,1) {$\trm{!a.C[D[N_0+aN_1]]^{i\cdot s}}$};
%	\node (B) at (2,1) {$\trm{!a.C[D[N_0]+aD[N_1]]^{i\cdot s}}$};
%	\node (C) at (1,0) {$\proj ai{C[D[N_i]]}^s$};
%	\draw[rw] (A) --node[above]{$\scriptstyle\perm$} (B);
%	\draw[rw] (A) --node[left] {$\scriptstyle\pi$}   (C);
%	\draw[rw] (B) --node[right]{$\scriptstyle\pi$}   (C);
%\end{tikzpicture}
%\]
%This, however, is about the extent to which projective reduction can be used as an invariant: it cannot capture permutative evaluation of a generator in argument position (and its bound choice operators), since it does not evaluate there; and whether a generator will end up in head position is of course undecidable.
%
%Projective reduction also does not evaluate under a generator $\ttrm{!b}$. Doing so would correspond to permuting two generators, $\ttrm{!b.!a.N}$ to $\ttrm{!a.!b.N}$, which we do not admit as a permutative rule, as indeed we can't without losing strong normalization. Naturally, though, one would expect such terms to be in some way equivalent. We can express this through streams: exchanging two generators is equivalent by also exchanging the corresponding bits in the context stream.
%\[
%	H[\,\trm{!a.!b.N}]^{i\cdot j\cdot s}
%	\quad\sim\quad
%	H[\,\trm{!b.!a.N}]^{j\cdot i\cdot s}
%\]
%Finally, projective reduction does not evaluate under a choice, though it might: this is merely a simplification due to terms being label-closed, which means we would not expect the outermost generator to occur under a choice.
%
%Overall, then, projective reduction is an invariant over permutative reduction, except in argument position. In future work we may try to bring both forms closer together, for instance through a suitable notion of B\"ohm tree. Here, we contend ourselves with showing that permutative reduction can simulate a projective step, in the following way.
%
%If the first element in a stream $s$ is an even probabilistic choice between $0$ and $1$, we may express this by $s=0\cdot r + 1\cdot r$, with $r$ the remaining stream. Projective reduction on this stream is then as follows.
%\[
%	H[\,\trm{!a.N}]^s ~\rw_\pi~ H[\proj a0N]^r~+~H[\proj a1N]^r
%\]
%Moreover, observe that if $a$ is not free in $N$, then $\proj aiN=N$, and the above would evaluate to $H[N]^r$. The following proposition demonstrates how permutative reduction captures this behaviour.
%
%\begin{prop}[Permutative reduction simulates projective reduction]
%\[
%	H[\,\trm{!a.N}] ~\rws_\perm~
%	\left\{\begin{array}{l@{\qquad}l}
%		H[N]						 & (a\notin\fl N) \\[5pt]
%		H[\proj a0N] \+ H[\proj a1N] & (a\in\fl N)
%	\end{array}\right.
%\]
%\end{prop}
%
%\begin{proof}
%The case $a\notin\fl N$ is immediate by a $\boxVoid$ step. For the other case, observe that $\trm{H[\,!a.N]}\rws_\perm\trm{!a.H[N]}$ by $\boxAbs$ and $\boxFun$ steps, and since $a$ does not occur in $H[\,]$, we have $H[\proj aiN]=\proj ai{H[N]}$. Unfolding also the definition of $\+$, we may thus restrict ourselves to proving the following.
%\[
%	\trm{!a.N} ~\rws_\perm~ \trm{!a.} \proj a0N~\trm{+a}~\proj a1N
%\]
%Given that $a$ is the smallest label in $N$, \ie\ $a<b$ for any other label $b$ in $N$, a straightforward induction on $N$ gives $N\rws_\perm\proj a0N~\ttrm{+a}~\proj a1N$, with as special base case $N\rws_\perm N$ for $a\notin\fl N$.
%\end{proof}
%
%\begin{rmrk}
%Our $\boxVoid$ rule, $\trm{!a.N}\rw_\perm N~(a\notin\fl N)$, is not in full accordance with the stream interpretation: morally, it should remove the corresponding element from the context stream. However, we cannot express this as a rewrite step on terms, not even with explicit context streams, as we cannot predict the depth in the stream where an element should be dropped. With that caveat, we retain the rule in the calculus, since it is natural from a rewriting perspective.
%\end{rmrk}
%
%%============================================================ CALL-BY-VALUE
%
%\section{Call-by-value translation}
%\label{sec:cbv}
%
%We consider the interpretation of a call-by-value probabilistic lambda-calculus. For simplicity we will only restrict probabilistic reduction to a call-by-value regime, and not $\beta$-reduction; our values $V$ are then just deterministic (the idea is that probabilistic sums cannot be duplicated or erased). We evaluate the internal probabilistic choice $\ttrm{v{}}$ to an external probabilistic choice $+$.
%\[
%\begin{array}{l@{\qquad}rcl}
%	N \coloneqq x \mid \x.N \mid MN \mid \trm{M v{} N}  & (\x.N)V 		&\rw_\val& N[V/x]
%\\[5pt]
%	V \coloneqq x \mid \x.V \mid VW  					& \trm{M v{} N} &\rw_\val& M + N
%\end{array}
%\]
%
%%
%%
%\begin{defn}
%A \emph{head context} $H^d[\,]$ of \emph{depth} $d\in\mathbb N$ is given by the following grammar.
%\[
%\begin{array}{c@{\quad}c@{\quad}r@{\quad}c@{\quad}c@{\quad}c@{\quad}c@{\quad}c}
%	H^d[\,] & \coloneqq & [\,] & (d=0) &\mid& \x.\,H^d[\,] &\mid& H^d[\,]\,N
%	\\[5pt] & \mid &	  \trm{!a.H^{d-1}[\,]} & (d\neq 0) &\mid& \trm{H^d[\,]+a N} &\mid& \trm{N+aH^d[\,]}
%\end{array}
%\]
%\end{defn}
%
%That is, the depth $d$ is the number of generators above the hole $[\,]$ in the context $H^d[\,]$. We use $r,s,t$ for finite and infinite streams over $\{0,1\}$, use $(\cdot)$ for appending streams (where we assume the first argument to be finite), and denote the length of a finite stream $s$ by $|s|$ .
%
%\begin{defn}
%\emph{Projective} reduction $\rw_\pi$ is the following reduction step.
%\[
%	H^d[\,\trm{!a.N}]^{r\cdot i\cdot s} ~\rw_\pi~ H^d[\proj aiN]^{r\cdot s} \qquad (|r|=d)
%\]
%\end{defn}
%
%
%Projective reduction is an invariant for permutative reduction, in the following way.
%
%\begin{proposition}
%%
%%\\	\trm{!a.N}				&\rw_\perm N 									&& (a\notin N)		\tag{\boxVoid}
%%\\	\trm{\x.!a.N} 			&\rw_\perm \trm{!a.\x. N}				\rstrut						\tag{\boxAbs}
%%\\	\trm{(!a.N)M}			&\rw_\perm \trm{!a.(NM)}				\rstrut						\tag{\boxFun}
%
%\end{proposition}



%
%The call-by-value interpretation $\uncbv{N}$ of term $N$ in this calculus is given as follows. First, we translate $N$ to an open $\PEL$-term $\unopen N=\labjudg\theta P$, and then $\uncbv{N}$ is the label closure $\uncbv{N}=\labclose\theta P$, which prefixes $P$ with a generator $\trm{!a}$ for every $a$ in $\theta$.
%
%\begin{defn}
%The \emph{label closure} $\labclose\theta P$ is given inductively as follows.
%\[
%	\labclose{}P = P \qquad \labclose{a\cdot\theta}P = \labclose\theta{\trm{!a.P}}
%\]
%The \emph{open interpretation} $\unopen N$ is given as follows, where $\unopen{N_i}=\labjudg{\theta_i}{P_i}$ for $i\in\{1,2\}$, and all labels are fresh.
%\[
%\begin{array}{r@{\quad}c@{\quad}l@{\qquad}r@{\quad}c@{\quad}l}
%		\unopen x 		 &=& \labjudg{}x				& \unopen {N_1N_2}   &=& \labjudg{\theta_2\cdot\theta_1}{P_1P_2}
%\\[5pt]	\unopen {\x.N_1} &=& \labjudg{\theta_1}{\x.P_1} & \unopen {N_1\plusval N_2} &=& \labjudg{\theta_2\cdot\theta_1\cdot a}{\trm{P_1 +a P_2}}
%\end{array}
%\]
%The \emph{call-by-value interpretation} of a probabilistic lambda-term $N$ is
%\[
%	\uncbv N=\lfloor\unopen N\rfloor~.
%\]
%\end{defn}
%
%The choice of ordering in building up $\theta$ in an open interpretation will determine the order of the labels in a term, and thus which label will rise to the surface. If we want to simulate a call-by-value step $M\plusval N\rw_\val M+N$ with $\rws_\perm$, we need to permute $\theta$ so that the label $a$ assigned to the translation of the $\plusval$ will be the smallest.
%
%\begin{prop}
%If $N\rw_\val M+P$ and $\unopen N=\labjudg\theta{N'}$ then there is a permutation $\theta'\cdot a$ of $\theta$ that gives the following.
%\[
%	\labclose{\theta'\cdot a}{N'}~\rws_\perm~\trm{!a.}\uncbv M\trm{+a}\uncbv P
%\]
%\end{prop}
%
%\begin{proof}
%%	We prove the following statement, from which the thesis follows:
%	The result follows from the following, more general, statement:
%	if $N \rw_\val M +P$ and $\unopen N=\labjudg\theta{N'}$ then there is a permutation  $\theta'' \cdot \theta' \cdot a$ of $\theta$ such that
%	$\labclose{\theta'' \cdot \theta' \cdot a}{N'} \rws_\perm \labclose{\theta'' \cdot \theta' \cdot a}{Q \trm{+a} R}$ where $\unopen{M} =  \labjudg{\theta' }{Q}$ and  $\unopen{P} = \labjudg{\theta''}{R}$.
%	The proof of this statement is by induction on the structure of the context $C$ such that $N=C[Q\oplus_\val R]$ and $M=C[Q]$ and $P=C[R]$.
%%	The proof is by induction on the structure of the context C such that N=C[R\oplus Q], M=C[R] and
%%	P=C[Q]:
%%	* If C is the empty context, the result is trivial.
%%	* If C is SD, where S is a term and D is a context, then  ….
%\end{proof}

%


%\vfill
%\hrule
%\newpage
%
%
%We would like to evaluate $\ttrm{!a.N}$ by the probabilistic sum $N_0+N_1$, where $N_i$ is $N$ with any subterm of the form $\ttrm{M_0+aM_1}$ projected to $M_i$. The meta-level sum $+$ must be distinct from the abbreviation $N\+M=\ttrm{!a.N+aM}$, since otherwise reduction on this term would be circular. We then need a call-by-need strategy for evaluating $\ttrm{!a.N}$, which we implement through a \emph{head context}.
%
%\begin{defn}
%The \emph{$a$-projections} $\proj a0N$ and $\proj a1N$ are defined as follows, where $a\neq b$.
%\begin{align*}
%	\proj a0{N+aM} &= \proj a0N		&	\proj ai{\x.N} &= \x.\proj aiN
%\\	\proj a1{N+aM} &= \proj a1M		&	\proj ai{NM}   &= (\proj aiN)(\proj aiM)
%\\	\proj ai{!a.N} &= \trm{!a.N}	& 	\proj ai{N+bM} &= (\proj aiN)\trm{+b}(\proj aiM)
%\\	\proj aix      &= x				&	\proj ai{!b.N} &= \trm{!b.}\proj aiN
%\end{align*}
%\end{defn}
%
%\begin{defn}
%A \emph{head context} $H[\,]$ is given by the following grammar.
%\[
%	H[\,] \coloneqq [\,] ~\mid~ \lambda x.H[\,] ~\mid~ H[\,]N
%\]
%\end{defn}
%
%\begin{defn}
%\emph{Projective} reduction $\rw_\pi$ is the following reduction step.
%\[
%	H[\,\trm{!a.N}] ~\rw_\pi~ H[\proj a0N] + H[\proj a1N]
%\]
%\end{defn}
%
%Projective reduction is a strategy, and not a rewrite relation, as it applies only in head contexts---that is, we do not evaluate inside arguments or under other generators $\ttrm{!a}$ or choices $\ttrm{+a}$. This corresponds to the generator permuting outside of a head context by $\boxAbs$ and $\boxFun$ steps, as below.
%\[
%	\ttrm{H[\,!a.N]}\rws_\perm \ttrm{!a.H[N]}
%\]
%Evaluating inside $\ttrm{!a}$ would correspond to permuting two generators, $\ttrm{!a.!b.N}$ to $\ttrm{!b.!a.N}$, which we do not admit as a rewrite rule. Similarly, we do not evaluate inside a choice, since we distribute a generator over a choice (rule $\plusBox$) rather than permuting in the other direction. Still, since projective reduction evaluates the outermost generator on the spine of a term, and removes all its bound labels, projective reduction has the same normal forms except in argument position. Rather than trying to bring both forms closer together, which would involve juggling $\+$ and $+$ and several kinds of reduction context, we contend ourselves with showing that permutative reduction can implement a projective step. For the following proposition, observe that if $a$ is not free in $N$, then $\proj aiN=N$, so that we have $H[\,\trm{!a.N}] ~\rw_\pi~ H[N]+H[N]~=~H[N]$.

%If we restrict permutative reduction in that way, we

%\begin{definition}
%An \emph{argument context} $A[\,]$ is a context of the form $C[N\,[\,]]$, with the hole in argument position. \emph{Deep} projective reduction is the closure of exhaustive projective reduction under argument contexts.
%\[
%	N \rwn N_1+\dots+N_n \qquad
%\]
%\end{definition}
%
%\begin{prop}[Permutative reduction simulates projective reduction]
%\[
%	H[\,\trm{!a.N}] ~\rws_\perm~
%	\left\{\begin{array}{l@{\qquad}l}
%		H[N]						 & (a\notin\fl N) \\[5pt]
%		H[\proj a0N] \+ H[\proj a1N] & (a\in\fl N)
%	\end{array}\right.
%\]
%\end{prop}
%
%\begin{proof}
%The case $a\notin\fl N$ is immediate by a $\boxVoid$ step. For the other case, observe that $\trm{H[\,!a.N]}\rws_\perm\trm{!a.H[N]}$ by $\boxAbs$ and $\boxFun$ steps, and since $a$ does not occur in $H[\,]$, we have $H[\proj aiN]=\proj ai{H[N]}$. Unfolding also the definition of $\+$, we may thus restrict ourselves to proving the following.
%\[
%	\trm{!a.N} ~\rws_\perm~ \trm{!a.} \proj a0N~\trm{+a}~\proj a1N
%\]
%Given that $a$ is the smallest label in $N$, \ie\ $a<b$ for any other label $b$ in $N$, a straightforward induction on $N$ gives $N\rws_\perm\proj a0N~\ttrm{+a}~\proj a1N$, with as special base case $N\rws_\perm N$ for $a\notin\fl N$.
%\end{proof}


%Observe that $\trm{H[\,!a.N]}\rws_\perm\trm{!a.H[N]}$ by $\boxAbs$ and $\boxFun$ steps, and since $a$ does not occur in $H[\,]$, we have $H[\proj aiN]=\proj ai{H[N]}$. Unfolding also the definition of $\+$, we may thus restrict ourselves to proving the following.
%\[
%	\trm{!a.N} ~\rws_\perm~
%	\left\{\begin{array}{l@{\qquad}l}
%		N						 & (a\notin\fl N) \\[5pt]
%		\trm{!a.}\proj a0N]~\trm{+a}~\proj a1N & (a\in\fl N)
%	\end{array}\right.
%\]
%Given that $a$ is the smallest label in $N$, \ie\ $a<b$ for any other label $b$ in $N$, a straightforward induction on $N$ gives $N\rws_\perm\proj a0N~\ttrm{+a}~\proj a1N$, as required.


%We will demonstrate that $\rw_\pi$ is included in $\rws_\perm$. Since $\rws_\perm$ is ignorant of the external sum $+$ (it instead permutes the internal sum $\+$ to the surface), to make the connection formal we need to interpret each top-level $\+$ by $+$. Then let $N^+$ denote the term $N$ with every top-level $\+$ evaluated as $+$, as follows.
%\[
%	\trm{(N\+M)}^+=N^+\!+M^+ \qquad\qquad N^+=N \quad(N\neq \trm{M\+P})
%\]
%
%
%\begin{rmrk}
%	\label{rmrk:proj}
%	Let $N, M$ be terms with $\fl{N} \cup \fl{M} \subseteq \{a\}$.
%	Then $\trm{!a. N +a M} \rws_\perm \trm{!a}. \proj{a}{0}{N} \trm{+a} \proj{a}{1}{M} $, where the number of $\rw_\perm$-steps is the number of free occurrences of the label $a$ in $N$ and $M$ not in the scope of some box.
%	More in general, under the same hypothesis, if $H$ is a head context then $H[\trm{!a. N +a M}] \rws_\perm \trm{!a}. H[\proj{a}{0}{N}] \trm{+a} H[\proj{a}{1}{M}]$.
%	The proof is a straightforward induction on $H$.
%\end{rmrk}
%
%\begin{lem}\label{lem:plus-projection}
%	Let $N$ be a term such that $\fl{N} \subseteq \{a\}$.
%	\begin{enumerate}
%		\item\label{lem:plus-projection-base} 	Then, $\proj{a}{i}{N}^+ = \proj{a}{i}{N}$ for all $i \in \{0,1\}$.
%		\item\label{lem:plus-projection-head} If $H$ is a head context, then $H[\proj{a}{i}{N}]^+ = H[\proj{a}{i}{N}]$.
%	\end{enumerate}
%\end{lem}
%
%\begin{proof}
%	\begin{enumerate}
%		\item By straightforward induction on $N$.
%		\item By straightforward induction on $H$, the base case is \Cref{lem:plus-projection-base}.
%		%\qedhere
%	\end{enumerate}
%\end{proof}
%
%\begin{prop}
%Let $N$ a label-closed term. If $N\rw_\pi M$ then there is a $P$ such that $N\rws_\perm P$ with $P^+=M$.
%\end{prop}

%\begin{proof}
%	By induction on the definition of $N \rw_\pi M$. Cases:
%	\begin{itemize}
%		\item \emph{Step at the root}, \ie\ $N = \trm{!a.N'} \rw_\pi \proj{a}{0}{N'} + \proj{a}{1}{N'}$.
%
%		\item \emph{Abstraction}, \ie\ $N = \lambda x. N' \rw_\pi \lambda x. M' = M$ with $N' \rw_\pi M'$.
%		Let $P = M$: thus, $N  \rws_\perm = P$ (since $\rws_\perm$ is reflexive) with $P^+ =  (\lambda x.P')^+ = \lambda x. P' $.
%
%		\item \emph{Application}, \ie\ $N = N'Q \rw_\pi M'Q = M$ with $N' \rw_\pi M'$.
%		By \ih, there is $P'$ such that $N' \rws_\perm P'$ and $P'^+ = M'$.
%		\qed
%	\end{itemize}
%\end{proof}
%\begin{proof}
%	Since $N\rw_\pi M$, then $N = H[\trm{!a.N'}]$ and $M = H[\proj a0{N'}] + H[\proj a1{N'}]$.
%	We prove the proposition by induction on $N'$. Cases:
%	\begin{itemize}
%		\item \emph{Superposition}, \ie\ $N = H[\trm{!a.N_0 +b N_1}] \rw_\pi H[\proj{a}{0}{N_0 +b N_1}] + H[\proj{a}{1}{N_0 +b N_1}] \allowbreak= M$.
%		Since $N$ is label-closed and the head context $H$ cannot close $\trm{+b}$, then $b = a$.
%		Therefore, $M = H[\proj{a}{0}{N_0}] + H[\proj{a}{1}{N_1}]$.
%		Let $P = \trm{!a}. H[\proj{a}{0}{N_0}] \trm{+a} \allowbreak H[\proj{a}{1}{N_1}]$.
%		According to \Cref{rmrk:proj}, $N = H[\trm{!a.N_0 +a N_1}] \rws_\perm P
%			%\trm{!a}. H[\proj{a}{0}{N_0}] \trm{+a} H[\proj{a}{1}{N_1}]
%		$ where $P^+ = \allowbreak (\trm{!a}. H[\proj{a}{0}{N_0}] \trm{+a} H[\proj{a}{1}{N_1}])^+ = (H[\proj{a}{0}{N_0}])^+ + (H[\proj{a}{1}{N_1}])^+ = \allowbreak H[\proj{a}{0}{N_0}] \allowbreak+ H[\proj{a}{1}{N_1}] = M$ (the last identity holds by \Cref{lem:plus-projection}.\ref{lem:plus-projection-head}).
%
%		\item \emph{Variable}, \ie\ $N = H[\trm{!a}. x] \rw_\pi H[\proj{a}{0}{x}] + H[\proj{a}{1}{x}] =\allowbreak H[x] + H[x] = H[x] = M$.
%%		$\proj{a}{0}{N''} + \proj{a}{1}{N''} = M$ with $N' \rw_\pi M'$.
%		Let $P = M$: thus, $N  \rws_\perm P$ with $P^+ =  H[x]^+ = H[x] = M$.
%
%		\item \emph{Abstraction}, \ie\ $N = H[\trm{!a}.\lambda x. Q] \rw_\pi H[\proj{a}{0}{\lambda x.Q}] + H[\proj{a}{1}{\lambda x.Q}] =\allowbreak H[\lambda x.\proj{a}{0}{Q}] + H[\lambda x.\proj{a}{1}{Q}] = M$.
%		%		$\proj{a}{0}{N''} + \proj{a}{1}{N''} = M$ with $N' \rw_\pi M'$.
%		There are two sub-cases:
%		\begin{itemize}
%			\item $a \in \fl{Q}$, and then let $P = \trm{!a}. H[\lambda x.\proj{a}{0}{Q}] \trm{+a} H[\lambda x.\proj{a}{1}{Q}]$:
%			as $H[\trm{!a}.Q] \allowbreak\rw_\pi H[\proj{a}{0}{Q}] + H[\proj{a}{1}{Q}]$, we have $H[\trm{!a}.Q] \rws_\perm \trm{!a}.H[\proj{a}{0}{Q}] \trm{+a} H[\proj{a}{1}{Q}]$ by \ih,
%			thus $N = H[\trm{!a}.\lambda x.Q] \rws_\perm \trm{!a}.H[\proj{a}{0}{\lambda x.Q}] \trm{+a} H[\proj{a}{1}{\lambda x.Q}] = \trm{!a}. H[\lambda x.\proj{a}{0}{Q}] \trm{+a} H[\lambda x.\proj{a}{1}{Q}] = P$ with $P^+ =  H[\lambda x.\proj{a}{0}{Q}]^+ +\allowbreak H[\lambda x.\proj{a}{1}{Q}]^+ \allowbreak= H[\lambda x.\proj{a}{0}{Q}] + H[\lambda x.\proj{a}{1}{Q}] \allowbreak= M$.
%
%			\item $a \notin \fl{Q}$, and then let $P = H[\lambda x.Q]$:
%			we have $N = H[\trm{!a}.\lambda x. Q] \rw_\perm P$ and $P^+ = H[\lambda x.Q] = H[\lambda x.Q] + H[\lambda x.Q] = H[\lambda x.\proj{a}{0}{Q}] + H[\lambda x.\proj{a}{1}{Q}] \allowbreak= M$ since $\proj{a}{i}{Q} = Q$ because $a \notin \fl{Q}$.
%		\end{itemize}
%
%		\item \emph{Application}, \ie\ $N = H[\trm{!a}.QQ'] \rw_\pi H[\proj{a}{0}{QQ'}] + H[\proj{a}{1}{QQ'}] = H[\proj{a}{0}{Q}\proj{a}{0}{Q'}] + H[\proj{a}{1}{Q}\proj{a}{1}{Q'}] = M$.
%		Analogous to the abstraction case.
%%		Let $P = \trm{!a}. H[\proj{a}{0}{Q}\proj{a}{1}{Q'}] \trm{+a} H[\proj{a}{1}{Q}\proj{a}{1}{Q'}]$: thus, $N  \rws_\perm P$ with $P^+ =  H[\lambda x.\proj{a}{0}{Q}]^+ + H[\lambda x.\proj{a}{1}{Q}]^+ = H[\lambda x.\proj{a}{0}{Q}] + H[\lambda x.\proj{a}{1}{Q}] = M$.
%
%		\item \emph{Box}, \ie\ $N = H[\trm{!a}.\trm{!b}.Q] \rw_\pi H[\proj{a}{0}{!b.Q}] + H[\proj{a}{1}{!b.Q}] = H[\trm{!b.}\proj{a}{0}{Q}] + H[\trm{!b.}\proj{a}{1}{Q}] = M$ where $a \neq b$ (without loss of generality).
%		Analogous to the abstraction case.
%		%\qedhere
%	\end{itemize}
%\end{proof}

%\hrule

%
%\section{Call-by-value translation}
%\label{sec:cbv}
%
%We consider the interpretation of a call-by-value probabilistic lambda-calculus. For simplicity we will only restrict probabilistic reduction to a call-by-value regime, and not $\beta$-reduction; our values $V$ are then just deterministic (the idea is that probabilistic sums cannot be duplicated or erased).
%\[
%\begin{array}{l@{\qquad}rcl}
%	N \coloneqq x \mid \x.N \mid MN \mid M\plusval N  & (\x.N)V &\rw_\val& N[V/x]
%\\[5pt]
%	V \coloneqq x \mid \x.V \mid VW  &  M\plusval N &\rw_\val& M + N
%\end{array}
%\]
%The call-by-value interpretation $\uncbv{N}$ of term $N$ in this calculus is given as follows. First, we translate $N$ to an open $\PEL$-term $\unopen N=\labjudg\theta P$, and then $\uncbv{N}$ is the label closure $\uncbv{N}=\labclose\theta P$, which prefixes $P$ with a generator $\trm{!a}$ for every $a$ in $\theta$.
%
%\begin{defn}
%The \emph{label closure} $\labclose\theta P$ is given inductively as follows.
%\[
%	\labclose{}P = P \qquad \labclose{a\cdot\theta}P = \labclose\theta{\trm{!a.P}}
%\]
%The \emph{open interpretation} $\unopen N$ is given as follows, where $\unopen{N_i}=\labjudg{\theta_i}{P_i}$ for $i\in\{1,2\}$, and all labels are fresh.
%\[
%\begin{array}{r@{\quad}c@{\quad}l@{\qquad}r@{\quad}c@{\quad}l}
%		\unopen x 		 &=& \labjudg{}x				& \unopen {N_1N_2}   &=& \labjudg{\theta_2\cdot\theta_1}{P_1P_2}
%\\[5pt]	\unopen {\x.N_1} &=& \labjudg{\theta_1}{\x.P_1} & \unopen {N_1\plusval N_2} &=& \labjudg{\theta_2\cdot\theta_1\cdot a}{\trm{P_1 +a P_2}}
%\end{array}
%\]
%The \emph{call-by-value interpretation} of a probabilistic lambda-term $N$ is
%\[
%	\uncbv N=\lfloor\unopen N\rfloor~.
%\]
%\end{defn}
%
%The choice of ordering in building up $\theta$ in an open interpretation will determine the order of the labels in a term, and thus which label will rise to the surface. If we want to simulate a call-by-value step $M\plusval N\rw_\val M+N$ with $\rws_\perm$, we need to permute $\theta$ so that the label $a$ assigned to the translation of the $\plusval$ will be the smallest.
%
%\begin{prop}
%If $N\rw_\val M+P$ and $\unopen N=\labjudg\theta{N'}$ then there is a permutation $\theta'\cdot a$ of $\theta$ that gives the following.
%\[
%	\labclose{\theta'\cdot a}{N'}~\rws_\perm~\trm{!a.}\uncbv M\trm{+a}\uncbv P
%\]
%\end{prop}
%
%\begin{proof}
%%	We prove the following statement, from which the thesis follows:
%	The result follows from the following, more general, statement:
%	if $N \rw_\val M +P$ and $\unopen N=\labjudg\theta{N'}$ then there is a permutation  $\theta'' \cdot \theta' \cdot a$ of $\theta$ such that
%	$\labclose{\theta'' \cdot \theta' \cdot a}{N'} \rws_\perm \labclose{\theta'' \cdot \theta' \cdot a}{Q \trm{+a} R}$ where $\unopen{M} =  \labjudg{\theta' }{Q}$ and  $\unopen{P} = \labjudg{\theta''}{R}$.
%	The proof of this statement is by induction on the structure of the context $C$ such that $N=C[Q\oplus_\val R]$ and $M=C[Q]$ and $P=C[R]$.
%%	The proof is by induction on the structure of the context C such that N=C[R\oplus Q], M=C[R] and
%%	P=C[Q]:
%%	* If C is the empty context, the result is trivial.
%%	* If C is SD, where S is a term and D is a context, then  ….
%\end{proof}

%
%
%{\color{red}NOTE: Please check thoroughly that I haven't messed up the order of labels in the notion of ``label closure''.}
%
%\begin{defn}
%	A \emph{weak context} $W[\,]$ is given by the following grammar.
%	\[
%	W[\,] \coloneqq [\,] ~\mid~ NW[\,] ~\mid~ W[\,]N
%	\]
%\end{defn}
%
%\begin{defn}
%	\emph{Projective call-by-value} reduction $\rw_\pi$ is the following reduction step.
%	\[
%	W[\,\trm{!a.N}] ~\rw_{\pi_\cbv}~ W[\proj a0N] + W[\proj a1N]
%	\]
%\end{defn}
%
%\begin{rmrk}
%	\label{rmrk:proj-cbv}
%	Let $N, M$ be terms with $\fl{N} \cup \fl{M} \subseteq \{a\}$.
%	If $W$ is a weak context then $W[\trm{!a. N +a M}] \rws_\perm \trm{!a}. W[\proj{a}{0}{N}] \trm{+a} W[\proj{a}{1}{M}]$.
%	The proof is a straightforward induction on $W$ (the base case is the same as in \Cref{rmrk:proj}).
%\end{rmrk}
%
%\begin{prop}
%	Let $N$ a label-closed term. If $N\rw_{\pi_\cbv} M$ then there is a $P$ such that $N\rws_\perm P$ with $\uncbv{P}^+ = M$.
%\end{prop}
%
%%\begin{proof}
%%	By induction on the definition of $N \rw_\pi M$. Cases:
%%	\begin{itemize}
%%		\item \emph{Step at the root}, \ie\ $N = \trm{!a.N'} \rw_\pi \proj{a}{0}{N'} + \proj{a}{1}{N'}$.
%%
%%		\item \emph{Abstraction}, \ie\ $N = \lambda x. N' \rw_\pi \lambda x. M' = M$ with $N' \rw_\pi M'$.
%%		Let $P = M$: thus, $N  \rws_\perm = P$ (since $\rws_\perm$ is reflexive) with $P^+ =  (\lambda x.P')^+ = \lambda x. P' $.
%%
%%		\item \emph{Application}, \ie\ $N = N'Q \rw_\pi M'Q = M$ with $N' \rw_\pi M'$.
%%		By \ih, there is $P'$ such that $N' \rws_\perm P'$ and $P'^+ = M'$.
%%		\qed
%%	\end{itemize}
%%\end{proof}
%\begin{proof}
%	Since $N\rw_\pi M$, then $N = W[\trm{!a.N'}]$ and $M = W[\proj a0{N'}] + W[\proj a1{N'}]$.
%	We prove the proposition by induction on $N'$. Cases:
%	\begin{itemize}
%		\item \emph{Superposition}, \ie\ $N = W[\trm{!a.N_0 +b N_1}] \rw_{\pi_\cbv} W[\proj{a}{0}{N_0 +b N_1}] + W[\proj{a}{1}{N_0 +b N_1}] \allowbreak= M$.
%		Since $N$ is label-closed and the weak context $W$ cannot close $\trm{+b}$, then $b = a$.
%		Therefore, $M = W[\proj{a}{0}{N_0}] + W[\proj{a}{1}{N_1}]$.
%		Let $P = \trm{!a}. W[\proj{a}{0}{N_0}] \trm{+a} \allowbreak W[\proj{a}{1}{N_1}]$.
%		According to \Cref{rmrk:proj-cbv}, $N = W[\trm{!a.N_0 +a N_1}] \rws_\perm P $ where $\uncbv{P}^+ = \allowbreak \uncbv{\trm{!a}. W[\proj{a}{0}{N_0}] \trm{+a} W[\proj{a}{1}{N_1}]}^+ = \uncbv{W[\proj{a}{0}{N_0}]} + \uncbv{W[\proj{a}{1}{N_1}]} = \allowbreak W[\proj{a}{0}{N_0}] \allowbreak+ W[\proj{a}{1}{N_1}] = M$ (the last identity holds by \Cref{lem:plus-projection}.\ref{lem:plus-projection-head}).
%
%		\item \emph{Variable}, \ie\ $N = W[\trm{!a}. x] \rw_\pi W[\proj{a}{0}{x}] + W[\proj{a}{1}{x}] =\allowbreak W[x] + W[x] = W[x] = M$.
%		Let $P = M$: thus, $N  \rws_\perm P$ with $\uncbv{P} = \uncbv{W[x]} = \lfloor\unopen{W[x]}\rfloor = \lfloor \labjudg{}{W[x]} \rfloor = W[x] = M$.
%
%		\item \emph{Abstraction}, \ie\ $N = W[\trm{!a}.\lambda x. Q] \rw_\pi W[\proj{a}{0}{\lambda x.Q}] + W[\proj{a}{1}{\lambda x.Q}] =\allowbreak W[\lambda x.\proj{a}{0}{Q}] + W[\lambda x.\proj{a}{1}{Q}] = M$.
%		%		$\proj{a}{0}{N''} + \proj{a}{1}{N''} = M$ with $N' \rw_\pi M'$.
%		There are two sub-cases:
%		\begin{itemize}
%			\item $a \in \fl{Q}$, and then let $P = \trm{!a}. H[\lambda x.\proj{a}{0}{Q}] \trm{+a} H[\lambda x.\proj{a}{1}{Q}]$:
%			as $H[\trm{!a}.Q] \allowbreak\rw_\pi H[\proj{a}{0}{Q}] + H[\proj{a}{1}{Q}]$, we have $H[\trm{!a}.Q] \rws_\perm \trm{!a}.H[\proj{a}{0}{Q}] \trm{+a} H[\proj{a}{1}{Q}]$ by \ih,
%			thus $N = H[\trm{!a}.\lambda x.Q] \rws_\perm \trm{!a}.H[\proj{a}{0}{\lambda x.Q}] \trm{+a} H[\proj{a}{1}{\lambda x.Q}] = \trm{!a}. H[\lambda x.\proj{a}{0}{Q}] \trm{+a} H[\lambda x.\proj{a}{1}{Q}] = P$ with $P^+ =  H[\lambda x.\proj{a}{0}{Q}]^+ +\allowbreak H[\lambda x.\proj{a}{1}{Q}]^+ \allowbreak= H[\lambda x.\proj{a}{0}{Q}] + H[\lambda x.\proj{a}{1}{Q}] \allowbreak= M$.
%
%			\item $a \notin \fl{Q}$, and then let $P = H[\lambda x.Q]$:
%			we have $N = H[\trm{!a}.\lambda x. Q] \rw_\perm P$ and $P^+ = H[\lambda x.Q] = H[\lambda x.Q] + H[\lambda x.Q] = H[\lambda x.\proj{a}{0}{Q}] + H[\lambda x.\proj{a}{1}{Q}] \allowbreak= M$ since $\proj{a}{i}{Q} = Q$ because $a \notin \fl{Q}$.
%		\end{itemize}
%
%		\item \emph{Application}, \ie\ $N = H[\trm{!a}.QQ'] \rw_\pi H[\proj{a}{0}{QQ'}] + H[\proj{a}{1}{QQ'}] = H[\proj{a}{0}{Q}\proj{a}{0}{Q'}] + H[\proj{a}{1}{Q}\proj{a}{1}{Q'}] = M$.
%		Analogous to the abstraction case.
%		%		Let $P = \trm{!a}. H[\proj{a}{0}{Q}\proj{a}{1}{Q'}] \trm{+a} H[\proj{a}{1}{Q}\proj{a}{1}{Q'}]$: thus, $N  \rws_\perm P$ with $P^+ =  H[\lambda x.\proj{a}{0}{Q}]^+ + H[\lambda x.\proj{a}{1}{Q}]^+ = H[\lambda x.\proj{a}{0}{Q}] + H[\lambda x.\proj{a}{1}{Q}] = M$.
%
%		\item \emph{Box}, \ie\ $N = H[\trm{!a}.\trm{!b}.Q] \rw_\pi H[\proj{a}{0}{!b.Q}] + H[\proj{a}{1}{!b.Q}] = H[\trm{!b.}\proj{a}{0}{Q}] + H[\trm{!b.}\proj{a}{1}{Q}] = M$ where $a \neq b$ (without loss of generality).
%		Analogous to the abstraction case.
%		%\qedhere
%	\end{itemize}
%\end{proof}

\end{document}